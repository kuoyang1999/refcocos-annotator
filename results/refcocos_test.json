[
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the computer screen that is in the middle layer",
    "image": "val2017/000000547144.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the computer screen that is in the middle layer.",
    "solution": [
      297.0,
      345.0,
      427.0,
      440.0
    ],
    "normalized_solution": [
      464,
      718,
      667,
      916
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person on the right hand side of the boy not wearing hat",
    "image": "val2017/000000001000.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the right hand side of the boy not wearing hat.",
    "solution": [
      386.0,
      156.0,
      461.0,
      478.0
    ],
    "normalized_solution": [
      603,
      325,
      720,
      995
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 333,
    "width": 500,
    "normal_caption": "background person not leaning back",
    "image": "val2017/000000006471.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: background person not leaning back.",
    "solution": [
      20.0,
      98.0,
      70.0,
      149.0
    ],
    "normalized_solution": [
      40,
      294,
      140,
      447
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "non-glass cup",
    "image": "val2017/000000002157.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: non-glass cup.",
    "solution": [
      3.0,
      121.0,
      67.0,
      267.0
    ],
    "normalized_solution": [
      4,
      283,
      104,
      625
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "person not holding anything",
    "image": "val2017/000000009590.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person not holding anything.",
    "solution": [
      255.0,
      179.0,
      330.0,
      254.0
    ],
    "normalized_solution": [
      398,
      419,
      515,
      594
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the woman looking at an apple laptop",
    "image": "val2017/000000009400.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the woman looking at an apple laptop.",
    "solution": [
      1.0,
      93.0,
      114.0,
      213.0
    ],
    "normalized_solution": [
      1,
      193,
      178,
      443
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "hidden": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person helding nothing",
    "image": "val2017/000000010707.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person helding nothing.",
    "solution": [
      347.0,
      190.0,
      478.0,
      477.0
    ],
    "normalized_solution": [
      542,
      395,
      746,
      993
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "hidden": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "suitcase next to car wheel",
    "image": "val2017/000000009891.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: suitcase next to car wheel.",
    "solution": [
      419.0,
      245.0,
      495.0,
      350.0
    ],
    "normalized_solution": [
      654,
      510,
      773,
      729
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "the person who is on the phone",
    "image": "val2017/000000012670.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is on the phone.",
    "solution": [
      100.0,
      122.0,
      199.0,
      275.0
    ],
    "normalized_solution": [
      156,
      285,
      310,
      642
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person who is wearing a necklace",
    "image": "val2017/000000015335.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is wearing a necklace.",
    "solution": [
      3.0,
      72.0,
      219.0,
      366.0
    ],
    "normalized_solution": [
      4,
      150,
      342,
      762
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 640,
    "normal_caption": "image containing fork and knife",
    "image": "val2017/000000008629.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: image containing fork and knife.",
    "solution": [
      430.0,
      226.0,
      621.0,
      417.0
    ],
    "normalized_solution": [
      671,
      353,
      970,
      651
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "person outside the middle window",
    "image": "val2017/000000000139.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person outside the middle window.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 483,
    "width": 640,
    "normal_caption": "person on bed",
    "image": "val2017/000000000632.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person on bed.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "letter X",
    "image": "val2017/000000000885.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: letter X.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "person holding a goose feather",
    "image": "val2017/000000001268.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person holding a goose feather.",
    "solution": [
      20.0,
      213.0,
      81.0,
      285.0
    ],
    "normalized_solution": [
      31,
      498,
      126,
      667
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "hidden": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "sign to 101 south",
    "image": "val2017/000000001532.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: sign to 101 south.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 302,
    "width": 500,
    "normal_caption": "child in second row from camera, third from left",
    "image": "val2017/000000002299.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: child in second row from camera, third from left.",
    "solution": [
      77.0,
      135.0,
      117.0,
      234.0
    ],
    "normalized_solution": [
      154,
      447,
      234,
      774
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the ski pole held by the left hand of the person in the air",
    "image": "val2017/000000002473.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the ski pole held by the left hand of the person in the air.",
    "solution": [
      220.0,
      117.0,
      257.0,
      167.0
    ],
    "normalized_solution": [
      343,
      274,
      401,
      391
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 555,
    "width": 640,
    "normal_caption": "the shoes worn by the person with black hoodie",
    "image": "val2017/000000002685.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the shoes worn by the person with black hoodie.",
    "solution": [
      524.0,
      370.0,
      634.0,
      438.0
    ],
    "normalized_solution": [
      818,
      666,
      990,
      789
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "baby corn",
    "image": "val2017/000000003845.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: baby corn.",
    "solution": [
      96.0,
      163.0,
      141.0,
      240.0
    ],
    "normalized_solution": [
      192,
      434,
      282,
      640
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 375,
    "normal_caption": "the man farthest from the camera",
    "image": "val2017/000000003934.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man farthest from the camera.",
    "solution": [
      297.0,
      133.0,
      326.0,
      221.0
    ],
    "normalized_solution": [
      792,
      266,
      869,
      442
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person behind the lady in orange",
    "image": "val2017/000000005001.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person behind the lady in orange.",
    "solution": [
      425.0,
      25.0,
      506.0,
      164.0
    ],
    "normalized_solution": [
      664,
      52,
      790,
      341
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person who is not facing the camera and not holding it",
    "image": "val2017/000000005193.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is not facing the camera and not holding it.",
    "solution": [
      224.0,
      67.0,
      265.0,
      185.0
    ],
    "normalized_solution": [
      350,
      157,
      414,
      435
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 335,
    "width": 500,
    "normal_caption": "the object held by the person on the right hand side of the person in red",
    "image": "val2017/000000013291.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the object held by the person on the right hand side of the person in red.",
    "solution": [
      182.0,
      199.0,
      217.0,
      232.0
    ],
    "normalized_solution": [
      364,
      594,
      434,
      692
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 404,
    "width": 640,
    "normal_caption": "the person sitting on the left side of the red chair",
    "image": "val2017/000000014439.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person sitting on the left side of the red chair.",
    "solution": [
      23.0,
      120.0,
      64.0,
      155.0
    ],
    "normalized_solution": [
      35,
      297,
      100,
      383
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the second worker from the right",
    "image": "val2017/000000014473.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second worker from the right.",
    "solution": [
      273.0,
      272.0,
      300.0,
      310.0
    ],
    "normalized_solution": [
      426,
      637,
      468,
      725
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the frisbee that the child in blue looking at",
    "image": "val2017/000000006954.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the frisbee that the child in blue looking at.",
    "solution": [
      248.0,
      228.0,
      366.0,
      345.0
    ],
    "normalized_solution": [
      387,
      475,
      571,
      718
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb"
      ],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the glass behind the flower",
    "image": "val2017/000000007818.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the glass behind the flower.",
    "solution": [
      402.0,
      187.0,
      445.0,
      292.0
    ],
    "normalized_solution": [
      628,
      437,
      695,
      683
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "person other than the man and his reflection",
    "image": "val2017/000000009483.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person other than the man and his reflection.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "yellow flag next to the middle clownfish flag",
    "image": "val2017/000000017959.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: yellow flag next to the middle clownfish flag.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "third motorcycle from the left",
    "image": "val2017/000000019109.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: third motorcycle from the left.",
    "solution": [
      138.0,
      261.0,
      189.0,
      375.0
    ],
    "normalized_solution": [
      215,
      609,
      295,
      876
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the person next to the stairs",
    "image": "val2017/000000018380.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person next to the stairs.",
    "solution": [
      229.0,
      36.0,
      278.0,
      120.0
    ],
    "normalized_solution": [
      357,
      84,
      434,
      281
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person outside the fence who is not sitting",
    "image": "val2017/000000018491.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person outside the fence who is not sitting.",
    "solution": [
      128.0,
      32.0,
      165.0,
      145.0
    ],
    "normalized_solution": [
      200,
      74,
      257,
      339
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person on the surfboard which is not pink or yellow",
    "image": "val2017/000000081988.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the surfboard which is not pink or yellow.",
    "solution": [
      45.0,
      284.0,
      160.0,
      394.0
    ],
    "normalized_solution": [
      70,
      665,
      250,
      922
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 275,
    "width": 500,
    "normal_caption": "a burned hotdog",
    "image": "val2017/000000083531.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a burned hotdog.",
    "solution": [
      343.0,
      159.0,
      404.0,
      178.0
    ],
    "normalized_solution": [
      686,
      578,
      808,
      647
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the three people on the balcony right above crowd, not on the ground",
    "image": "val2017/000000084031.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the three people on the balcony right above crowd, not on the ground.",
    "solution": [
      250.0,
      126.0,
      277.0,
      152.0
    ],
    "normalized_solution": [
      390,
      295,
      432,
      355
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 396,
    "width": 640,
    "normal_caption": "the smaller pot in front of the cooking pan",
    "image": "val2017/000000084241.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the smaller pot in front of the cooking pan.",
    "solution": [
      238.0,
      326.0,
      321.0,
      394.0
    ],
    "normalized_solution": [
      371,
      823,
      501,
      994
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "person wearing striped shirt without long hair",
    "image": "val2017/000000085157.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person wearing striped shirt without long hair.",
    "solution": [
      422.0,
      97.0,
      630.0,
      455.0
    ],
    "normalized_solution": [
      659,
      202,
      984,
      947
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "hidden": true,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the carbinets on the top of the microwave",
    "image": "val2017/000000091615.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the carbinets on the top of the microwave.",
    "solution": [
      479.0,
      1.0,
      626.0,
      51.0
    ],
    "normalized_solution": [
      748,
      2,
      978,
      120
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "hotdog without vegetables on it",
    "image": "val2017/000000091779.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: hotdog without vegetables on it.",
    "solution": [
      110.0,
      99.0,
      472.0,
      320.0
    ],
    "normalized_solution": [
      171,
      206,
      737,
      666
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "dish seems to have the least amount",
    "image": "val2017/000000092053.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: dish seems to have the least amount.",
    "solution": [
      370.0,
      84.0,
      637.0,
      248.0
    ],
    "normalized_solution": [
      578,
      196,
      995,
      580
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "black board that does not have a number on it",
    "image": "val2017/000000094185.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: black board that does not have a number on it.",
    "solution": [
      551.0,
      180.0,
      604.0,
      352.0
    ],
    "normalized_solution": [
      860,
      375,
      943,
      733
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "person holding up a frisbee and not wearing a bag",
    "image": "val2017/000000100238.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person holding up a frisbee and not wearing a bag.",
    "solution": [
      8.0,
      27.0,
      207.0,
      475.0
    ],
    "normalized_solution": [
      12,
      56,
      323,
      989
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb"
      ],
      "hidden": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "ice cream next to the potato",
    "image": "val2017/000000104669.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: ice cream next to the potato.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person partially obscured by the person in red shorts",
    "image": "val2017/000000105264.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person partially obscured by the person in red shorts.",
    "solution": [
      437.0,
      196.0,
      469.0,
      295.0
    ],
    "normalized_solution": [
      682,
      459,
      732,
      690
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 336,
    "width": 500,
    "normal_caption": "the second car behind the car with two open doors",
    "image": "val2017/000000111086.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second car behind the car with two open doors.",
    "solution": [
      161.0,
      232.0,
      226.0,
      281.0
    ],
    "normalized_solution": [
      322,
      690,
      452,
      836
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 425,
    "normal_caption": "the suitcase own by a person holding food in hand",
    "image": "val2017/000000114049.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the suitcase own by a person holding food in hand.",
    "solution": [
      131.0,
      327.0,
      236.0,
      571.0
    ],
    "normalized_solution": [
      308,
      510,
      555,
      892
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb"
      ],
      "hidden": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 329,
    "width": 500,
    "normal_caption": "the bus next to the bus with a different color",
    "image": "val2017/000000114884.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bus next to the bus with a different color.",
    "solution": [
      215.0,
      73.0,
      273.0,
      133.0
    ],
    "normalized_solution": [
      430,
      221,
      546,
      404
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "woman with hat",
    "image": "val2017/000000115870.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: woman with hat.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the elephant fifth farthest from the camera",
    "image": "val2017/000000119641.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the elephant fifth farthest from the camera.",
    "solution": [
      502.0,
      385.0,
      537.0,
      435.0
    ],
    "normalized_solution": [
      784,
      802,
      839,
      906
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 451,
    "width": 640,
    "normal_caption": "horse at left rear of the horse ride by a man wearing shirt",
    "image": "val2017/000000121031.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: horse at left rear of the horse ride by a man wearing shirt.",
    "solution": [
      387.0,
      187.0,
      442.0,
      260.0
    ],
    "normalized_solution": [
      604,
      414,
      690,
      576
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 392,
    "width": 640,
    "normal_caption": "person in yellow jersy",
    "image": "val2017/000000123213.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person in yellow jersy.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the doll in front of a book whose name is not the office and not monk",
    "image": "val2017/000000125062.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the doll in front of a book whose name is not the office and not monk.",
    "solution": [
      1.0,
      224.0,
      127.0,
      445.0
    ],
    "normalized_solution": [
      2,
      350,
      297,
      695
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "hidden": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 327,
    "width": 500,
    "normal_caption": "chips that is neither red nor green",
    "image": "val2017/000000125936.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: chips that is neither red nor green.",
    "solution": [
      255.0,
      107.0,
      316.0,
      136.0
    ],
    "normalized_solution": [
      510,
      327,
      632,
      415
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the cabinet above the white rice cooker",
    "image": "val2017/000000127182.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cabinet above the white rice cooker.",
    "solution": [
      187.0,
      64.0,
      325.0,
      275.0
    ],
    "normalized_solution": [
      437,
      100,
      761,
      429
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the surfboard overlapping two other surfboards",
    "image": "val2017/000000127517.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the surfboard overlapping two other surfboards.",
    "solution": [
      507.0,
      75.0,
      578.0,
      363.0
    ],
    "normalized_solution": [
      792,
      156,
      903,
      756
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "object behind the couch not facing camera horizontally",
    "image": "val2017/000000128148.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: object behind the couch not facing camera horizontally.",
    "solution": [
      1.0,
      189.0,
      96.0,
      311.0
    ],
    "normalized_solution": [
      1,
      441,
      150,
      726
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "hidden": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the cake decorated with two white swan-like figures, noticeably further apart from each other compared to similar decorations on other cakes",
    "image": "val2017/000000128476.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cake decorated with two white swan-like figures, noticeably further apart from each other compared to similar decorations on other cakes.",
    "solution": [
      307.0,
      146.0,
      593.0,
      353.0
    ],
    "normalized_solution": [
      479,
      341,
      926,
      826
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the cow furthest from camera",
    "image": "val2017/000000129416.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cow furthest from camera.",
    "solution": [
      57.0,
      214.0,
      74.0,
      235.0
    ],
    "normalized_solution": [
      114,
      570,
      148,
      626
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "man sitting next to number 25 with his mouth open",
    "image": "val2017/000000133969.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: man sitting next to number 25 with his mouth open.",
    "solution": [
      214.0,
      176.0,
      288.0,
      315.0
    ],
    "normalized_solution": [
      334,
      412,
      450,
      737
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "keyboard closest to monitor that is on",
    "image": "val2017/000000135872.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: keyboard closest to monitor that is on.",
    "solution": [
      310.0,
      166.0,
      369.0,
      198.0
    ],
    "normalized_solution": [
      484,
      388,
      576,
      463
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 563,
    "width": 640,
    "normal_caption": "cow closest to the one sticking out tongue and doesn't have brown skin",
    "image": "val2017/000000137576.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: cow closest to the one sticking out tongue and doesn't have brown skin.",
    "solution": [
      0.0,
      304.0,
      121.0,
      489.0
    ],
    "normalized_solution": [
      0,
      539,
      189,
      868
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 453,
    "width": 640,
    "normal_caption": "the watermelon behind the one that is being held",
    "image": "val2017/000000139099.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the watermelon behind the one that is being held.",
    "solution": [
      43.0,
      391.0,
      182.0,
      411.0
    ],
    "normalized_solution": [
      67,
      863,
      284,
      907
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 333,
    "width": 500,
    "normal_caption": "third biggest decoration on left wall",
    "image": "val2017/000000139684.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: third biggest decoration on left wall.",
    "solution": [
      86.0,
      18.0,
      110.0,
      70.0
    ],
    "normalized_solution": [
      172,
      54,
      220,
      210
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 457,
    "width": 640,
    "normal_caption": "object under the wrench",
    "image": "val2017/000000140556.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: object under the wrench.",
    "solution": [
      389.0,
      244.0,
      487.0,
      456.0
    ],
    "normalized_solution": [
      607,
      533,
      760,
      997
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "object being cut by lady in middle",
    "image": "val2017/000000140640.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: object being cut by lady in middle.",
    "solution": [
      463.0,
      367.0,
      593.0,
      423.0
    ],
    "normalized_solution": [
      723,
      861,
      926,
      992
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 281,
    "width": 500,
    "normal_caption": "the kite on the left of english flag",
    "image": "val2017/000000140840.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the kite on the left of english flag.",
    "solution": [
      138.0,
      175.0,
      199.0,
      238.0
    ],
    "normalized_solution": [
      276,
      622,
      398,
      846
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the person not on the same side as man with hat",
    "image": "val2017/000000115870.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person not on the same side as man with hat.",
    "solution": [
      273.0,
      103.0,
      333.0,
      181.0
    ],
    "normalized_solution": [
      426,
      241,
      520,
      424
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "hidden": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "person who is on a bicycle but not riding it",
    "image": "val2017/000000142324.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person who is on a bicycle but not riding it.",
    "solution": [
      284.0,
      194.0,
      330.0,
      291.0
    ],
    "normalized_solution": [
      443,
      404,
      515,
      606
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the cap of the portable stove",
    "image": "val2017/000000142620.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cap of the portable stove.",
    "solution": [
      41.0,
      369.0,
      101.0,
      422.0
    ],
    "normalized_solution": [
      64,
      866,
      157,
      990
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 356,
    "width": 640,
    "normal_caption": "the man the woman with a translucent veil looking at",
    "image": "val2017/000000143961.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man the woman with a translucent veil looking at.",
    "solution": [
      0.0,
      138.0,
      73.0,
      325.0
    ],
    "normalized_solution": [
      0,
      387,
      114,
      912
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb"
      ],
      "hidden": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "person sitting at 3 o'clock position on picnic mat",
    "image": "val2017/000000145597.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person sitting at 3 o'clock position on picnic mat.",
    "solution": [
      480.0,
      35.0,
      639.0,
      256.0
    ],
    "normalized_solution": [
      750,
      72,
      998,
      533
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "a bowl whose exterior is neither red nor white",
    "image": "val2017/000000494869.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a bowl whose exterior is neither red nor white.",
    "solution": [
      342.29,
      236.85,
      392.62,
      265.01
    ],
    "normalized_solution": [
      802,
      370,
      919,
      414
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person wearing sneakers that are not blue",
    "image": "val2017/000000554002.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing sneakers that are not blue.",
    "solution": [
      19.14,
      2.39,
      109.12,
      257.97
    ],
    "normalized_solution": [
      30,
      6,
      171,
      607
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "9"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car has a cat wearing a red scarf around its neck",
    "image": "val2017/000000078823.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car has a cat wearing a red scarf around its neck.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 426,
    "normal_caption": "the knife that is neither held by anyone nor placed on the marble surface",
    "image": "val2017/000000419974.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the knife that is neither held by anyone nor placed on the marble surface.",
    "solution": [
      130.09,
      276.33,
      146.09,
      283.4
    ],
    "normalized_solution": [
      305,
      432,
      343,
      443
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 512,
    "width": 640,
    "normal_caption": "the bicycle being ridden by a person holding a dog",
    "image": "val2017/000000424162.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bicycle being ridden by a person holding a dog.",
    "solution": [
      305.56,
      230.39,
      422.68,
      474.33
    ],
    "normalized_solution": [
      477,
      450,
      660,
      926
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the cup mounted on the wall, located in the second row from the top, at the leftmost position",
    "image": "val2017/000000329219.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cup mounted on the wall, located in the second row from the top, at the leftmost position.",
    "solution": [
      331.4,
      80.38,
      346.26,
      97.16999999999999
    ],
    "normalized_solution": [
      518,
      188,
      541,
      228
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "12"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 485,
    "width": 640,
    "normal_caption": "the person in the car who is not sitting in the driver's seat",
    "image": "val2017/000000067213.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in the car who is not sitting in the driver's seat.",
    "solution": [
      277.98,
      371.09,
      310.22,
      409.37
    ],
    "normalized_solution": [
      434,
      765,
      485,
      844
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "7"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the bench that a dog is sitting on",
    "image": "val2017/000000061108.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bench that a dog is sitting on.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "7"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 588,
    "width": 640,
    "normal_caption": "the car located to the left of the car containing the dog",
    "image": "val2017/000000365207.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car located to the left of the car containing the dog.",
    "solution": [
      69.7,
      260.42,
      211.63,
      463.18
    ],
    "normalized_solution": [
      109,
      443,
      331,
      788
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 429,
    "width": 640,
    "normal_caption": "the bicycle in the background positioned between the person wearing a black shirt and white pants and the person wearing a black-and-white patterned shirt and shorts, mostly obscured by other objects",
    "image": "val2017/000000279278.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bicycle in the background positioned between the person wearing a black shirt and white pants and the person wearing a black-and-white patterned shirt and shorts, mostly obscured by other objects.",
    "solution": [
      334.76,
      48.96,
      365.2,
      157.71
    ],
    "normalized_solution": [
      523,
      114,
      571,
      368
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "10"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the second hanging potted plant from the right",
    "image": "val2017/000000482100.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second hanging potted plant from the right.",
    "solution": [
      338.75,
      0,
      379.54,
      39.27
    ],
    "normalized_solution": [
      529,
      0,
      593,
      92
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "a watermelon in a bowl placed centrally on the wooden countertop island",
    "image": "val2017/000000540502.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a watermelon in a bowl placed centrally on the wooden countertop island.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "4",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the second knife from the top positioned in a knife block",
    "image": "val2017/000000127182.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second knife from the top positioned in a knife block.",
    "solution": [
      7.8,
      342.05,
      37.51,
      371.61
    ],
    "normalized_solution": [
      18,
      534,
      88,
      581
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a red bowl that is not located on the top shelf of the right set of cabinets",
    "image": "val2017/000000575970.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a red bowl that is not located on the top shelf of the right set of cabinets.",
    "solution": [
      276.5,
      83.81,
      296.74,
      90.16
    ],
    "normalized_solution": [
      432,
      175,
      464,
      188
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "9"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "a wine glass located on top of the stove",
    "image": "val2017/000000226984.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a wine glass located on top of the stove.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "17"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 230,
    "width": 352,
    "normal_caption": "the chair close to the fruit and not next to the refrigerator",
    "image": "val2017/000000037777.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair close to the fruit and not next to the refrigerator.",
    "solution": [
      116.5,
      189.57,
      166.5,
      215.07
    ],
    "normalized_solution": [
      331,
      824,
      473,
      935
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the plant located between a yellow bottle and a blue bottle",
    "image": "val2017/000000491216.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the plant located between a yellow bottle and a blue bottle.",
    "solution": [
      269.55,
      180.58,
      298.97,
      243.18
    ],
    "normalized_solution": [
      562,
      282,
      623,
      380
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the plant that is neither hanging nor placed on a kitchen table",
    "image": "val2017/000000136355.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the plant that is neither hanging nor placed on a kitchen table.",
    "solution": [
      448.77,
      175.76,
      513.22,
      298.76
    ],
    "normalized_solution": [
      701,
      412,
      802,
      700
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "a cup on the middle shelf of the left wall, surrounded by wine glasses",
    "image": "val2017/000000529568.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a cup on the middle shelf of the left wall, surrounded by wine glasses.",
    "solution": [
      66.71,
      220.26,
      82.78999999999999,
      253.76999999999998
    ],
    "normalized_solution": [
      139,
      344,
      172,
      397
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "7"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "a person wiping her face with a towel",
    "image": "val2017/000000306733.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person wiping her face with a towel.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the smaller bowl that is yellow",
    "image": "val2017/000000068833.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the smaller bowl that is yellow.",
    "solution": [
      313.8,
      228.19,
      335.29,
      247.14
    ],
    "normalized_solution": [
      490,
      475,
      524,
      515
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 383,
    "width": 500,
    "normal_caption": "the figure of a person that has a solid-colored background that is not white",
    "image": "val2017/000000149222.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the figure of a person that has a solid-colored background that is not white.",
    "solution": [
      236.11,
      72.81,
      248.48000000000002,
      89.11
    ],
    "normalized_solution": [
      472,
      190,
      497,
      233
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 360,
    "width": 640,
    "normal_caption": "a display screen that is not showing any content with red color",
    "image": "val2017/000000361586.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a display screen that is not showing any content with red color.",
    "solution": [
      19.67,
      133.25,
      86.2,
      211.82
    ],
    "normalized_solution": [
      31,
      370,
      135,
      588
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the bottle that is not empty and is located on the right side of the flower",
    "image": "val2017/000000186632.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle that is not empty and is located on the right side of the flower.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the third chair from the left at the dining table",
    "image": "val2017/000000440475.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the third chair from the left at the dining table.",
    "solution": [
      444.5,
      299.5,
      542.71,
      361.2
    ],
    "normalized_solution": [
      695,
      701,
      848,
      846
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "7"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 357,
    "normal_caption": "an orange cat sitting on the carpet watching tv",
    "image": "val2017/000000240940.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: an orange cat sitting on the carpet watching tv.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "12"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the second bicycle that is laying on top of the motorcycle",
    "image": "val2017/000000070774.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second bicycle that is laying on top of the motorcycle.",
    "solution": [
      261.38,
      173.6,
      506.79999999999995,
      223.64999999999998
    ],
    "normalized_solution": [
      408,
      408,
      792,
      526
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the white pigeon burying its head inside the bread",
    "image": "val2017/000000123585.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white pigeon burying its head inside the bread.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the car that is neither blue nor on the left side of the road and does not have a cat on it",
    "image": "val2017/000000466156.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car that is neither blue nor on the left side of the road and does not have a cat on it.",
    "solution": [
      274.28,
      32.03,
      291.21,
      40.57
    ],
    "normalized_solution": [
      549,
      85,
      582,
      108
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car whose license plate number begins with a digit other than one",
    "image": "val2017/000000172330.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car whose license plate number begins with a digit other than one.",
    "solution": [
      471.74,
      79.74,
      637.94,
      384.26
    ],
    "normalized_solution": [
      737,
      166,
      997,
      801
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the second cup next to the red tube",
    "image": "val2017/000000227044.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second cup next to the red tube.",
    "solution": [
      114.34,
      0,
      174.74,
      43.15
    ],
    "normalized_solution": [
      179,
      0,
      273,
      90
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the person who is wearing green clothing and is next to the woman wearing a purple shirt",
    "image": "val2017/000000176857.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is wearing green clothing and is next to the woman wearing a purple shirt.",
    "solution": [
      145.04,
      11.4,
      175.32,
      75.97
    ],
    "normalized_solution": [
      290,
      30,
      351,
      203
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "11"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the horse that is not brown and is facing away from the car",
    "image": "val2017/000000017178.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the horse that is not brown and is facing away from the car.",
    "solution": [
      374.97,
      173.6,
      433.33000000000004,
      267.26
    ],
    "normalized_solution": [
      586,
      407,
      677,
      626
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 411,
    "normal_caption": "the silver car that is on the front left side of the horse",
    "image": "val2017/000000368335.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the silver car that is on the front left side of the horse.",
    "solution": [
      75.52,
      209.12,
      165.68,
      326.19
    ],
    "normalized_solution": [
      184,
      327,
      403,
      510
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 338,
    "width": 450,
    "normal_caption": "the person wearing a blue shirt walking behind the blue and white bus",
    "image": "val2017/000000367680.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a blue shirt walking behind the blue and white bus.",
    "solution": [
      236.2,
      150.47,
      250.04999999999998,
      197.09
    ],
    "normalized_solution": [
      525,
      445,
      556,
      583
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "8"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 462,
    "width": 640,
    "normal_caption": "the horse that is not facing the camera and does not have a white tail",
    "image": "val2017/000000234807.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the horse that is not facing the camera and does not have a white tail.",
    "solution": [
      3.17,
      238.5,
      86.94,
      291.1
    ],
    "normalized_solution": [
      5,
      516,
      136,
      630
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the rider that is not wearing red or black helmet",
    "image": "val2017/000000507975.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the rider that is not wearing red or black helmet.",
    "solution": [
      361.96,
      23.07,
      451.36,
      101.44
    ],
    "normalized_solution": [
      566,
      48,
      705,
      211
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 425,
    "normal_caption": "the person who is holding a camera and carrying a green bag",
    "image": "val2017/000000338304.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is holding a camera and carrying a green bag.",
    "solution": [
      0.42,
      298.6,
      101.52,
      488.25
    ],
    "normalized_solution": [
      1,
      467,
      239,
      763
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": true,
      "distractors": "13"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 322,
    "width": 500,
    "normal_caption": "the traffic light with an arrow that is not pointing to the right",
    "image": "val2017/000000555050.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the traffic light with an arrow that is not pointing to the right.",
    "solution": [
      5.1,
      50.72,
      36.13,
      132.82999999999998
    ],
    "normalized_solution": [
      10,
      158,
      72,
      413
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 332,
    "normal_caption": "the second cow next to the cow with the least amount of brown",
    "image": "val2017/000000206135.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second cow next to the cow with the least amount of brown.",
    "solution": [
      172.18,
      302.22,
      233.89000000000001,
      439.78000000000003
    ],
    "normalized_solution": [
      519,
      604,
      704,
      880
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the bottle with a white top that is closest to the red bottle",
    "image": "val2017/000000465129.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle with a white top that is closest to the red bottle.",
    "solution": [
      543.74,
      335.07,
      560.86,
      366.53
    ],
    "normalized_solution": [
      850,
      698,
      876,
      764
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the bottle that is not foil-wrapped and is located on the first shelf from the top",
    "image": "val2017/000000506310.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle that is not foil-wrapped and is located on the first shelf from the top.",
    "solution": [
      1.46,
      76.32,
      39.76,
      241.29
    ],
    "normalized_solution": [
      2,
      180,
      62,
      568
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 426,
    "normal_caption": "the spinning chair that is closest to the wine bottle",
    "image": "val2017/000000519569.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the spinning chair that is closest to the wine bottle.",
    "solution": [
      126.4,
      391.5,
      248.52,
      615.54
    ],
    "normalized_solution": [
      297,
      612,
      583,
      962
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 375,
    "normal_caption": "the man who is blow drying his hair using the hair drier",
    "image": "val2017/000000178028.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man who is blow drying his hair using the hair drier.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": false,
      "distractors": "7"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 612,
    "width": 612,
    "normal_caption": "the cup on the counter that is mostly covered",
    "image": "val2017/000000290768.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cup on the counter that is mostly covered.",
    "solution": [
      152.34,
      189.47,
      170.51,
      258.27
    ],
    "normalized_solution": [
      249,
      310,
      279,
      422
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the ceramic bowl that is empty",
    "image": "val2017/000000182611.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the ceramic bowl that is empty.",
    "solution": [
      136.4,
      537.44,
      185.67000000000002,
      581.34
    ],
    "normalized_solution": [
      284,
      840,
      387,
      908
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "occluded": true,
      "distractors": "10"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 429,
    "normal_caption": "the person that is not wearing a uniform and is blocked by the person who is wearing a hat",
    "image": "val2017/000000228214.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person that is not wearing a uniform and is blocked by the person who is wearing a hat.",
    "solution": [
      287.84,
      475.7,
      406.40999999999997,
      640
    ],
    "normalized_solution": [
      671,
      743,
      947,
      1000
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the first toothbrush from the right side that is not blue",
    "image": "val2017/000000293390.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the first toothbrush from the right side that is not blue.",
    "solution": [
      494.62,
      11.04,
      502.18,
      49.46
    ],
    "normalized_solution": [
      773,
      23,
      785,
      103
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 375,
    "normal_caption": "the smallest bottle without a blue or green cap",
    "image": "val2017/000000384808.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the smallest bottle without a blue or green cap.",
    "solution": [
      48.91,
      268.67,
      63.449999999999996,
      325.36
    ],
    "normalized_solution": [
      130,
      537,
      169,
      651
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the bottle that is not in the refrigerator and has blue writing on its label",
    "image": "val2017/000000425226.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle that is not in the refrigerator and has blue writing on its label.",
    "solution": [
      299.65,
      2.09,
      321.41999999999996,
      44.269999999999996
    ],
    "normalized_solution": [
      624,
      3,
      670,
      69
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "6"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the bottle that is neither green nor has a rectangular cap",
    "image": "val2017/000000292005.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle that is neither green nor has a rectangular cap.",
    "solution": [
      201.81,
      453.48,
      220.65,
      508.34000000000003
    ],
    "normalized_solution": [
      420,
      709,
      460,
      794
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 640,
    "normal_caption": "the chair close to the stove and partially covered by the banana",
    "image": "val2017/000000480122.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair close to the stove and partially covered by the banana.",
    "solution": [
      217.57,
      359.3,
      294.26,
      430.21000000000004
    ],
    "normalized_solution": [
      340,
      561,
      460,
      672
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 478,
    "width": 640,
    "normal_caption": "the partially empty spray bottle with green liquid",
    "image": "val2017/000000197796.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the partially empty spray bottle with green liquid.",
    "solution": [
      312.48,
      57.63,
      337.43,
      155.96
    ],
    "normalized_solution": [
      488,
      121,
      527,
      326
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the pink cup on the second shelf from the top",
    "image": "val2017/000000481386.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the pink cup on the second shelf from the top.",
    "solution": [
      287.43,
      135.07,
      311.46000000000004,
      160.73
    ],
    "normalized_solution": [
      673,
      211,
      729,
      251
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "10"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the white ceramic bowl that is not on the counter",
    "image": "val2017/000000397133.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white ceramic bowl that is not on the counter.",
    "solution": [
      157.2,
      114.15,
      175.06,
      129.97
    ],
    "normalized_solution": [
      246,
      267,
      274,
      304
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the red bottle that is not located on the first shelf from the top",
    "image": "val2017/000000173302.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the red bottle that is not located on the first shelf from the top.",
    "solution": [
      435.32,
      178.03,
      442.81,
      191.89
    ],
    "normalized_solution": [
      680,
      419,
      692,
      452
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the tall bottle that is closest to the stove",
    "image": "val2017/000000523100.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the tall bottle that is closest to the stove.",
    "solution": [
      153.77,
      86.61,
      187.13,
      178.3
    ],
    "normalized_solution": [
      320,
      135,
      390,
      279
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 396,
    "width": 640,
    "normal_caption": "the woman who is wearing pink clothing and not smiling",
    "image": "val2017/000000084241.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the woman who is wearing pink clothing and not smiling.",
    "solution": [
      198.89,
      23.16,
      284.51,
      289.42
    ],
    "normalized_solution": [
      311,
      58,
      445,
      731
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the bottle behind the stove with yellow and red wrapping",
    "image": "val2017/000000074209.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle behind the stove with yellow and red wrapping.",
    "solution": [
      171.43,
      197.48,
      181.38,
      223.79
    ],
    "normalized_solution": [
      268,
      411,
      283,
      466
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the spoon inside the glass cup filled with water",
    "image": "val2017/000000239627.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the spoon inside the glass cup filled with water.",
    "solution": [
      425.77,
      173.22,
      501.2,
      248.64
    ],
    "normalized_solution": [
      665,
      406,
      783,
      582
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 478,
    "width": 640,
    "normal_caption": "a hand soap on the bathroom counter next to a pile of paper towels",
    "image": "val2017/000000195165.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a hand soap on the bathroom counter next to a pile of paper towels.",
    "solution": [
      329.8,
      263.35,
      347.95,
      312.64000000000004
    ],
    "normalized_solution": [
      515,
      551,
      544,
      654
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "10"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 640,
    "normal_caption": "the reflection in the mirror of a cup not containing a toothbrush",
    "image": "val2017/000000492878.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the reflection in the mirror of a cup not containing a toothbrush.",
    "solution": [
      53.06,
      77.26,
      182.38,
      282.86
    ],
    "normalized_solution": [
      83,
      121,
      285,
      442
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 461,
    "width": 614,
    "normal_caption": "the metal pot on the left stove",
    "image": "val2017/000000175364.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the metal pot on the left stove.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "9"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person who is neither facing the camera nor wearing a brown jacket",
    "image": "val2017/000000438774.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is neither facing the camera nor wearing a brown jacket.",
    "solution": [
      333.68,
      51.59,
      458.49,
      382.25
    ],
    "normalized_solution": [
      521,
      121,
      716,
      899
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a plastic bottle without a label",
    "image": "val2017/000000485424.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a plastic bottle without a label.",
    "solution": [
      50.52,
      237.88,
      113.97,
      315.43
    ],
    "normalized_solution": [
      79,
      496,
      178,
      657
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 464,
    "width": 640,
    "normal_caption": "a red bowl that is not on the counter nor the stove",
    "image": "val2017/000000530836.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a red bowl that is not on the counter nor the stove.",
    "solution": [
      0,
      190.59,
      30.24,
      209.08
    ],
    "normalized_solution": [
      0,
      411,
      47,
      451
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "6"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a woman wearing sandals",
    "image": "val2017/000000177934.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a woman wearing sandals.",
    "solution": [
      352.76,
      154.48,
      405.12,
      338.5
    ],
    "normalized_solution": [
      551,
      322,
      633,
      705
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the bottle with a black cap, second from the left",
    "image": "val2017/000000040471.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle with a black cap, second from the left.",
    "solution": [
      309.15,
      323.63,
      317.90999999999997,
      339.51
    ],
    "normalized_solution": [
      724,
      506,
      745,
      530
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 446,
    "width": 640,
    "normal_caption": "a bowl on a metal wall-mounted open cabinet that is not stacked",
    "image": "val2017/000000455597.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a bowl on a metal wall-mounted open cabinet that is not stacked.",
    "solution": [
      182.03,
      164.87,
      209.75,
      174.99
    ],
    "normalized_solution": [
      284,
      370,
      328,
      392
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 375,
    "normal_caption": "the second bottle from the right on the kitchen countertop",
    "image": "val2017/000000308799.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second bottle from the right on the kitchen countertop.",
    "solution": [
      243.36,
      224.27,
      253.26000000000002,
      254.91000000000003
    ],
    "normalized_solution": [
      649,
      449,
      675,
      510
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the plant that is not on the windowsill and is located on the right side",
    "image": "val2017/000000045229.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the plant that is not on the windowsill and is located on the right side.",
    "solution": [
      348.72,
      388.45,
      380.18,
      423.94
    ],
    "normalized_solution": [
      545,
      809,
      594,
      883
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "8"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a pot on the stovetop next to the coffee machine",
    "image": "val2017/000000109976.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a pot on the stovetop next to the coffee machine.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 424,
    "width": 640,
    "normal_caption": "a black chair that doesn't have any object on it and has a backrest",
    "image": "val2017/000000441247.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a black chair that doesn't have any object on it and has a backrest.",
    "solution": [
      221.7,
      220.73,
      301.35,
      347.73
    ],
    "normalized_solution": [
      346,
      521,
      471,
      820
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 361,
    "width": 640,
    "normal_caption": "a stack of two books that is not placed next to the chair",
    "image": "val2017/000000093437.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a stack of two books that is not placed next to the chair.",
    "solution": [
      490.55,
      212.2,
      523.83,
      222.91
    ],
    "normalized_solution": [
      766,
      588,
      818,
      617
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "a chair that is neither close to the wall nor closest to the camera",
    "image": "val2017/000000221708.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a chair that is neither close to the wall nor closest to the camera.",
    "solution": [
      210.25,
      255.88,
      285.67,
      424.44
    ],
    "normalized_solution": [
      438,
      400,
      595,
      663
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the chair farthest from the microwave",
    "image": "val2017/000000216497.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair farthest from the microwave.",
    "solution": [
      386.03,
      269.83,
      468.07,
      451.40999999999997
    ],
    "normalized_solution": [
      603,
      562,
      731,
      940
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the upper oven embedded in the white cabinet",
    "image": "val2017/000000458768.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the upper oven embedded in the white cabinet.",
    "solution": [
      408.36,
      206.98,
      428.23,
      252.88
    ],
    "normalized_solution": [
      638,
      485,
      669,
      592
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the middle chair among chairs with green mat",
    "image": "val2017/000000543047.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the middle chair among chairs with green mat.",
    "solution": [
      397.23,
      177.89,
      419.54,
      206.7
    ],
    "normalized_solution": [
      621,
      371,
      656,
      431
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the middle chair at the dining table not on the sofa side",
    "image": "val2017/000000472046.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the middle chair at the dining table not on the sofa side.",
    "solution": [
      70.16,
      256.44,
      100.33,
      277.29
    ],
    "normalized_solution": [
      110,
      603,
      157,
      652
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 408,
    "normal_caption": "a person holding a green umbrella walking away from the camera",
    "image": "val2017/000000045596.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person holding a green umbrella walking away from the camera.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "7"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 425,
    "normal_caption": "a bicycle without a basket that is partially blocked by a yellow pole",
    "image": "val2017/000000259830.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a bicycle without a basket that is partially blocked by a yellow pole.",
    "solution": [
      338.58,
      426.67,
      425,
      579.44
    ],
    "normalized_solution": [
      797,
      667,
      1000,
      905
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car next to the car with its door open",
    "image": "val2017/000000357737.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car next to the car with its door open.",
    "solution": [
      576.36,
      88.04,
      583.4300000000001,
      91.39
    ],
    "normalized_solution": [
      901,
      183,
      912,
      190
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "a bicycle that is not placed on the ground",
    "image": "val2017/000000055022.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a bicycle that is not placed on the ground.",
    "solution": [
      245.25,
      0.76,
      281.89,
      80.16000000000001
    ],
    "normalized_solution": [
      511,
      1,
      587,
      125
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "6"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a person who is neither standing, sitting, walking, nor skateboarding",
    "image": "val2017/000000087038.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person who is neither standing, sitting, walking, nor skateboarding.",
    "solution": [
      257.85,
      224.48,
      301.98,
      321.48
    ],
    "normalized_solution": [
      403,
      468,
      472,
      670
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "13"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 543,
    "width": 640,
    "normal_caption": "a person who is not on the sidewalk and is carrying a bag that is not blue",
    "image": "val2017/000000577932.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person who is not on the sidewalk and is carrying a bag that is not blue.",
    "solution": [
      231.84,
      233.37,
      314.82,
      492.06
    ],
    "normalized_solution": [
      362,
      430,
      492,
      906
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "10"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 335,
    "width": 500,
    "normal_caption": "a motorcycle facing toward the road with a red seat",
    "image": "val2017/000000356387.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a motorcycle facing toward the road with a red seat.",
    "solution": [
      216.26,
      220.98,
      312.12,
      308.39
    ],
    "normalized_solution": [
      433,
      660,
      624,
      921
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "a vehicle that has a backrest and does not have four wheels",
    "image": "val2017/000000441586.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a vehicle that has a backrest and does not have four wheels.",
    "solution": [
      395.66,
      146.02,
      426.92,
      224.5
    ],
    "normalized_solution": [
      618,
      344,
      667,
      528
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 485,
    "width": 640,
    "normal_caption": "a boat with a red top and a white hull",
    "image": "val2017/000000228436.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a boat with a red top and a white hull.",
    "solution": [
      287.59,
      138.45,
      356.13,
      167.37
    ],
    "normalized_solution": [
      449,
      285,
      556,
      345
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "occluded": false,
      "distractors": "12"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "a person next to a bicycle lying on the ground who is not making a phone call",
    "image": "val2017/000000414510.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person next to a bicycle lying on the ground who is not making a phone call.",
    "solution": [
      54.6,
      267.4,
      134.32,
      388.39
    ],
    "normalized_solution": [
      114,
      418,
      280,
      607
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "a bus moving toward the camera with blue on its front",
    "image": "val2017/000000210273.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a bus moving toward the camera with blue on its front.",
    "solution": [
      362.04,
      118.05,
      424.51,
      194.73000000000002
    ],
    "normalized_solution": [
      566,
      276,
      663,
      455
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": true,
      "distractors": "13"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a person standing at the doorway and eating something",
    "image": "val2017/000000507037.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person standing at the doorway and eating something.",
    "solution": [
      0,
      246.23,
      25.34,
      383.58
    ],
    "normalized_solution": [
      0,
      513,
      40,
      799
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "13"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the man wearing backpack to the left side of the red-shirt girl, not the boy",
    "image": "val2017/000000350122.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man wearing backpack to the left side of the red-shirt girl, not the boy.",
    "solution": [
      96.9,
      206.17,
      151.79000000000002,
      380.67999999999995
    ],
    "normalized_solution": [
      151,
      430,
      237,
      793
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "13"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the one standing above stairs, not near bike or motor",
    "image": "val2017/000000038829.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the one standing above stairs, not near bike or motor.",
    "solution": [
      392.03,
      60.98,
      418.64,
      133.46
    ],
    "normalized_solution": [
      613,
      143,
      654,
      313
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 433,
    "normal_caption": "the black motor on the front, close to the red motor, not close to the green bike",
    "image": "val2017/000000291634.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the black motor on the front, close to the red motor, not close to the green bike.",
    "solution": [
      17,
      224.07,
      168.41,
      384.39
    ],
    "normalized_solution": [
      39,
      350,
      389,
      601
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 481,
    "width": 640,
    "normal_caption": "the third one from the back of the boat",
    "image": "val2017/000000395180.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the third one from the back of the boat.",
    "solution": [
      477.48,
      189.92,
      493.46000000000004,
      203.54999999999998
    ],
    "normalized_solution": [
      746,
      395,
      771,
      423
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 333,
    "width": 500,
    "normal_caption": "the motor close to the woman's red motor",
    "image": "val2017/000000226417.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the motor close to the woman's red motor.",
    "solution": [
      194.7,
      197.58,
      231.32999999999998,
      262.70000000000005
    ],
    "normalized_solution": [
      389,
      593,
      463,
      789
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 333,
    "normal_caption": "The light near the '24 hour' sign with only three signals",
    "image": "val2017/000000301376.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: The light near the '24 hour' sign with only three signals.",
    "solution": [
      83.29,
      94.92,
      111.14000000000001,
      152.57
    ],
    "normalized_solution": [
      250,
      190,
      334,
      305
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the guy on the right side, red shirt, with no hat",
    "image": "val2017/000000455624.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the guy on the right side, red shirt, with no hat.",
    "solution": [
      614.54,
      143.23,
      640,
      206.35999999999999
    ],
    "normalized_solution": [
      960,
      335,
      1000,
      483
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 453,
    "width": 640,
    "normal_caption": "red cat on the blue motor",
    "image": "val2017/000000139099.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: red cat on the blue motor.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "23"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the girl who is not a reflection in the glass",
    "image": "val2017/000000292456.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the girl who is not a reflection in the glass.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 400,
    "width": 600,
    "normal_caption": "the guy closest to the motor with a black box in the back",
    "image": "val2017/000000534605.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the guy closest to the motor with a black box in the back.",
    "solution": [
      283.68,
      97.14,
      323.75,
      216.22
    ],
    "normalized_solution": [
      473,
      243,
      540,
      541
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the light with green signal on",
    "image": "val2017/000000178982.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the light with green signal on.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 333,
    "normal_caption": "the motorcycle being leaned on by the person in the striped shirt",
    "image": "val2017/000000574702.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the motorcycle being leaned on by the person in the striped shirt.",
    "solution": [
      85.46,
      215.72,
      119.69,
      302.77
    ],
    "normalized_solution": [
      257,
      431,
      359,
      606
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 420,
    "width": 640,
    "normal_caption": "the guy on the wider motor, and his clothes is orange",
    "image": "val2017/000000246963.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the guy on the wider motor, and his clothes is orange.",
    "solution": [
      167.62,
      151.24,
      233.54000000000002,
      242.58
    ],
    "normalized_solution": [
      262,
      360,
      365,
      578
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 403,
    "width": 640,
    "normal_caption": "the kite that flies the third highest in the middle",
    "image": "val2017/000000345027.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the kite that flies the third highest in the middle.",
    "solution": [
      310.6,
      183.89,
      326.46000000000004,
      189.20999999999998
    ],
    "normalized_solution": [
      485,
      456,
      510,
      470
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "6"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the book with cover of same color as the page",
    "image": "val2017/000000200839.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the book with cover of same color as the page.",
    "solution": [
      143.97,
      240.83,
      176.81,
      268.65000000000003
    ],
    "normalized_solution": [
      225,
      502,
      276,
      560
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person on the right side of the row with no one wearing hat but one wearing hairband",
    "image": "val2017/000000057672.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the right side of the row with no one wearing hat but one wearing hairband.",
    "solution": [
      417.03,
      191.5,
      484.16999999999996,
      289.63
    ],
    "normalized_solution": [
      652,
      399,
      757,
      603
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the guy with brown jeans, black hoodie and a suitcase walking in the street",
    "image": "val2017/000000138639.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the guy with brown jeans, black hoodie and a suitcase walking in the street.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "4",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "14"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the man between the yellow-coat guy and the blue-shirt woman, hair not yellow",
    "image": "val2017/000000078748.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man between the yellow-coat guy and the blue-shirt woman, hair not yellow.",
    "solution": [
      244.74,
      13.38,
      289.17,
      111.38
    ],
    "normalized_solution": [
      382,
      28,
      452,
      232
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 336,
    "width": 500,
    "normal_caption": "the white car next to the red car, in front of the car that's tilted to the side",
    "image": "val2017/000000111086.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white car next to the red car, in front of the car that's tilted to the side.",
    "solution": [
      126.86,
      201,
      156.21,
      232.27
    ],
    "normalized_solution": [
      254,
      598,
      312,
      691
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "11"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 569,
    "width": 640,
    "normal_caption": "the man with glasses, not in the car nor driving the motor",
    "image": "val2017/000000461751.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man with glasses, not in the car nor driving the motor.",
    "solution": [
      464.34,
      120.29,
      640,
      569
    ],
    "normalized_solution": [
      726,
      211,
      1000,
      1000
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "yellow taxi, not on the slope, close to the big bus",
    "image": "val2017/000000336232.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: yellow taxi, not on the slope, close to the big bus.",
    "solution": [
      412.46,
      107.39,
      471.75,
      156.45
    ],
    "normalized_solution": [
      644,
      251,
      737,
      366
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "13"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the man with shirt hair, sitting behind the long-hair guy",
    "image": "val2017/000000248334.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man with shirt hair, sitting behind the long-hair guy.",
    "solution": [
      469.42,
      186.72,
      487.43,
      221.01999999999998
    ],
    "normalized_solution": [
      939,
      498,
      975,
      589
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "8"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the one not inside the bus, but close to the door",
    "image": "val2017/000000445834.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the one not inside the bus, but close to the door.",
    "solution": [
      424.1,
      180.42,
      517.0500000000001,
      415.7
    ],
    "normalized_solution": [
      663,
      423,
      808,
      974
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 425,
    "normal_caption": "the one with dark color cloth, not riding bike",
    "image": "val2017/000000472623.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the one with dark color cloth, not riding bike.",
    "solution": [
      125.81,
      239.86,
      152.76,
      305.90000000000003
    ],
    "normalized_solution": [
      296,
      375,
      359,
      478
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "the red-shirt person, with no hat on",
    "image": "val2017/000000244833.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the red-shirt person, with no hat on.",
    "solution": [
      547.17,
      12.75,
      613.73,
      119.36
    ],
    "normalized_solution": [
      855,
      30,
      959,
      279
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 361,
    "width": 640,
    "normal_caption": "the bag carried by the person with a purple umbrella and pulling a small suitcase",
    "image": "val2017/000000191845.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bag carried by the person with a purple umbrella and pulling a small suitcase.",
    "solution": [
      436.05,
      217.51,
      466.85,
      254.57999999999998
    ],
    "normalized_solution": [
      681,
      603,
      729,
      705
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 470,
    "width": 640,
    "normal_caption": "the guy on the second row, not near the ones with umbrella",
    "image": "val2017/000000267537.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the guy on the second row, not near the ones with umbrella.",
    "solution": [
      498.75,
      0.28,
      635.88,
      234.72
    ],
    "normalized_solution": [
      779,
      1,
      994,
      499
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "9"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 421,
    "normal_caption": "the girl next to the man wearing backpack pointing somewhere, on the stairs",
    "image": "val2017/000000370486.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the girl next to the man wearing backpack pointing somewhere, on the stairs.",
    "solution": [
      41.32,
      53.59,
      76.08,
      113.12
    ],
    "normalized_solution": [
      98,
      84,
      181,
      177
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "13"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the chair only able to be seen through the middle window, on the left",
    "image": "val2017/000000333745.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair only able to be seen through the middle window, on the left.",
    "solution": [
      150.39,
      33.71,
      206.79,
      95.23
    ],
    "normalized_solution": [
      352,
      53,
      484,
      149
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "5"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person on the right side from the single man's perspective, not holding beer",
    "image": "val2017/000000074058.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the right side from the single man's perspective, not holding beer.",
    "solution": [
      27.67,
      158.53,
      102.07000000000001,
      334.65
    ],
    "normalized_solution": [
      43,
      371,
      159,
      784
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the bed no one sitting on, and not the upper bed",
    "image": "val2017/000000393569.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bed no one sitting on, and not the upper bed.",
    "solution": [
      452.97,
      169.19,
      592.4300000000001,
      322.7
    ],
    "normalized_solution": [
      708,
      352,
      926,
      672
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 428,
    "normal_caption": "the cup facing right, not the rightmost one",
    "image": "val2017/000000292060.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cup facing right, not the rightmost one.",
    "solution": [
      271.28,
      271.82,
      296.09,
      298.78999999999996
    ],
    "normalized_solution": [
      634,
      425,
      692,
      467
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the white cup, beside the sink",
    "image": "val2017/000000437898.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white cup, beside the sink.",
    "solution": [
      65.61,
      228.82,
      82.41,
      249.57999999999998
    ],
    "normalized_solution": [
      103,
      536,
      129,
      584
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the green cup on top of an array of glasses, not upright",
    "image": "val2017/000000052996.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the green cup on top of an array of glasses, not upright.",
    "solution": [
      118.01,
      269.13,
      151.59,
      294.07
    ],
    "normalized_solution": [
      184,
      632,
      237,
      690
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "the knife beside the pineapple, third from the left",
    "image": "val2017/000000078266.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the knife beside the pineapple, third from the left.",
    "solution": [
      284.1,
      200.63,
      290.89000000000004,
      209.12
    ],
    "normalized_solution": [
      444,
      469,
      455,
      489
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the bowl on the same cabinet shelf as the small yellow object",
    "image": "val2017/000000156278.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bowl on the same cabinet shelf as the small yellow object.",
    "solution": [
      278.52,
      305.12,
      336.25,
      333.28000000000003
    ],
    "normalized_solution": [
      435,
      718,
      525,
      784
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "annotation_id": "38829_1742593294302",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person standing above stairs, not near any bikes or motorcycles",
    "image": "val2017/000000038829.jpg",
    "file_name": "000000038829.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person standing above stairs, not near any bikes or motorcycles.",
    "solution": [
      392.03,
      60.98,
      418.64,
      133.46
    ],
    "normalized_solution": [
      613,
      143,
      654,
      313
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "annotation_id": "309391_1742594615011",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 384,
    "width": 640,
    "normal_caption": "a black car that is not moving away from the camera",
    "image": "val2017/000000309391.jpg",
    "file_name": "000000309391.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a black car that is not moving away from the camera.",
    "solution": [
      311.42,
      189.69,
      364.25,
      213.92
    ],
    "normalized_solution": [
      487,
      494,
      569,
      557
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "7"
    }
  },
  {
    "annotation_id": "122166_1742595465272",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car in front of a black Audi sedan",
    "image": "val2017/000000122166.jpg",
    "file_name": "000000122166.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car in front of a black Audi sedan.",
    "solution": [
      158.18,
      264.32,
      323.15999999999997,
      417.38
    ],
    "normalized_solution": [
      247,
      551,
      505,
      870
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    }
  },
  {
    "annotation_id": "122166_1742595533439",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car in front of a black Audi sedan",
    "image": "val2017/000000122166.jpg",
    "file_name": "000000122166.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car in front of a black Audi sedan.",
    "solution": [
      158.18,
      264.32,
      323.15999999999997,
      417.38
    ],
    "normalized_solution": [
      247,
      551,
      505,
      870
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    }
  },
  {
    "annotation_id": "241319_1742939549372",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 476,
    "width": 640,
    "normal_caption": "the reflection of the toothbrush that is not white",
    "image": "val2017/000000241319.jpg",
    "file_name": "000000241319.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the reflection of the toothbrush that is not white.",
    "solution": [
      196.75,
      151.84,
      239.71,
      239.18
    ],
    "normalized_solution": [
      307,
      319,
      375,
      502
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "annotation_id": "89556_1742939838888",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car parked next to a fire hydrant, which is not an sedan",
    "image": "val2017/000000089556.jpg",
    "file_name": "000000089556.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car parked next to a fire hydrant, which is not an sedan.",
    "solution": [
      321.15,
      127.77,
      627.64,
      328.29
    ],
    "normalized_solution": [
      502,
      266,
      981,
      684
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "13"
    }
  },
  {
    "annotation_id": "292997_1742940912411",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the lower traffic light mounted on the pole struck by a car",
    "image": "val2017/000000292997.jpg",
    "file_name": "000000292997.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the lower traffic light mounted on the pole struck by a car.",
    "solution": [
      479,
      227,
      498,
      261
    ],
    "normalized_solution": [
      748,
      473,
      778,
      544
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "annotation_id": "295809_1742963403240",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 512,
    "width": 640,
    "normal_caption": "the traffic light on the pole next to the black car on the left side, located at the upper left corner",
    "image": "val2017/000000295809.jpg",
    "file_name": "000000295809.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the traffic light on the pole next to the black car on the left side, located at the upper left corner.",
    "solution": [
      71.87,
      38.93,
      81.72,
      64.25999999999999
    ],
    "normalized_solution": [
      112,
      76,
      128,
      126
    ],
    "categories": {
      "empty_case": false,
      "hops": "5",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "9"
    }
  },
  {
    "annotation_id": "295809_1742963434580",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 512,
    "width": 640,
    "normal_caption": "the traffic light on the pole next to the black car on the left side, located at the upper right corner",
    "image": "val2017/000000295809.jpg",
    "file_name": "000000295809.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the traffic light on the pole next to the black car on the left side, located at the upper right corner.",
    "solution": [
      82.52,
      35.19,
      94.11,
      65.32
    ],
    "normalized_solution": [
      129,
      69,
      147,
      128
    ],
    "categories": {
      "empty_case": false,
      "hops": "5",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "9"
    }
  },
  {
    "annotation_id": "227511_1743028736038",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the parked car facing away from the camera, nearest to the silver car driving towards the camera",
    "image": "val2017/000000227511.jpg",
    "file_name": "000000227511.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the parked car facing away from the camera, nearest to the silver car driving towards the camera.",
    "solution": [
      182.65,
      258.59,
      195.41,
      267.9
    ],
    "normalized_solution": [
      365,
      690,
      391,
      714
    ],
    "categories": {
      "empty_case": false,
      "hops": "5",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "annotation_id": "418696_1743028923790",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the green traffic light hanging from a wire above the intersection, with the church tower behind it",
    "image": "val2017/000000418696.jpg",
    "file_name": "000000418696.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the green traffic light hanging from a wire above the intersection, with the church tower behind it.",
    "solution": [
      348.6,
      172.76,
      358.79,
      182.04999999999998
    ],
    "normalized_solution": [
      545,
      405,
      561,
      426
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "5"
    }
  },
  {
    "annotation_id": "480944_1743029152077",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the sedan in front of the blue truck",
    "image": "val2017/000000480944.jpg",
    "file_name": "000000480944.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the sedan in front of the blue truck.",
    "solution": [
      132.62,
      356.49,
      225.3,
      392.09000000000003
    ],
    "normalized_solution": [
      276,
      557,
      469,
      613
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    }
  },
  {
    "annotation_id": "480944_1743029418875",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the wagon in front of the red truck",
    "image": "val2017/000000480944.jpg",
    "file_name": "000000480944.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the wagon in front of the red truck.",
    "solution": [
      21.07,
      354.61,
      123.52000000000001,
      398.21000000000004
    ],
    "normalized_solution": [
      44,
      554,
      257,
      622
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "6"
    }
  },
  {
    "annotation_id": "412531_1743029524744",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the white car partially obscured by the bush",
    "image": "val2017/000000412531.jpg",
    "file_name": "000000412531.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white car partially obscured by the bush.",
    "solution": [
      333.89,
      280.56,
      389.08,
      327.04
    ],
    "normalized_solution": [
      522,
      585,
      608,
      681
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "annotation_id": "183709_1743029836053",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person wearing a dark jacket and carrying a shoulder bag",
    "image": "val2017/000000183709.jpg",
    "file_name": "000000183709.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a dark jacket and carrying a shoulder bag.",
    "solution": [
      215.07,
      223.54,
      232,
      277.55
    ],
    "normalized_solution": [
      448,
      349,
      483,
      434
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    }
  },
  {
    "annotation_id": "183709_1743029968398",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person standing on the traffic island waiting for the traffic light, wearing a white jacket",
    "image": "val2017/000000183709.jpg",
    "file_name": "000000183709.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person standing on the traffic island waiting for the traffic light, wearing a white jacket.",
    "solution": [
      215.07,
      223.54,
      232,
      277.55
    ],
    "normalized_solution": [
      448,
      349,
      483,
      434
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    }
  },
  {
    "annotation_id": "301135_1743032969026",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 428,
    "normal_caption": "the person who is neither standing nor lying on the bench, wearing sunglasses and holding a bag",
    "image": "val2017/000000301135.jpg",
    "file_name": "000000301135.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is neither standing nor lying on the bench, wearing sunglasses and holding a bag.",
    "solution": [
      206.97,
      396,
      278.90999999999997,
      541.22
    ],
    "normalized_solution": [
      484,
      619,
      652,
      846
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    }
  },
  {
    "annotation_id": "301135_1743033605992",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 428,
    "normal_caption": "the handbag held by the person sitting on the same bench as the person wearing long blue jeans",
    "image": "val2017/000000301135.jpg",
    "file_name": "000000301135.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the handbag held by the person sitting on the same bench as the person wearing long blue jeans.",
    "solution": [
      126.87,
      422.93,
      164.79000000000002,
      442.27
    ],
    "normalized_solution": [
      296,
      661,
      385,
      691
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "annotation_id": "199771_1743034817144",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person wearing a black hat and plastic gloves, with a hand resting on the table",
    "image": "val2017/000000199771.jpg",
    "file_name": "000000199771.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a black hat and plastic gloves, with a hand resting on the table.",
    "solution": [
      244.85,
      104.07,
      343.43,
      270.86
    ],
    "normalized_solution": [
      383,
      245,
      537,
      637
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "9"
    }
  },
  {
    "annotation_id": "504074_1743035255690",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the chair occupied by the person who does not have a laptop on the lap",
    "image": "val2017/000000504074.jpg",
    "file_name": "000000504074.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair occupied by the person who does not have a laptop on the lap.",
    "solution": [
      41,
      138,
      191,
      349
    ],
    "normalized_solution": [
      64,
      323,
      298,
      817
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "annotation_id": "298396_1743035742441",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the third knife from the top, hanging horizontally on the left-side wall",
    "image": "val2017/000000298396.jpg",
    "file_name": "000000298396.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the third knife from the top, hanging horizontally on the left-side wall.",
    "solution": [
      148.81,
      173.81,
      179.17000000000002,
      181.57
    ],
    "normalized_solution": [
      233,
      362,
      280,
      378
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "11"
    }
  },
  {
    "annotation_id": "298396_1743035848865",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the second knife from the top, hanging horizontally on the left-side wall",
    "image": "val2017/000000298396.jpg",
    "file_name": "000000298396.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second knife from the top, hanging horizontally on the left-side wall.",
    "solution": [
      149.15,
      159.75,
      177.64000000000001,
      166.65
    ],
    "normalized_solution": [
      233,
      333,
      278,
      347
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "11"
    }
  },
  {
    "annotation_id": "298396_1743035931591",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the fifth knife from the top, hanging horizontally on the left-side wall",
    "image": "val2017/000000298396.jpg",
    "file_name": "000000298396.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the fifth knife from the top, hanging horizontally on the left-side wall.",
    "solution": [
      154.43,
      189.16,
      173.88,
      191.64
    ],
    "normalized_solution": [
      241,
      394,
      272,
      399
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    }
  },
  {
    "annotation_id": "479126_1743035982786",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the chair that is sitted by a person with a laptop on the lap",
    "image": "val2017/000000479126.jpg",
    "file_name": "000000479126.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair that is sitted by a person with a laptop on the lap.",
    "solution": [
      519.32,
      266.88,
      640,
      421.71000000000004
    ],
    "normalized_solution": [
      811,
      625,
      1000,
      988
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "annotation_id": "34873_1743037312583",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "one of the two chairs with identical backrest patterns and closer to the corner of the two walls",
    "image": "val2017/000000034873.jpg",
    "file_name": "000000034873.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: one of the two chairs with identical backrest patterns and closer to the corner of the two walls.",
    "solution": [
      482.45,
      169.57,
      528.5,
      219.01999999999998
    ],
    "normalized_solution": [
      754,
      353,
      826,
      456
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "annotation_id": "469192_1743038252862",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the kite located directly above the kite shaped like a green gecko",
    "image": "val2017/000000469192.jpg",
    "file_name": "000000469192.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the kite located directly above the kite shaped like a green gecko.",
    "solution": [
      508.69,
      50.06,
      549.5,
      70.32000000000001
    ],
    "normalized_solution": [
      795,
      104,
      859,
      147
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "12"
    }
  },
  {
    "annotation_id": "567197_1743038636134",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 407,
    "width": 500,
    "normal_caption": "the car behind the one with its wheels turned right, facing towards the camera",
    "image": "val2017/000000567197.jpg",
    "file_name": "000000567197.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car behind the one with its wheels turned right, facing towards the camera.",
    "solution": [
      45.85,
      302.29,
      72.87,
      328.40000000000003
    ],
    "normalized_solution": [
      92,
      743,
      146,
      807
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "annotation_id": "492362_1743038892795",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the middle hotdog image on the food cart beneath the halal food sign",
    "image": "val2017/000000492362.jpg",
    "file_name": "000000492362.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the middle hotdog image on the food cart beneath the halal food sign.",
    "solution": [
      80.23,
      224.22,
      121.35,
      245.95
    ],
    "normalized_solution": [
      188,
      350,
      284,
      384
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "annotation_id": "78404_1743039916102",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 350,
    "width": 500,
    "normal_caption": "the women sitting on the right side of the chair",
    "image": "val2017/000000078404.jpg",
    "file_name": "000000078404.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the women sitting on the right side of the chair.",
    "solution": [
      218.06,
      9.28,
      405.3,
      306.34999999999997
    ],
    "normalized_solution": [
      436,
      27,
      811,
      875
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "annotation_id": "173799_1743040072713",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 524,
    "width": 640,
    "normal_caption": "the elephant standing on higher terrain behind the person who is not wearing a hat",
    "image": "val2017/000000173799.jpg",
    "file_name": "000000173799.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the elephant standing on higher terrain behind the person who is not wearing a hat.",
    "solution": [
      68.32,
      132.5,
      141,
      189.61
    ],
    "normalized_solution": [
      107,
      253,
      220,
      362
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "13"
    }
  },
  {
    "annotation_id": "110042_1743041705366",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 425,
    "normal_caption": "the person who is not in a tent, facing away from the camera",
    "image": "val2017/000000110042.jpg",
    "file_name": "000000110042.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is not in a tent, facing away from the camera.",
    "solution": [
      81.58,
      105.96,
      112.33,
      206.42
    ],
    "normalized_solution": [
      192,
      166,
      264,
      323
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "4"
    }
  },
  {
    "annotation_id": "580294_1743041892447",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 443,
    "width": 640,
    "normal_caption": "the empty plate that is not being used as a lid to cover the pot",
    "image": "val2017/000000580294.jpg",
    "file_name": "000000580294.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the empty plate that is not being used as a lid to cover the pot.",
    "solution": [
      389,
      123,
      420,
      193
    ],
    "normalized_solution": [
      608,
      278,
      656,
      436
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "annotation_id": "16249_1743042113421",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 365,
    "width": 500,
    "normal_caption": "the empty bench next to the bench occupied by a person reading a newspaper",
    "image": "val2017/000000016249.jpg",
    "file_name": "000000016249.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the empty bench next to the bench occupied by a person reading a newspaper.",
    "solution": [
      222.9,
      199.99,
      286.01,
      312.73
    ],
    "normalized_solution": [
      446,
      548,
      572,
      857
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    }
  },
  {
    "annotation_id": "16249_1743196211645",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 365,
    "width": 500,
    "normal_caption": "person sitting without glasses and with white hair",
    "image": "val2017/000000016249.jpg",
    "file_name": "000000016249.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person sitting without glasses and with white hair.",
    "solution": [
      314.46,
      98.67,
      454.03999999999996,
      281.57
    ],
    "normalized_solution": [
      629,
      270,
      908,
      771
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "annotation_id": "346703_1743196558721",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 550,
    "normal_caption": "an incomplete cake without star-shaped decoration",
    "image": "val2017/000000346703.jpg",
    "file_name": "000000346703.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: an incomplete cake without star-shaped decoration.",
    "solution": [
      207.57,
      552.07,
      376.22,
      640
    ],
    "normalized_solution": [
      377,
      863,
      684,
      1000
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "annotation_id": "346703_1743196756464",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 550,
    "normal_caption": "the person not holding a spoon, wearing white clothing and no hat",
    "image": "val2017/000000346703.jpg",
    "file_name": "000000346703.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person not holding a spoon, wearing white clothing and no hat.",
    "solution": [
      186.64,
      376.36,
      336.40999999999997,
      583.1600000000001
    ],
    "normalized_solution": [
      339,
      588,
      612,
      911
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "6"
    }
  },
  {
    "annotation_id": "346703_1743196973149",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 550,
    "normal_caption": "the person on the left hand side of the person wearing a hat",
    "image": "val2017/000000346703.jpg",
    "file_name": "000000346703.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the left hand side of the person wearing a hat.",
    "solution": [
      316.19,
      129.38,
      549.66,
      366.81
    ],
    "normalized_solution": [
      575,
      202,
      999,
      573
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "6"
    }
  },
  {
    "annotation_id": "294350_1743197098773",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person wearing a hat and not facing the camera",
    "image": "val2017/000000294350.jpg",
    "file_name": "000000294350.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a hat and not facing the camera.",
    "solution": [
      70.03,
      126.77,
      130.69,
      161.13
    ],
    "normalized_solution": [
      109,
      298,
      204,
      379
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "6"
    }
  },
  {
    "annotation_id": "252219_1743197273559",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "the person walking not beneath an umbrella",
    "image": "val2017/000000252219.jpg",
    "file_name": "000000252219.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person walking not beneath an umbrella.",
    "solution": [
      9.79,
      167.06,
      131.73,
      393.51
    ],
    "normalized_solution": [
      15,
      390,
      206,
      919
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "annotation_id": "104572_1743260963696",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 419,
    "width": 640,
    "normal_caption": "the sink not in the mirror and closest to the paper towel dispenser",
    "image": "val2017/000000104572.jpg",
    "file_name": "000000104572.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the sink not in the mirror and closest to the paper towel dispenser.",
    "solution": [
      90.38,
      292.39,
      234.38,
      369.32
    ],
    "normalized_solution": [
      141,
      698,
      366,
      881
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "annotation_id": "283785_1743261209235",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 336,
    "width": 500,
    "normal_caption": "the teddy bear held by a person with a hat not facing the camera",
    "image": "val2017/000000283785.jpg",
    "file_name": "000000283785.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the teddy bear held by a person with a hat not facing the camera.",
    "solution": [
      47.64,
      204.77,
      89.64,
      239.76000000000002
    ],
    "normalized_solution": [
      95,
      609,
      179,
      714
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "5"
    }
  },
  {
    "annotation_id": "534664_1743261317008",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 404,
    "width": 640,
    "normal_caption": "the all brown leather suitcase with a tag on it",
    "image": "val2017/000000534664.jpg",
    "file_name": "000000534664.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the all brown leather suitcase with a tag on it.",
    "solution": [
      415.83,
      114.19,
      608.73,
      259.78
    ],
    "normalized_solution": [
      650,
      283,
      951,
      643
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    }
  },
  {
    "annotation_id": "555597_1743261397143",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 517,
    "width": 640,
    "normal_caption": "the white car closest to a truck",
    "image": "val2017/000000555597.jpg",
    "file_name": "000000555597.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white car closest to a truck.",
    "solution": [
      306.02,
      386.98,
      396.42999999999995,
      425.69
    ],
    "normalized_solution": [
      478,
      749,
      619,
      823
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    }
  },
  {
    "annotation_id": "276018_1743262502730",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 416,
    "normal_caption": "the person in blue jacket holding a grey doll",
    "image": "val2017/000000276018.jpg",
    "file_name": "000000276018.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in blue jacket holding a grey doll.",
    "solution": [
      142.56,
      254.04,
      258.8,
      635.11
    ],
    "normalized_solution": [
      343,
      397,
      622,
      992
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "9"
    }
  },
  {
    "annotation_id": "209613_1743262570421",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the dog facing the camera near a bush",
    "image": "val2017/000000209613.jpg",
    "file_name": "000000209613.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the dog facing the camera near a bush.",
    "solution": [
      168.52,
      182.74,
      201.58,
      212.66000000000003
    ],
    "normalized_solution": [
      263,
      428,
      315,
      498
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "2"
    }
  },
  {
    "annotation_id": "342367_1743262653518",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person sitting with a hat",
    "image": "val2017/000000342367.jpg",
    "file_name": "000000342367.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person sitting with a hat.",
    "solution": [
      411.24,
      277.76,
      547.94,
      425.63
    ],
    "normalized_solution": [
      643,
      579,
      856,
      887
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "2"
    }
  },
  {
    "annotation_id": "17627_1743519637856",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a white car driving past a black car",
    "image": "val2017/000000017627.jpg",
    "file_name": "000000017627.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a white car driving past a black car.",
    "solution": [
      264.65,
      235.3,
      375.21999999999997,
      302.59000000000003
    ],
    "normalized_solution": [
      414,
      490,
      586,
      630
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    }
  },
  {
    "annotation_id": "211674_1743519813208",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 406,
    "width": 640,
    "normal_caption": "the person wearing a white hat waving to the camera",
    "image": "val2017/000000211674.jpg",
    "file_name": "000000211674.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a white hat waving to the camera.",
    "solution": [
      376.96,
      11.12,
      417.76,
      45.07
    ],
    "normalized_solution": [
      589,
      27,
      653,
      111
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    }
  },
  {
    "annotation_id": "156071_1743520253598",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person wearing a white cowboy hat on the right hand side of a person in a red top",
    "image": "val2017/000000156071.jpg",
    "file_name": "000000156071.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a white cowboy hat on the right hand side of a person in a red top.",
    "solution": [
      227.55,
      101.84,
      299.63,
      251
    ],
    "normalized_solution": [
      356,
      212,
      468,
      523
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "13"
    }
  },
  {
    "annotation_id": "143556_1743520569040",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person wearing sunglasses riding a motorbike without a McDonald\u2019s sign on it",
    "image": "val2017/000000143556.jpg",
    "file_name": "000000143556.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing sunglasses riding a motorbike without a McDonald\u2019s sign on it.",
    "solution": [
      377.63,
      231.45,
      472.64,
      474.77
    ],
    "normalized_solution": [
      787,
      362,
      985,
      742
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    }
  },
  {
    "annotation_id": "7816_1743520727004",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person wearing a black top not facing the camera",
    "image": "val2017/000000007816.jpg",
    "file_name": "000000007816.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a black top not facing the camera.",
    "solution": [
      491.06,
      56.27,
      519.44,
      162.91
    ],
    "normalized_solution": [
      767,
      132,
      812,
      382
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "9"
    }
  },
  {
    "annotation_id": "194875_1743520851067",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 574,
    "width": 640,
    "normal_caption": "the person with long hair sitting next to the bar",
    "image": "val2017/000000194875.jpg",
    "file_name": "000000194875.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person with long hair sitting next to the bar.",
    "solution": [
      389.66,
      154.47,
      447.55,
      237.06
    ],
    "normalized_solution": [
      609,
      269,
      699,
      413
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "10"
    }
  },
  {
    "annotation_id": "194875_1743520958164",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 574,
    "width": 640,
    "normal_caption": "the bottle with light orange liquor inside on the right hand side of a green bottle",
    "image": "val2017/000000194875.jpg",
    "file_name": "000000194875.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle with light orange liquor inside on the right hand side of a green bottle.",
    "solution": [
      344.67,
      95.8,
      354.88,
      136.62
    ],
    "normalized_solution": [
      539,
      167,
      555,
      238
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    }
  },
  {
    "annotation_id": "102411_1743521203776",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person wearing a white top facing away from the camera",
    "image": "val2017/000000102411.jpg",
    "file_name": "000000102411.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a white top facing away from the camera.",
    "solution": [
      202.34,
      174.08,
      216.86,
      213.57000000000002
    ],
    "normalized_solution": [
      316,
      408,
      339,
      500
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    }
  },
  {
    "annotation_id": "109900_1743542454625",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 478,
    "width": 640,
    "normal_caption": "the person near a person holding a phone",
    "image": "val2017/000000109900.jpg",
    "file_name": "000000109900.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person near a person holding a phone.",
    "solution": [
      183.99,
      182.35,
      232.53,
      333
    ],
    "normalized_solution": [
      287,
      381,
      363,
      697
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "9"
    }
  },
  {
    "annotation_id": "284445_1743542826479",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 594,
    "width": 640,
    "normal_caption": "the person wearing a grey hat facing away from the camera",
    "image": "val2017/000000284445.jpg",
    "file_name": "000000284445.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a grey hat facing away from the camera.",
    "solution": [
      582.8,
      321.21,
      621.65,
      448.87
    ],
    "normalized_solution": [
      911,
      541,
      971,
      756
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "13"
    }
  },
  {
    "annotation_id": "463199_1743543004006",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person in a blue top near the window",
    "image": "val2017/000000463199.jpg",
    "file_name": "000000463199.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a blue top near the window.",
    "solution": [
      216.43,
      134.65,
      274.4,
      242.49
    ],
    "normalized_solution": [
      338,
      281,
      429,
      505
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "11"
    }
  },
  {
    "annotation_id": "1532_1743543184557",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the white car under the bridge",
    "image": "val2017/000000001532.jpg",
    "file_name": "000000001532.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white car under the bridge.",
    "solution": [
      106.19,
      375.71,
      185.28,
      435.29999999999995
    ],
    "normalized_solution": [
      166,
      783,
      290,
      907
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    }
  },
  {
    "annotation_id": "287291_1743543400698",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the person in a black top near a car",
    "image": "val2017/000000287291.jpg",
    "file_name": "000000287291.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a black top near a car.",
    "solution": [
      332.53,
      176.07,
      354.61999999999995,
      228.93
    ],
    "normalized_solution": [
      665,
      470,
      709,
      610
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "annotation_id": "303818_1744115681193",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person wearing white walking in front of a car",
    "image": "val2017/000000303818.jpg",
    "file_name": "000000303818.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing white walking in front of a car.",
    "solution": [
      11.78,
      184.89,
      25.91,
      217.25
    ],
    "normalized_solution": [
      25,
      289,
      54,
      339
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    }
  },
  {
    "annotation_id": "288584_1744115895091",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person wearing a hat near the bush",
    "image": "val2017/000000288584.jpg",
    "file_name": "000000288584.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a hat near the bush.",
    "solution": [
      399.17,
      143.93,
      489.37,
      399.17
    ],
    "normalized_solution": [
      624,
      337,
      765,
      935
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    }
  },
  {
    "annotation_id": "255917_1744116117577",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the grey car on the left side of a red car",
    "image": "val2017/000000255917.jpg",
    "file_name": "000000255917.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the grey car on the left side of a red car.",
    "solution": [
      50.5,
      329.7,
      130.23000000000002,
      384.96
    ],
    "normalized_solution": [
      79,
      772,
      203,
      902
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    }
  },
  {
    "annotation_id": "531134_1744116265191",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person wearing grey walking into an underpass",
    "image": "val2017/000000531134.jpg",
    "file_name": "000000531134.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing grey walking into an underpass.",
    "solution": [
      427.8,
      321.49,
      450.18,
      415.35
    ],
    "normalized_solution": [
      668,
      670,
      703,
      865
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    }
  },
  {
    "annotation_id": "162858_1744116338173",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 428,
    "normal_caption": "the black car behind a white car",
    "image": "val2017/000000162858.jpg",
    "file_name": "000000162858.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the black car behind a white car.",
    "solution": [
      359.14,
      339.46,
      426.90999999999997,
      542.75
    ],
    "normalized_solution": [
      839,
      530,
      997,
      848
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "12"
    }
  },
  {
    "annotation_id": "412894_1744116578418",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the person wearing a white top and carrying a bag on the right shoulder",
    "image": "val2017/000000412894.jpg",
    "file_name": "000000412894.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a white top and carrying a bag on the right shoulder.",
    "solution": [
      0.82,
      537.34,
      63.81,
      640
    ],
    "normalized_solution": [
      2,
      840,
      149,
      1000
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    }
  },
  {
    "annotation_id": "88848_1744116699504",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 640,
    "normal_caption": "the person wearing sunglasses, positioned between two people",
    "image": "val2017/000000088848.jpg",
    "file_name": "000000088848.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing sunglasses, positioned between two people.",
    "solution": [
      468.19,
      470.56,
      519.9,
      614.79
    ],
    "normalized_solution": [
      732,
      735,
      812,
      961
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "annotation_id": "130826_1744116842828",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person wearing jeans and carrying a bag on the shoulder",
    "image": "val2017/000000130826.jpg",
    "file_name": "000000130826.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing jeans and carrying a bag on the shoulder.",
    "solution": [
      52.85,
      4.31,
      153.17,
      188.76
    ],
    "normalized_solution": [
      83,
      9,
      239,
      393
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "5"
    }
  },
  {
    "annotation_id": "531707_1744116981433",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person sitting in the middle not wearing a hat",
    "image": "val2017/000000531707.jpg",
    "file_name": "000000531707.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person sitting in the middle not wearing a hat.",
    "solution": [
      331.89,
      221.08,
      392.43,
      376.76
    ],
    "normalized_solution": [
      519,
      461,
      613,
      785
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "3"
    }
  },
  {
    "annotation_id": "204186_1744117299968",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 513,
    "width": 640,
    "normal_caption": "the person in a white top not facing the camera",
    "image": "val2017/000000204186.jpg",
    "file_name": "000000204186.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top not facing the camera.",
    "solution": [
      521.14,
      66.78,
      562.13,
      190.28
    ],
    "normalized_solution": [
      814,
      130,
      878,
      371
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    }
  },
  {
    "annotation_id": "548780_1744117519828",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person in a white top not facing the camera",
    "image": "val2017/000000548780.jpg",
    "file_name": "000000548780.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top not facing the camera.",
    "solution": [
      175.6,
      0,
      261.96,
      210.14
    ],
    "normalized_solution": [
      274,
      0,
      409,
      492
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    }
  },
  {
    "annotation_id": "295231_1744117885971",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the sheep with dark face not facing the camera",
    "image": "val2017/000000295231.jpg",
    "file_name": "000000295231.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the sheep with dark face not facing the camera.",
    "solution": [
      311.07,
      160.92,
      458.86,
      321.4
    ],
    "normalized_solution": [
      648,
      251,
      956,
      502
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    }
  },
  {
    "annotation_id": "375763_1744118050795",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the sheep with a white face behind other sheep",
    "image": "val2017/000000375763.jpg",
    "file_name": "000000375763.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the sheep with a white face behind other sheep.",
    "solution": [
      161.15,
      182.81,
      204.73000000000002,
      210.83
    ],
    "normalized_solution": [
      252,
      381,
      320,
      439
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "11"
    }
  },
  {
    "annotation_id": "430073_1744118285673",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person in a white top carrying a bag",
    "image": "val2017/000000430073.jpg",
    "file_name": "000000430073.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top carrying a bag.",
    "solution": [
      141,
      126,
      160,
      180
    ],
    "normalized_solution": [
      220,
      263,
      250,
      375
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "23"
    }
  },
  {
    "annotation_id": "13659_1744118423931",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person on the right hand side of the person wearing a hat",
    "image": "val2017/000000013659.jpg",
    "file_name": "000000013659.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the right hand side of the person wearing a hat.",
    "solution": [
      331.36,
      94.09,
      461.70000000000005,
      265.38
    ],
    "normalized_solution": [
      518,
      196,
      721,
      553
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    }
  },
  {
    "annotation_id": "13659_1744118554804",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the red chair in front of a computer",
    "image": "val2017/000000013659.jpg",
    "file_name": "000000013659.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the red chair in front of a computer.",
    "solution": [
      188.62,
      124.46,
      277.81,
      194.67
    ],
    "normalized_solution": [
      295,
      259,
      434,
      406
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    }
  },
  {
    "annotation_id": "334555_1744118865354",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the person wearing a suit jacket standing by the wall",
    "image": "val2017/000000334555.jpg",
    "file_name": "000000334555.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a suit jacket standing by the wall.",
    "solution": [
      194.38,
      137.17,
      211.24,
      193.58999999999997
    ],
    "normalized_solution": [
      304,
      322,
      330,
      454
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "12"
    }
  },
  {
    "annotation_id": "356612_1744119030948",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 416,
    "width": 640,
    "normal_caption": "the cow in front of a grey car",
    "image": "val2017/000000356612.jpg",
    "file_name": "000000356612.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cow in front of a grey car.",
    "solution": [
      224.82,
      199.42,
      283.78,
      299.53999999999996
    ],
    "normalized_solution": [
      351,
      479,
      443,
      720
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    }
  },
  {
    "annotation_id": "507797_1744119263307",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person wearing a white shirt facing away from the camera",
    "image": "val2017/000000507797.jpg",
    "file_name": "000000507797.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a white shirt facing away from the camera.",
    "solution": [
      147.26,
      168.7,
      206.04,
      360.69
    ],
    "normalized_solution": [
      230,
      397,
      322,
      849
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "7"
    }
  },
  {
    "annotation_id": "70254_1744119539929",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 384,
    "width": 640,
    "normal_caption": "the person in a white top sitting on a bench",
    "image": "val2017/000000070254.jpg",
    "file_name": "000000070254.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top sitting on a bench.",
    "solution": [
      175.98,
      175.4,
      224,
      249.51
    ],
    "normalized_solution": [
      275,
      457,
      350,
      650
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    }
  }
]