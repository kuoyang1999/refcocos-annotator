[
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the computer screen that is in the middle layer",
    "image": "val2017/000000547144.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the computer screen that is in the middle layer.",
    "solution": [
      297.0,
      345.0,
      427.0,
      440.0
    ],
    "normalized_solution": [
      464,
      718,
      667,
      916
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 1901,
    "file_name": "000000547144.jpg",
    "annotation_id": "000000547144_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 333,
    "width": 500,
    "normal_caption": "background person not leaning back",
    "image": "val2017/000000006471.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: background person not leaning back.",
    "solution": [
      20.0,
      98.0,
      70.0,
      149.0
    ],
    "normalized_solution": [
      40,
      294,
      140,
      447
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 1247,
    "file_name": "000000006471.jpg",
    "annotation_id": "000000006471_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "non-glass cup",
    "image": "val2017/000000002157.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: non-glass cup.",
    "solution": [
      3.0,
      121.0,
      67.0,
      267.0
    ],
    "normalized_solution": [
      4,
      283,
      104,
      625
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 1337,
    "file_name": "000000002157.jpg",
    "annotation_id": "000000002157_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "person not holding anything",
    "image": "val2017/000000009590.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person not holding anything.",
    "solution": [
      255.0,
      179.0,
      330.0,
      254.0
    ],
    "normalized_solution": [
      398,
      419,
      515,
      594
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 2172,
    "file_name": "000000009590.jpg",
    "annotation_id": "000000009590_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the woman looking at an apple laptop",
    "image": "val2017/000000009400.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the woman looking at an apple laptop.",
    "solution": [
      1.0,
      93.0,
      114.0,
      213.0
    ],
    "normalized_solution": [
      1,
      193,
      178,
      443
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "hidden": true,
      "distractors": "3"
    },
    "image_index": 1808,
    "file_name": "000000009400.jpg",
    "annotation_id": "000000009400_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person helding nothing",
    "image": "val2017/000000010707.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person helding nothing.",
    "solution": [
      347.0,
      190.0,
      478.0,
      477.0
    ],
    "normalized_solution": [
      542,
      395,
      746,
      993
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "hidden": true,
      "distractors": "3"
    },
    "image_index": 1701,
    "file_name": "000000010707.jpg",
    "annotation_id": "000000010707_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "suitcase next to car wheel",
    "image": "val2017/000000009891.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: suitcase next to car wheel.",
    "solution": [
      419.0,
      245.0,
      495.0,
      350.0
    ],
    "normalized_solution": [
      654,
      510,
      773,
      729
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 982,
    "file_name": "000000009891.jpg",
    "annotation_id": "000000009891_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person who is wearing a necklace",
    "image": "val2017/000000015335.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is wearing a necklace.",
    "solution": [
      3.0,
      72.0,
      219.0,
      366.0
    ],
    "normalized_solution": [
      4,
      150,
      342,
      762
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 2191,
    "file_name": "000000015335.jpg",
    "annotation_id": "000000015335_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "person outside the middle window",
    "image": "val2017/000000000139.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person outside the middle window.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "3"
    },
    "image_index": 1660,
    "file_name": "000000000139.jpg",
    "annotation_id": "000000000139_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 483,
    "width": 640,
    "normal_caption": "person on bed",
    "image": "val2017/000000000632.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person on bed.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "3"
    },
    "image_index": 1767,
    "file_name": "000000000632.jpg",
    "annotation_id": "000000000632_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "person holding a goose feather",
    "image": "val2017/000000001268.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person holding a goose feather.",
    "solution": [
      20.0,
      213.0,
      81.0,
      285.0
    ],
    "normalized_solution": [
      31,
      498,
      126,
      667
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "hidden": false,
      "distractors": "4"
    },
    "image_index": 567,
    "file_name": "000000001268.jpg",
    "annotation_id": "000000001268_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "sign to 101 south",
    "image": "val2017/000000001532.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: sign to 101 south.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "3"
    },
    "image_index": 419,
    "file_name": "000000001532.jpg",
    "annotation_id": "000000001532_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 302,
    "width": 500,
    "normal_caption": "child in second row from camera, third from left",
    "image": "val2017/000000002299.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: child in second row from camera, third from left.",
    "solution": [
      77.0,
      135.0,
      117.0,
      234.0
    ],
    "normalized_solution": [
      154,
      447,
      234,
      774
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 993,
    "file_name": "000000002299.jpg",
    "annotation_id": "000000002299_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the ski pole held by the left hand of the person in the air",
    "image": "val2017/000000002473.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the ski pole held by the left hand of the person in the air.",
    "solution": [
      220.0,
      117.0,
      257.0,
      167.0
    ],
    "normalized_solution": [
      343,
      274,
      401,
      391
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": false,
      "distractors": "3"
    },
    "image_index": 1515,
    "file_name": "000000002473.jpg",
    "annotation_id": "000000002473_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 555,
    "width": 640,
    "normal_caption": "the shoes worn by the person with black hoodie",
    "image": "val2017/000000002685.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the shoes worn by the person with black hoodie.",
    "solution": [
      524.0,
      370.0,
      634.0,
      438.0
    ],
    "normalized_solution": [
      818,
      666,
      990,
      789
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 2167,
    "file_name": "000000002685.jpg",
    "annotation_id": "000000002685_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "baby corn",
    "image": "val2017/000000003845.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: baby corn.",
    "solution": [
      96.0,
      163.0,
      141.0,
      240.0
    ],
    "normalized_solution": [
      192,
      434,
      282,
      640
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 187,
    "file_name": "000000003845.jpg",
    "annotation_id": "000000003845_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 375,
    "normal_caption": "the man farthest from the camera",
    "image": "val2017/000000003934.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man farthest from the camera.",
    "solution": [
      297.0,
      133.0,
      326.0,
      221.0
    ],
    "normalized_solution": [
      792,
      266,
      869,
      442
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "4"
    },
    "image_index": 1737,
    "file_name": "000000003934.jpg",
    "annotation_id": "000000003934_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person who is not facing the camera and not holding it",
    "image": "val2017/000000005193.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is not facing the camera and not holding it.",
    "solution": [
      224.0,
      67.0,
      265.0,
      185.0
    ],
    "normalized_solution": [
      350,
      157,
      414,
      435
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 1539,
    "file_name": "000000005193.jpg",
    "annotation_id": "000000005193_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 335,
    "width": 500,
    "normal_caption": "the object held by the person on the right hand side of the person in red",
    "image": "val2017/000000013291.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the object held by the person on the right hand side of the person in red.",
    "solution": [
      182.0,
      199.0,
      217.0,
      232.0
    ],
    "normalized_solution": [
      364,
      594,
      434,
      692
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": false,
      "distractors": "4"
    },
    "image_index": 1230,
    "file_name": "000000013291.jpg",
    "annotation_id": "000000013291_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the second worker from the right",
    "image": "val2017/000000014473.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second worker from the right.",
    "solution": [
      273.0,
      272.0,
      300.0,
      310.0
    ],
    "normalized_solution": [
      426,
      637,
      468,
      725
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 695,
    "file_name": "000000014473.jpg",
    "annotation_id": "000000014473_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the frisbee that the child in blue looking at",
    "image": "val2017/000000006954.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the frisbee that the child in blue looking at.",
    "solution": [
      248.0,
      228.0,
      366.0,
      345.0
    ],
    "normalized_solution": [
      387,
      475,
      571,
      718
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb"
      ],
      "hidden": false,
      "distractors": "3"
    },
    "image_index": 1244,
    "file_name": "000000006954.jpg",
    "annotation_id": "000000006954_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the glass behind the flower",
    "image": "val2017/000000007818.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the glass behind the flower.",
    "solution": [
      402.0,
      187.0,
      445.0,
      292.0
    ],
    "normalized_solution": [
      628,
      437,
      695,
      683
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "3"
    },
    "image_index": 2198,
    "file_name": "000000007818.jpg",
    "annotation_id": "000000007818_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "person other than the man and his reflection",
    "image": "val2017/000000009483.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person other than the man and his reflection.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "hidden": false,
      "distractors": "3"
    },
    "image_index": 1910,
    "file_name": "000000009483.jpg",
    "annotation_id": "000000009483_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "yellow flag next to the middle clownfish flag",
    "image": "val2017/000000017959.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: yellow flag next to the middle clownfish flag.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 2053,
    "file_name": "000000017959.jpg",
    "annotation_id": "000000017959_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "third motorcycle from the left",
    "image": "val2017/000000019109.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: third motorcycle from the left.",
    "solution": [
      138.0,
      261.0,
      189.0,
      375.0
    ],
    "normalized_solution": [
      215,
      609,
      295,
      876
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 678,
    "file_name": "000000019109.jpg",
    "annotation_id": "000000019109_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the person next to the stairs",
    "image": "val2017/000000018380.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person next to the stairs.",
    "solution": [
      229.0,
      36.0,
      278.0,
      120.0
    ],
    "normalized_solution": [
      357,
      84,
      434,
      281
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 2283,
    "file_name": "000000018380.jpg",
    "annotation_id": "000000018380_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person outside the fence who is not sitting",
    "image": "val2017/000000018491.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person outside the fence who is not sitting.",
    "solution": [
      128.0,
      32.0,
      165.0,
      145.0
    ],
    "normalized_solution": [
      200,
      74,
      257,
      339
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 1320,
    "file_name": "000000018491.jpg",
    "annotation_id": "000000018491_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person on the surfboard which is not pink or yellow",
    "image": "val2017/000000081988.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the surfboard which is not pink or yellow.",
    "solution": [
      45.0,
      284.0,
      160.0,
      394.0
    ],
    "normalized_solution": [
      70,
      665,
      250,
      922
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 1841,
    "file_name": "000000081988.jpg",
    "annotation_id": "000000081988_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 275,
    "width": 500,
    "normal_caption": "a burned hotdog",
    "image": "val2017/000000083531.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a burned hotdog.",
    "solution": [
      343.0,
      159.0,
      404.0,
      178.0
    ],
    "normalized_solution": [
      686,
      578,
      808,
      647
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 1642,
    "file_name": "000000083531.jpg",
    "annotation_id": "000000083531_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the three people on the balcony right above crowd, not on the ground",
    "image": "val2017/000000084031.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the three people on the balcony right above crowd, not on the ground.",
    "solution": [
      250.0,
      126.0,
      277.0,
      152.0
    ],
    "normalized_solution": [
      390,
      295,
      432,
      355
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 1323,
    "file_name": "000000084031.jpg",
    "annotation_id": "000000084031_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 396,
    "width": 640,
    "normal_caption": "the smaller pot in front of the cooking pan",
    "image": "val2017/000000084241.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the smaller pot in front of the cooking pan.",
    "solution": [
      238.0,
      326.0,
      321.0,
      394.0
    ],
    "normalized_solution": [
      371,
      823,
      501,
      994
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "4"
    },
    "image_index": 57,
    "file_name": "000000084241.jpg",
    "annotation_id": "000000084241_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the carbinets on the top of the microwave",
    "image": "val2017/000000091615.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the carbinets on the top of the microwave.",
    "solution": [
      479.0,
      1.0,
      626.0,
      51.0
    ],
    "normalized_solution": [
      748,
      2,
      978,
      120
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 151,
    "file_name": "000000091615.jpg",
    "annotation_id": "000000091615_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "hotdog without vegetables on it",
    "image": "val2017/000000091779.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: hotdog without vegetables on it.",
    "solution": [
      110.0,
      99.0,
      472.0,
      320.0
    ],
    "normalized_solution": [
      171,
      206,
      737,
      666
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "hidden": false,
      "distractors": "3"
    },
    "image_index": 1622,
    "file_name": "000000091779.jpg",
    "annotation_id": "000000091779_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "dish seems to have the least amount",
    "image": "val2017/000000092053.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: dish seems to have the least amount.",
    "solution": [
      370.0,
      84.0,
      637.0,
      248.0
    ],
    "normalized_solution": [
      578,
      196,
      995,
      580
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "3"
    },
    "image_index": 1455,
    "file_name": "000000092053.jpg",
    "annotation_id": "000000092053_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "person holding up a frisbee and not wearing a bag",
    "image": "val2017/000000100238.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person holding up a frisbee and not wearing a bag.",
    "solution": [
      8.0,
      27.0,
      207.0,
      475.0
    ],
    "normalized_solution": [
      12,
      56,
      323,
      989
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb"
      ],
      "hidden": false,
      "distractors": "4"
    },
    "image_index": 1160,
    "file_name": "000000100238.jpg",
    "annotation_id": "000000100238_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "ice cream next to the potato",
    "image": "val2017/000000104669.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: ice cream next to the potato.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "4"
    },
    "image_index": 1201,
    "file_name": "000000104669.jpg",
    "annotation_id": "000000104669_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person partially obscured by the person in red shorts",
    "image": "val2017/000000105264.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person partially obscured by the person in red shorts.",
    "solution": [
      437.0,
      196.0,
      469.0,
      295.0
    ],
    "normalized_solution": [
      682,
      459,
      732,
      690
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 614,
    "file_name": "000000105264.jpg",
    "annotation_id": "000000105264_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 336,
    "width": 500,
    "normal_caption": "the second car behind the car with two open doors",
    "image": "val2017/000000111086.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second car behind the car with two open doors.",
    "solution": [
      161.0,
      232.0,
      226.0,
      281.0
    ],
    "normalized_solution": [
      322,
      690,
      452,
      836
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 113,
    "file_name": "000000111086.jpg",
    "annotation_id": "000000111086_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 425,
    "normal_caption": "the suitcase own by a person holding food in hand",
    "image": "val2017/000000114049.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the suitcase own by a person holding food in hand.",
    "solution": [
      131.0,
      327.0,
      236.0,
      571.0
    ],
    "normalized_solution": [
      308,
      510,
      555,
      892
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb"
      ],
      "hidden": true,
      "distractors": "3"
    },
    "image_index": 1053,
    "file_name": "000000114049.jpg",
    "annotation_id": "000000114049_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 329,
    "width": 500,
    "normal_caption": "the bus next to the bus with a different color",
    "image": "val2017/000000114884.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bus next to the bus with a different color.",
    "solution": [
      215.0,
      73.0,
      273.0,
      133.0
    ],
    "normalized_solution": [
      430,
      221,
      546,
      404
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 914,
    "file_name": "000000114884.jpg",
    "annotation_id": "000000114884_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "woman with hat",
    "image": "val2017/000000115870.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: woman with hat.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 1888,
    "file_name": "000000115870.jpg",
    "annotation_id": "000000115870_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the elephant fifth farthest from the camera",
    "image": "val2017/000000119641.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the elephant fifth farthest from the camera.",
    "solution": [
      502.0,
      385.0,
      537.0,
      435.0
    ],
    "normalized_solution": [
      784,
      802,
      839,
      906
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 1003,
    "file_name": "000000119641.jpg",
    "annotation_id": "000000119641_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 451,
    "width": 640,
    "normal_caption": "horse at left rear of the horse ride by a man wearing shirt",
    "image": "val2017/000000121031.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: horse at left rear of the horse ride by a man wearing shirt.",
    "solution": [
      387.0,
      187.0,
      442.0,
      260.0
    ],
    "normalized_solution": [
      604,
      414,
      690,
      576
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": false,
      "distractors": "4"
    },
    "image_index": 1115,
    "file_name": "000000121031.jpg",
    "annotation_id": "000000121031_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 392,
    "width": 640,
    "normal_caption": "person in yellow jersy",
    "image": "val2017/000000123213.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person in yellow jersy.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 1198,
    "file_name": "000000123213.jpg",
    "annotation_id": "000000123213_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the doll in front of a book whose name is not the office and not monk",
    "image": "val2017/000000125062.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the doll in front of a book whose name is not the office and not monk.",
    "solution": [
      1.0,
      224.0,
      127.0,
      445.0
    ],
    "normalized_solution": [
      2,
      350,
      297,
      695
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "hidden": false,
      "distractors": "4"
    },
    "image_index": 1082,
    "file_name": "000000125062.jpg",
    "annotation_id": "000000125062_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 327,
    "width": 500,
    "normal_caption": "chips that is neither red nor green",
    "image": "val2017/000000125936.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: chips that is neither red nor green.",
    "solution": [
      255.0,
      107.0,
      316.0,
      136.0
    ],
    "normalized_solution": [
      510,
      327,
      632,
      415
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "hidden": false,
      "distractors": "3"
    },
    "image_index": 1412,
    "file_name": "000000125936.jpg",
    "annotation_id": "000000125936_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the cabinet above the white rice cooker",
    "image": "val2017/000000127182.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cabinet above the white rice cooker.",
    "solution": [
      187.0,
      64.0,
      325.0,
      275.0
    ],
    "normalized_solution": [
      437,
      100,
      761,
      429
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 12,
    "file_name": "000000127182.jpg",
    "annotation_id": "000000127182_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the surfboard overlapping two other surfboards",
    "image": "val2017/000000127517.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the surfboard overlapping two other surfboards.",
    "solution": [
      507.0,
      75.0,
      578.0,
      363.0
    ],
    "normalized_solution": [
      792,
      156,
      903,
      756
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 1640,
    "file_name": "000000127517.jpg",
    "annotation_id": "000000127517_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "object behind the couch not facing camera horizontally",
    "image": "val2017/000000128148.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: object behind the couch not facing camera horizontally.",
    "solution": [
      1.0,
      189.0,
      96.0,
      311.0
    ],
    "normalized_solution": [
      1,
      441,
      150,
      726
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "hidden": true,
      "distractors": "3"
    },
    "image_index": 1654,
    "file_name": "000000128148.jpg",
    "annotation_id": "000000128148_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the cake decorated with two white swan-like figures, noticeably further apart from each other compared to similar decorations on other cakes",
    "image": "val2017/000000128476.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cake decorated with two white swan-like figures, noticeably further apart from each other compared to similar decorations on other cakes.",
    "solution": [
      307.0,
      146.0,
      593.0,
      353.0
    ],
    "normalized_solution": [
      479,
      341,
      926,
      826
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 1601,
    "file_name": "000000128476.jpg",
    "annotation_id": "000000128476_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the cow furthest from camera",
    "image": "val2017/000000129416.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cow furthest from camera.",
    "solution": [
      57.0,
      214.0,
      74.0,
      235.0
    ],
    "normalized_solution": [
      114,
      570,
      148,
      626
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 620,
    "file_name": "000000129416.jpg",
    "annotation_id": "000000129416_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "man sitting next to number 25 with his mouth open",
    "image": "val2017/000000133969.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: man sitting next to number 25 with his mouth open.",
    "solution": [
      214.0,
      176.0,
      288.0,
      315.0
    ],
    "normalized_solution": [
      334,
      412,
      450,
      737
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 2120,
    "file_name": "000000133969.jpg",
    "annotation_id": "000000133969_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "keyboard closest to monitor that is on",
    "image": "val2017/000000135872.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: keyboard closest to monitor that is on.",
    "solution": [
      310.0,
      166.0,
      369.0,
      198.0
    ],
    "normalized_solution": [
      484,
      388,
      576,
      463
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "3"
    },
    "image_index": 535,
    "file_name": "000000135872.jpg",
    "annotation_id": "000000135872_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 563,
    "width": 640,
    "normal_caption": "cow closest to the one sticking out tongue and doesn't have brown skin",
    "image": "val2017/000000137576.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: cow closest to the one sticking out tongue and doesn't have brown skin.",
    "solution": [
      0.0,
      304.0,
      121.0,
      489.0
    ],
    "normalized_solution": [
      0,
      539,
      189,
      868
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 623,
    "file_name": "000000137576.jpg",
    "annotation_id": "000000137576_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 453,
    "width": 640,
    "normal_caption": "the watermelon behind the one that is being held",
    "image": "val2017/000000139099.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the watermelon behind the one that is being held.",
    "solution": [
      43.0,
      391.0,
      182.0,
      411.0
    ],
    "normalized_solution": [
      67,
      863,
      284,
      907
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "4"
    },
    "image_index": 122,
    "file_name": "000000139099.jpg",
    "annotation_id": "000000139099_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 333,
    "width": 500,
    "normal_caption": "third biggest decoration on left wall",
    "image": "val2017/000000139684.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: third biggest decoration on left wall.",
    "solution": [
      86.0,
      18.0,
      110.0,
      70.0
    ],
    "normalized_solution": [
      172,
      54,
      220,
      210
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 1914,
    "file_name": "000000139684.jpg",
    "annotation_id": "000000139684_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 457,
    "width": 640,
    "normal_caption": "object under the wrench",
    "image": "val2017/000000140556.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: object under the wrench.",
    "solution": [
      389.0,
      244.0,
      487.0,
      456.0
    ],
    "normalized_solution": [
      607,
      533,
      760,
      997
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "3"
    },
    "image_index": 836,
    "file_name": "000000140556.jpg",
    "annotation_id": "000000140556_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "object being cut by lady in middle",
    "image": "val2017/000000140640.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: object being cut by lady in middle.",
    "solution": [
      463.0,
      367.0,
      593.0,
      423.0
    ],
    "normalized_solution": [
      723,
      861,
      926,
      992
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "hidden": true,
      "distractors": "3"
    },
    "image_index": 531,
    "file_name": "000000140640.jpg",
    "annotation_id": "000000140640_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 281,
    "width": 500,
    "normal_caption": "the kite on the left of english flag",
    "image": "val2017/000000140840.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the kite on the left of english flag.",
    "solution": [
      138.0,
      175.0,
      199.0,
      238.0
    ],
    "normalized_solution": [
      276,
      622,
      398,
      846
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 2050,
    "file_name": "000000140840.jpg",
    "annotation_id": "000000140840_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the person not on the same side as man with hat",
    "image": "val2017/000000115870.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person not on the same side as man with hat.",
    "solution": [
      273.0,
      103.0,
      333.0,
      181.0
    ],
    "normalized_solution": [
      426,
      241,
      520,
      424
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "hidden": false,
      "distractors": "4"
    },
    "image_index": 1888,
    "file_name": "000000115870.jpg",
    "annotation_id": "000000115870_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "person who is on a bicycle but not riding it",
    "image": "val2017/000000142324.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person who is on a bicycle but not riding it.",
    "solution": [
      284.0,
      194.0,
      330.0,
      291.0
    ],
    "normalized_solution": [
      443,
      404,
      515,
      606
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 280,
    "file_name": "000000142324.jpg",
    "annotation_id": "000000142324_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the cap of the portable stove",
    "image": "val2017/000000142620.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cap of the portable stove.",
    "solution": [
      41.0,
      369.0,
      101.0,
      422.0
    ],
    "normalized_solution": [
      64,
      866,
      157,
      990
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 2186,
    "file_name": "000000142620.jpg",
    "annotation_id": "000000142620_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 356,
    "width": 640,
    "normal_caption": "the man the woman with a translucent veil looking at",
    "image": "val2017/000000143961.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man the woman with a translucent veil looking at.",
    "solution": [
      0.0,
      138.0,
      73.0,
      325.0
    ],
    "normalized_solution": [
      0,
      387,
      114,
      912
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb"
      ],
      "hidden": true,
      "distractors": "5"
    },
    "image_index": 966,
    "file_name": "000000143961.jpg",
    "annotation_id": "000000143961_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "person sitting at 3 o'clock position on picnic mat",
    "image": "val2017/000000145597.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person sitting at 3 o'clock position on picnic mat.",
    "solution": [
      480.0,
      35.0,
      639.0,
      256.0
    ],
    "normalized_solution": [
      750,
      72,
      998,
      533
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "hidden": false,
      "distractors": "5"
    },
    "image_index": 1413,
    "file_name": "000000145597.jpg",
    "annotation_id": "000000145597_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "a bowl whose exterior is neither red nor white",
    "image": "val2017/000000494869.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a bowl whose exterior is neither red nor white.",
    "solution": [
      342.29,
      236.85,
      392.62,
      265.01
    ],
    "normalized_solution": [
      802,
      370,
      919,
      414
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 0,
    "file_name": "000000494869.jpg",
    "annotation_id": "000000494869_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person wearing sneakers that are not blue",
    "image": "val2017/000000554002.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing sneakers that are not blue.",
    "solution": [
      19.14,
      2.39,
      109.12,
      257.97
    ],
    "normalized_solution": [
      30,
      6,
      171,
      607
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 1,
    "file_name": "000000554002.jpg",
    "annotation_id": "000000554002_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car has a cat wearing a red scarf around its neck",
    "image": "val2017/000000078823.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car has a cat wearing a red scarf around its neck.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 2,
    "file_name": "000000078823.jpg",
    "annotation_id": "000000078823_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 426,
    "normal_caption": "the knife that is neither held by anyone nor placed on the marble surface",
    "image": "val2017/000000419974.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the knife that is neither held by anyone nor placed on the marble surface.",
    "solution": [
      130.09,
      276.33,
      146.09,
      283.4
    ],
    "normalized_solution": [
      305,
      432,
      343,
      443
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 3,
    "file_name": "000000419974.jpg",
    "annotation_id": "000000419974_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 512,
    "width": 640,
    "normal_caption": "the bicycle being ridden by a person holding a dog",
    "image": "val2017/000000424162.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bicycle being ridden by a person holding a dog.",
    "solution": [
      305.56,
      230.39,
      422.68,
      474.33
    ],
    "normalized_solution": [
      477,
      450,
      660,
      926
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 5,
    "file_name": "000000424162.jpg",
    "annotation_id": "000000424162_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the cup mounted on the wall, located in the second row from the top, at the leftmost position",
    "image": "val2017/000000329219.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cup mounted on the wall, located in the second row from the top, at the leftmost position.",
    "solution": [
      331.4,
      80.38,
      346.26,
      97.16999999999999
    ],
    "normalized_solution": [
      518,
      188,
      541,
      228
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "12"
    },
    "image_index": 4,
    "file_name": "000000329219.jpg",
    "annotation_id": "000000329219_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 485,
    "width": 640,
    "normal_caption": "the person in the car who is not sitting in the driver's seat",
    "image": "val2017/000000067213.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in the car who is not sitting in the driver's seat.",
    "solution": [
      277.98,
      371.09,
      310.22,
      409.37
    ],
    "normalized_solution": [
      434,
      765,
      485,
      844
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "7"
    },
    "image_index": 7,
    "file_name": "000000067213.jpg",
    "annotation_id": "000000067213_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the bench that a dog is sitting on",
    "image": "val2017/000000061108.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bench that a dog is sitting on.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "7"
    },
    "image_index": 6,
    "file_name": "000000061108.jpg",
    "annotation_id": "000000061108_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 588,
    "width": 640,
    "normal_caption": "the car located to the left of the car containing the dog",
    "image": "val2017/000000365207.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car located to the left of the car containing the dog.",
    "solution": [
      69.7,
      260.42,
      211.63,
      463.18
    ],
    "normalized_solution": [
      109,
      443,
      331,
      788
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 8,
    "file_name": "000000365207.jpg",
    "annotation_id": "000000365207_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 429,
    "width": 640,
    "normal_caption": "the bicycle in the background positioned between the person wearing a black shirt and white pants and the person wearing a black-and-white patterned shirt and shorts, mostly obscured by other objects",
    "image": "val2017/000000279278.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bicycle in the background positioned between the person wearing a black shirt and white pants and the person wearing a black-and-white patterned shirt and shorts, mostly obscured by other objects.",
    "solution": [
      334.76,
      48.96,
      365.2,
      157.71
    ],
    "normalized_solution": [
      523,
      114,
      571,
      368
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "10"
    },
    "image_index": 9,
    "file_name": "000000279278.jpg",
    "annotation_id": "000000279278_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the second hanging potted plant from the right",
    "image": "val2017/000000482100.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second hanging potted plant from the right.",
    "solution": [
      338.75,
      0,
      379.54,
      39.27
    ],
    "normalized_solution": [
      529,
      0,
      593,
      92
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 10,
    "file_name": "000000482100.jpg",
    "annotation_id": "000000482100_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "a watermelon in a bowl placed centrally on the wooden countertop island",
    "image": "val2017/000000540502.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a watermelon in a bowl placed centrally on the wooden countertop island.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "4",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 11,
    "file_name": "000000540502.jpg",
    "annotation_id": "000000540502_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the second knife from the top positioned in a knife block",
    "image": "val2017/000000127182.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second knife from the top positioned in a knife block.",
    "solution": [
      7.8,
      342.05,
      37.51,
      371.61
    ],
    "normalized_solution": [
      18,
      534,
      88,
      581
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 12,
    "file_name": "000000127182.jpg",
    "annotation_id": "000000127182_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a red bowl that is not located on the top shelf of the right set of cabinets",
    "image": "val2017/000000575970.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a red bowl that is not located on the top shelf of the right set of cabinets.",
    "solution": [
      276.5,
      83.81,
      296.74,
      90.16
    ],
    "normalized_solution": [
      432,
      175,
      464,
      188
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 13,
    "file_name": "000000575970.jpg",
    "annotation_id": "000000575970_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "a wine glass located on top of the stove",
    "image": "val2017/000000226984.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a wine glass located on top of the stove.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "17"
    },
    "image_index": 14,
    "file_name": "000000226984.jpg",
    "annotation_id": "000000226984_1744240036431"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 230,
    "width": 352,
    "normal_caption": "the chair close to the fruit and not next to the refrigerator",
    "image": "val2017/000000037777.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair close to the fruit and not next to the refrigerator.",
    "solution": [
      116.5,
      189.57,
      166.5,
      215.07
    ],
    "normalized_solution": [
      331,
      824,
      473,
      935
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 15,
    "file_name": "000000037777.jpg",
    "annotation_id": "000000037777_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the plant located between a yellow bottle and a blue bottle",
    "image": "val2017/000000491216.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the plant located between a yellow bottle and a blue bottle.",
    "solution": [
      269.55,
      180.58,
      298.97,
      243.18
    ],
    "normalized_solution": [
      562,
      282,
      623,
      380
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 16,
    "file_name": "000000491216.jpg",
    "annotation_id": "000000491216_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the plant that is neither hanging nor placed on a kitchen table",
    "image": "val2017/000000136355.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the plant that is neither hanging nor placed on a kitchen table.",
    "solution": [
      448.77,
      175.76,
      513.22,
      298.76
    ],
    "normalized_solution": [
      701,
      412,
      802,
      700
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "4"
    },
    "image_index": 17,
    "file_name": "000000136355.jpg",
    "annotation_id": "000000136355_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "a cup on the middle shelf of the left wall, surrounded by wine glasses",
    "image": "val2017/000000529568.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a cup on the middle shelf of the left wall, surrounded by wine glasses.",
    "solution": [
      66.71,
      220.26,
      82.78999999999999,
      253.76999999999998
    ],
    "normalized_solution": [
      139,
      344,
      172,
      397
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "7"
    },
    "image_index": 18,
    "file_name": "000000529568.jpg",
    "annotation_id": "000000529568_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "a person wiping her face with a towel",
    "image": "val2017/000000306733.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person wiping her face with a towel.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 19,
    "file_name": "000000306733.jpg",
    "annotation_id": "000000306733_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the smaller bowl that is yellow",
    "image": "val2017/000000068833.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the smaller bowl that is yellow.",
    "solution": [
      313.8,
      228.19,
      335.29,
      247.14
    ],
    "normalized_solution": [
      490,
      475,
      524,
      515
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 20,
    "file_name": "000000068833.jpg",
    "annotation_id": "000000068833_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 383,
    "width": 500,
    "normal_caption": "the figure of a person that has a solid-colored background that is not white",
    "image": "val2017/000000149222.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the figure of a person that has a solid-colored background that is not white.",
    "solution": [
      236.11,
      72.81,
      248.48000000000002,
      89.11
    ],
    "normalized_solution": [
      472,
      190,
      497,
      233
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 21,
    "file_name": "000000149222.jpg",
    "annotation_id": "000000149222_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 360,
    "width": 640,
    "normal_caption": "a display screen that is not showing any content with red color",
    "image": "val2017/000000361586.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a display screen that is not showing any content with red color.",
    "solution": [
      19.67,
      133.25,
      86.2,
      211.82
    ],
    "normalized_solution": [
      31,
      370,
      135,
      588
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "4"
    },
    "image_index": 22,
    "file_name": "000000361586.jpg",
    "annotation_id": "000000361586_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the bottle that is not empty and is located on the right side of the flower",
    "image": "val2017/000000186632.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle that is not empty and is located on the right side of the flower.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 23,
    "file_name": "000000186632.jpg",
    "annotation_id": "000000186632_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the third chair from the left at the dining table",
    "image": "val2017/000000440475.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the third chair from the left at the dining table.",
    "solution": [
      444.5,
      299.5,
      542.71,
      361.2
    ],
    "normalized_solution": [
      695,
      701,
      848,
      846
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "7"
    },
    "image_index": 24,
    "file_name": "000000440475.jpg",
    "annotation_id": "000000440475_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 357,
    "normal_caption": "an orange cat sitting on the carpet watching tv",
    "image": "val2017/000000240940.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: an orange cat sitting on the carpet watching tv.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "12"
    },
    "image_index": 25,
    "file_name": "000000240940.jpg",
    "annotation_id": "000000240940_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the second bicycle that is laying on top of the motorcycle",
    "image": "val2017/000000070774.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second bicycle that is laying on top of the motorcycle.",
    "solution": [
      261.38,
      173.6,
      506.79999999999995,
      223.64999999999998
    ],
    "normalized_solution": [
      408,
      408,
      792,
      526
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 26,
    "file_name": "000000070774.jpg",
    "annotation_id": "000000070774_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the white pigeon burying its head inside the bread",
    "image": "val2017/000000123585.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white pigeon burying its head inside the bread.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": true,
      "distractors": "5"
    },
    "image_index": 27,
    "file_name": "000000123585.jpg",
    "annotation_id": "000000123585_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the car that is neither blue nor on the left side of the road and does not have a cat on it",
    "image": "val2017/000000466156.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car that is neither blue nor on the left side of the road and does not have a cat on it.",
    "solution": [
      274.28,
      32.03,
      291.21,
      40.57
    ],
    "normalized_solution": [
      549,
      85,
      582,
      108
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 28,
    "file_name": "000000466156.jpg",
    "annotation_id": "000000466156_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car whose license plate number begins with a digit other than one",
    "image": "val2017/000000172330.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car whose license plate number begins with a digit other than one.",
    "solution": [
      471.74,
      79.74,
      637.94,
      384.26
    ],
    "normalized_solution": [
      737,
      166,
      997,
      801
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 29,
    "file_name": "000000172330.jpg",
    "annotation_id": "000000172330_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the second cup next to the red tube",
    "image": "val2017/000000227044.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second cup next to the red tube.",
    "solution": [
      114.34,
      0,
      174.74,
      43.15
    ],
    "normalized_solution": [
      179,
      0,
      273,
      90
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 30,
    "file_name": "000000227044.jpg",
    "annotation_id": "000000227044_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the person who is wearing green clothing and is next to the woman wearing a purple shirt",
    "image": "val2017/000000176857.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is wearing green clothing and is next to the woman wearing a purple shirt.",
    "solution": [
      145.04,
      11.4,
      175.32,
      75.97
    ],
    "normalized_solution": [
      290,
      30,
      351,
      203
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "11"
    },
    "image_index": 31,
    "file_name": "000000176857.jpg",
    "annotation_id": "000000176857_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the horse that is not brown and is facing away from the car",
    "image": "val2017/000000017178.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the horse that is not brown and is facing away from the car.",
    "solution": [
      374.97,
      173.6,
      433.33000000000004,
      267.26
    ],
    "normalized_solution": [
      586,
      407,
      677,
      626
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 32,
    "file_name": "000000017178.jpg",
    "annotation_id": "000000017178_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 411,
    "normal_caption": "the silver car that is on the front left side of the horse",
    "image": "val2017/000000368335.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the silver car that is on the front left side of the horse.",
    "solution": [
      75.52,
      209.12,
      165.68,
      326.19
    ],
    "normalized_solution": [
      184,
      327,
      403,
      510
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 33,
    "file_name": "000000368335.jpg",
    "annotation_id": "000000368335_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 338,
    "width": 450,
    "normal_caption": "the person wearing a blue shirt walking behind the blue and white bus",
    "image": "val2017/000000367680.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a blue shirt walking behind the blue and white bus.",
    "solution": [
      236.2,
      150.47,
      250.04999999999998,
      197.09
    ],
    "normalized_solution": [
      525,
      445,
      556,
      583
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 34,
    "file_name": "000000367680.jpg",
    "annotation_id": "000000367680_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 462,
    "width": 640,
    "normal_caption": "the horse that is not facing the camera and does not have a white tail",
    "image": "val2017/000000234807.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the horse that is not facing the camera and does not have a white tail.",
    "solution": [
      3.17,
      238.5,
      86.94,
      291.1
    ],
    "normalized_solution": [
      5,
      516,
      136,
      630
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 35,
    "file_name": "000000234807.jpg",
    "annotation_id": "000000234807_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the rider that is not wearing red or black helmet",
    "image": "val2017/000000507975.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the rider that is not wearing red or black helmet.",
    "solution": [
      361.96,
      23.07,
      451.36,
      101.44
    ],
    "normalized_solution": [
      566,
      48,
      705,
      211
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "5"
    },
    "image_index": 36,
    "file_name": "000000507975.jpg",
    "annotation_id": "000000507975_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 425,
    "normal_caption": "the person who is holding a camera and carrying a green bag",
    "image": "val2017/000000338304.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is holding a camera and carrying a green bag.",
    "solution": [
      0.42,
      298.6,
      101.52,
      488.25
    ],
    "normalized_solution": [
      1,
      467,
      239,
      763
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": true,
      "distractors": "13"
    },
    "image_index": 37,
    "file_name": "000000338304.jpg",
    "annotation_id": "000000338304_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 322,
    "width": 500,
    "normal_caption": "the traffic light with an arrow that is not pointing to the right",
    "image": "val2017/000000555050.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the traffic light with an arrow that is not pointing to the right.",
    "solution": [
      5.1,
      50.72,
      36.13,
      132.82999999999998
    ],
    "normalized_solution": [
      10,
      158,
      72,
      413
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 38,
    "file_name": "000000555050.jpg",
    "annotation_id": "000000555050_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 332,
    "normal_caption": "the second cow next to the cow with the least amount of brown",
    "image": "val2017/000000206135.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second cow next to the cow with the least amount of brown.",
    "solution": [
      172.18,
      302.22,
      233.89000000000001,
      439.78000000000003
    ],
    "normalized_solution": [
      519,
      604,
      704,
      880
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 39,
    "file_name": "000000206135.jpg",
    "annotation_id": "000000206135_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the bottle with a white top that is closest to the red bottle",
    "image": "val2017/000000465129.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle with a white top that is closest to the red bottle.",
    "solution": [
      543.74,
      335.07,
      560.86,
      366.53
    ],
    "normalized_solution": [
      850,
      698,
      876,
      764
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 40,
    "file_name": "000000465129.jpg",
    "annotation_id": "000000465129_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the bottle that is not foil-wrapped and is located on the first shelf from the top",
    "image": "val2017/000000506310.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle that is not foil-wrapped and is located on the first shelf from the top.",
    "solution": [
      1.46,
      76.32,
      39.76,
      241.29
    ],
    "normalized_solution": [
      2,
      180,
      62,
      568
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "4"
    },
    "image_index": 41,
    "file_name": "000000506310.jpg",
    "annotation_id": "000000506310_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 426,
    "normal_caption": "the spinning chair that is closest to the wine bottle",
    "image": "val2017/000000519569.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the spinning chair that is closest to the wine bottle.",
    "solution": [
      126.4,
      391.5,
      248.52,
      615.54
    ],
    "normalized_solution": [
      297,
      612,
      583,
      962
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 42,
    "file_name": "000000519569.jpg",
    "annotation_id": "000000519569_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 375,
    "normal_caption": "the man who is blow drying his hair using the hair drier",
    "image": "val2017/000000178028.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man who is blow drying his hair using the hair drier.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": false,
      "distractors": "7"
    },
    "image_index": 43,
    "file_name": "000000178028.jpg",
    "annotation_id": "000000178028_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 612,
    "width": 612,
    "normal_caption": "the cup on the counter that is mostly covered",
    "image": "val2017/000000290768.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cup on the counter that is mostly covered.",
    "solution": [
      152.34,
      189.47,
      170.51,
      258.27
    ],
    "normalized_solution": [
      249,
      310,
      279,
      422
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 44,
    "file_name": "000000290768.jpg",
    "annotation_id": "000000290768_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the ceramic bowl that is empty",
    "image": "val2017/000000182611.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the ceramic bowl that is empty.",
    "solution": [
      136.4,
      537.44,
      185.67000000000002,
      581.34
    ],
    "normalized_solution": [
      284,
      840,
      387,
      908
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "occluded": true,
      "distractors": "10"
    },
    "image_index": 45,
    "file_name": "000000182611.jpg",
    "annotation_id": "000000182611_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 429,
    "normal_caption": "the person that is not wearing a uniform and is blocked by the person who is wearing a hat",
    "image": "val2017/000000228214.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person that is not wearing a uniform and is blocked by the person who is wearing a hat.",
    "solution": [
      287.84,
      475.7,
      406.40999999999997,
      640
    ],
    "normalized_solution": [
      671,
      743,
      947,
      1000
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 46,
    "file_name": "000000228214.jpg",
    "annotation_id": "000000228214_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the first toothbrush from the right side that is not blue",
    "image": "val2017/000000293390.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the first toothbrush from the right side that is not blue.",
    "solution": [
      494.62,
      11.04,
      502.18,
      49.46
    ],
    "normalized_solution": [
      773,
      23,
      785,
      103
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 47,
    "file_name": "000000293390.jpg",
    "annotation_id": "000000293390_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 375,
    "normal_caption": "the smallest bottle without a blue or green cap",
    "image": "val2017/000000384808.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the smallest bottle without a blue or green cap.",
    "solution": [
      48.91,
      268.67,
      63.449999999999996,
      325.36
    ],
    "normalized_solution": [
      130,
      537,
      169,
      651
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 48,
    "file_name": "000000384808.jpg",
    "annotation_id": "000000384808_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the bottle that is not in the refrigerator and has blue writing on its label",
    "image": "val2017/000000425226.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle that is not in the refrigerator and has blue writing on its label.",
    "solution": [
      299.65,
      2.09,
      321.41999999999996,
      44.269999999999996
    ],
    "normalized_solution": [
      624,
      3,
      670,
      69
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "6"
    },
    "image_index": 49,
    "file_name": "000000425226.jpg",
    "annotation_id": "000000425226_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the bottle that is neither green nor has a rectangular cap",
    "image": "val2017/000000292005.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle that is neither green nor has a rectangular cap.",
    "solution": [
      201.81,
      453.48,
      220.65,
      508.34000000000003
    ],
    "normalized_solution": [
      420,
      709,
      460,
      794
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 50,
    "file_name": "000000292005.jpg",
    "annotation_id": "000000292005_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 640,
    "normal_caption": "the chair close to the stove and partially covered by the banana",
    "image": "val2017/000000480122.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair close to the stove and partially covered by the banana.",
    "solution": [
      217.57,
      359.3,
      294.26,
      430.21000000000004
    ],
    "normalized_solution": [
      340,
      561,
      460,
      672
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "5"
    },
    "image_index": 51,
    "file_name": "000000480122.jpg",
    "annotation_id": "000000480122_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 478,
    "width": 640,
    "normal_caption": "the partially empty spray bottle with green liquid",
    "image": "val2017/000000197796.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the partially empty spray bottle with green liquid.",
    "solution": [
      312.48,
      57.63,
      337.43,
      155.96
    ],
    "normalized_solution": [
      488,
      121,
      527,
      326
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 52,
    "file_name": "000000197796.jpg",
    "annotation_id": "000000197796_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the pink cup on the second shelf from the top",
    "image": "val2017/000000481386.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the pink cup on the second shelf from the top.",
    "solution": [
      287.43,
      135.07,
      311.46000000000004,
      160.73
    ],
    "normalized_solution": [
      673,
      211,
      729,
      251
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "10"
    },
    "image_index": 53,
    "file_name": "000000481386.jpg",
    "annotation_id": "000000481386_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the white ceramic bowl that is not on the counter",
    "image": "val2017/000000397133.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white ceramic bowl that is not on the counter.",
    "solution": [
      157.2,
      114.15,
      175.06,
      129.97
    ],
    "normalized_solution": [
      246,
      267,
      274,
      304
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 54,
    "file_name": "000000397133.jpg",
    "annotation_id": "000000397133_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the red bottle that is not located on the first shelf from the top",
    "image": "val2017/000000173302.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the red bottle that is not located on the first shelf from the top.",
    "solution": [
      435.32,
      178.03,
      442.81,
      191.89
    ],
    "normalized_solution": [
      680,
      419,
      692,
      452
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 55,
    "file_name": "000000173302.jpg",
    "annotation_id": "000000173302_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the tall bottle that is closest to the stove",
    "image": "val2017/000000523100.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the tall bottle that is closest to the stove.",
    "solution": [
      153.77,
      86.61,
      187.13,
      178.3
    ],
    "normalized_solution": [
      320,
      135,
      390,
      279
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 56,
    "file_name": "000000523100.jpg",
    "annotation_id": "000000523100_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 396,
    "width": 640,
    "normal_caption": "the woman who is wearing pink clothing and not smiling",
    "image": "val2017/000000084241.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the woman who is wearing pink clothing and not smiling.",
    "solution": [
      198.89,
      23.16,
      284.51,
      289.42
    ],
    "normalized_solution": [
      311,
      58,
      445,
      731
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 57,
    "file_name": "000000084241.jpg",
    "annotation_id": "000000084241_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the bottle behind the stove with yellow and red wrapping",
    "image": "val2017/000000074209.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle behind the stove with yellow and red wrapping.",
    "solution": [
      171.43,
      197.48,
      181.38,
      223.79
    ],
    "normalized_solution": [
      268,
      411,
      283,
      466
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 58,
    "file_name": "000000074209.jpg",
    "annotation_id": "000000074209_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the spoon inside the glass cup filled with water",
    "image": "val2017/000000239627.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the spoon inside the glass cup filled with water.",
    "solution": [
      425.77,
      173.22,
      501.2,
      248.64
    ],
    "normalized_solution": [
      665,
      406,
      783,
      582
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 59,
    "file_name": "000000239627.jpg",
    "annotation_id": "000000239627_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 478,
    "width": 640,
    "normal_caption": "a hand soap on the bathroom counter next to a pile of paper towels",
    "image": "val2017/000000195165.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a hand soap on the bathroom counter next to a pile of paper towels.",
    "solution": [
      329.8,
      263.35,
      347.95,
      312.64000000000004
    ],
    "normalized_solution": [
      515,
      551,
      544,
      654
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "10"
    },
    "image_index": 60,
    "file_name": "000000195165.jpg",
    "annotation_id": "000000195165_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 640,
    "normal_caption": "the reflection in the mirror of a cup not containing a toothbrush",
    "image": "val2017/000000492878.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the reflection in the mirror of a cup not containing a toothbrush.",
    "solution": [
      53.06,
      77.26,
      182.38,
      282.86
    ],
    "normalized_solution": [
      83,
      121,
      285,
      442
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 61,
    "file_name": "000000492878.jpg",
    "annotation_id": "000000492878_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 461,
    "width": 614,
    "normal_caption": "the metal pot on the left stove",
    "image": "val2017/000000175364.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the metal pot on the left stove.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 62,
    "file_name": "000000175364.jpg",
    "annotation_id": "000000175364_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person who is neither facing the camera nor wearing a brown jacket",
    "image": "val2017/000000438774.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is neither facing the camera nor wearing a brown jacket.",
    "solution": [
      333.68,
      51.59,
      458.49,
      382.25
    ],
    "normalized_solution": [
      521,
      121,
      716,
      899
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "4"
    },
    "image_index": 63,
    "file_name": "000000438774.jpg",
    "annotation_id": "000000438774_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a plastic bottle without a label",
    "image": "val2017/000000485424.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a plastic bottle without a label.",
    "solution": [
      50.52,
      237.88,
      113.97,
      315.43
    ],
    "normalized_solution": [
      79,
      496,
      178,
      657
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "5"
    },
    "image_index": 64,
    "file_name": "000000485424.jpg",
    "annotation_id": "000000485424_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 464,
    "width": 640,
    "normal_caption": "a red bowl that is not on the counter nor the stove",
    "image": "val2017/000000530836.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a red bowl that is not on the counter nor the stove.",
    "solution": [
      0,
      190.59,
      30.24,
      209.08
    ],
    "normalized_solution": [
      0,
      411,
      47,
      451
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "6"
    },
    "image_index": 65,
    "file_name": "000000530836.jpg",
    "annotation_id": "000000530836_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a woman wearing sandals",
    "image": "val2017/000000177934.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a woman wearing sandals.",
    "solution": [
      352.76,
      154.48,
      405.12,
      338.5
    ],
    "normalized_solution": [
      551,
      322,
      633,
      705
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 66,
    "file_name": "000000177934.jpg",
    "annotation_id": "000000177934_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the bottle with a black cap, second from the left",
    "image": "val2017/000000040471.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle with a black cap, second from the left.",
    "solution": [
      309.15,
      323.63,
      317.90999999999997,
      339.51
    ],
    "normalized_solution": [
      724,
      506,
      745,
      530
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 67,
    "file_name": "000000040471.jpg",
    "annotation_id": "000000040471_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 446,
    "width": 640,
    "normal_caption": "a bowl on a metal wall-mounted open cabinet that is not stacked",
    "image": "val2017/000000455597.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a bowl on a metal wall-mounted open cabinet that is not stacked.",
    "solution": [
      182.03,
      164.87,
      209.75,
      174.99
    ],
    "normalized_solution": [
      284,
      370,
      328,
      392
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 68,
    "file_name": "000000455597.jpg",
    "annotation_id": "000000455597_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 375,
    "normal_caption": "the second bottle from the right on the kitchen countertop",
    "image": "val2017/000000308799.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second bottle from the right on the kitchen countertop.",
    "solution": [
      243.36,
      224.27,
      253.26000000000002,
      254.91000000000003
    ],
    "normalized_solution": [
      649,
      449,
      675,
      510
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 69,
    "file_name": "000000308799.jpg",
    "annotation_id": "000000308799_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the plant that is not on the windowsill and is located on the right side",
    "image": "val2017/000000045229.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the plant that is not on the windowsill and is located on the right side.",
    "solution": [
      348.72,
      388.45,
      380.18,
      423.94
    ],
    "normalized_solution": [
      545,
      809,
      594,
      883
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 70,
    "file_name": "000000045229.jpg",
    "annotation_id": "000000045229_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a pot on the stovetop next to the coffee machine",
    "image": "val2017/000000109976.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a pot on the stovetop next to the coffee machine.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 71,
    "file_name": "000000109976.jpg",
    "annotation_id": "000000109976_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 424,
    "width": 640,
    "normal_caption": "a black chair that doesn't have any object on it and has a backrest",
    "image": "val2017/000000441247.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a black chair that doesn't have any object on it and has a backrest.",
    "solution": [
      221.7,
      220.73,
      301.35,
      347.73
    ],
    "normalized_solution": [
      346,
      521,
      471,
      820
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 72,
    "file_name": "000000441247.jpg",
    "annotation_id": "000000441247_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 361,
    "width": 640,
    "normal_caption": "a stack of two books that is not placed next to the chair",
    "image": "val2017/000000093437.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a stack of two books that is not placed next to the chair.",
    "solution": [
      490.55,
      212.2,
      523.83,
      222.91
    ],
    "normalized_solution": [
      766,
      588,
      818,
      617
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 73,
    "file_name": "000000093437.jpg",
    "annotation_id": "000000093437_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "a chair that is neither close to the wall nor closest to the camera",
    "image": "val2017/000000221708.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a chair that is neither close to the wall nor closest to the camera.",
    "solution": [
      210.25,
      255.88,
      285.67,
      424.44
    ],
    "normalized_solution": [
      438,
      400,
      595,
      663
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 74,
    "file_name": "000000221708.jpg",
    "annotation_id": "000000221708_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the chair farthest from the microwave",
    "image": "val2017/000000216497.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair farthest from the microwave.",
    "solution": [
      386.03,
      269.83,
      468.07,
      451.40999999999997
    ],
    "normalized_solution": [
      603,
      562,
      731,
      940
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 75,
    "file_name": "000000216497.jpg",
    "annotation_id": "000000216497_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the upper oven embedded in the white cabinet",
    "image": "val2017/000000458768.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the upper oven embedded in the white cabinet.",
    "solution": [
      408.36,
      206.98,
      428.23,
      252.88
    ],
    "normalized_solution": [
      638,
      485,
      669,
      592
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 76,
    "file_name": "000000458768.jpg",
    "annotation_id": "000000458768_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the middle chair among chairs with green mat",
    "image": "val2017/000000543047.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the middle chair among chairs with green mat.",
    "solution": [
      397.23,
      177.89,
      419.54,
      206.7
    ],
    "normalized_solution": [
      621,
      371,
      656,
      431
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "4"
    },
    "image_index": 77,
    "file_name": "000000543047.jpg",
    "annotation_id": "000000543047_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the middle chair at the dining table not on the sofa side",
    "image": "val2017/000000472046.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the middle chair at the dining table not on the sofa side.",
    "solution": [
      70.16,
      256.44,
      100.33,
      277.29
    ],
    "normalized_solution": [
      110,
      603,
      157,
      652
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "5"
    },
    "image_index": 78,
    "file_name": "000000472046.jpg",
    "annotation_id": "000000472046_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 408,
    "normal_caption": "a person holding a green umbrella walking away from the camera",
    "image": "val2017/000000045596.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person holding a green umbrella walking away from the camera.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "7"
    },
    "image_index": 79,
    "file_name": "000000045596.jpg",
    "annotation_id": "000000045596_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 425,
    "normal_caption": "a bicycle without a basket that is partially blocked by a yellow pole",
    "image": "val2017/000000259830.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a bicycle without a basket that is partially blocked by a yellow pole.",
    "solution": [
      338.58,
      426.67,
      425,
      579.44
    ],
    "normalized_solution": [
      797,
      667,
      1000,
      905
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 80,
    "file_name": "000000259830.jpg",
    "annotation_id": "000000259830_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car next to the car with its door open",
    "image": "val2017/000000357737.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car next to the car with its door open.",
    "solution": [
      576.36,
      88.04,
      583.4300000000001,
      91.39
    ],
    "normalized_solution": [
      901,
      183,
      912,
      190
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 82,
    "file_name": "000000357737.jpg",
    "annotation_id": "000000357737_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "a bicycle that is not placed on the ground",
    "image": "val2017/000000055022.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a bicycle that is not placed on the ground.",
    "solution": [
      245.25,
      0.76,
      281.89,
      80.16000000000001
    ],
    "normalized_solution": [
      511,
      1,
      587,
      125
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "6"
    },
    "image_index": 83,
    "file_name": "000000055022.jpg",
    "annotation_id": "000000055022_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a person who is neither standing, sitting, walking, nor skateboarding",
    "image": "val2017/000000087038.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person who is neither standing, sitting, walking, nor skateboarding.",
    "solution": [
      257.85,
      224.48,
      301.98,
      321.48
    ],
    "normalized_solution": [
      403,
      468,
      472,
      670
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 84,
    "file_name": "000000087038.jpg",
    "annotation_id": "000000087038_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 543,
    "width": 640,
    "normal_caption": "a person who is not on the sidewalk and is carrying a bag that is not blue",
    "image": "val2017/000000577932.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person who is not on the sidewalk and is carrying a bag that is not blue.",
    "solution": [
      231.84,
      233.37,
      314.82,
      492.06
    ],
    "normalized_solution": [
      362,
      430,
      492,
      906
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "10"
    },
    "image_index": 85,
    "file_name": "000000577932.jpg",
    "annotation_id": "000000577932_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 335,
    "width": 500,
    "normal_caption": "a motorcycle facing toward the road with a red seat",
    "image": "val2017/000000356387.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a motorcycle facing toward the road with a red seat.",
    "solution": [
      216.26,
      220.98,
      312.12,
      308.39
    ],
    "normalized_solution": [
      433,
      660,
      624,
      921
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 86,
    "file_name": "000000356387.jpg",
    "annotation_id": "000000356387_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "a vehicle that has a backrest and does not have four wheels",
    "image": "val2017/000000441586.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a vehicle that has a backrest and does not have four wheels.",
    "solution": [
      395.66,
      146.02,
      426.92,
      224.5
    ],
    "normalized_solution": [
      618,
      344,
      667,
      528
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 88,
    "file_name": "000000441586.jpg",
    "annotation_id": "000000441586_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 485,
    "width": 640,
    "normal_caption": "a boat with a red top and a white hull",
    "image": "val2017/000000228436.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a boat with a red top and a white hull.",
    "solution": [
      287.59,
      138.45,
      356.13,
      167.37
    ],
    "normalized_solution": [
      449,
      285,
      556,
      345
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [],
      "occluded": false,
      "distractors": "12"
    },
    "image_index": 89,
    "file_name": "000000228436.jpg",
    "annotation_id": "000000228436_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "a person next to a bicycle lying on the ground who is not making a phone call",
    "image": "val2017/000000414510.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person next to a bicycle lying on the ground who is not making a phone call.",
    "solution": [
      54.6,
      267.4,
      134.32,
      388.39
    ],
    "normalized_solution": [
      114,
      418,
      280,
      607
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 90,
    "file_name": "000000414510.jpg",
    "annotation_id": "000000414510_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "a bus moving toward the camera with blue on its front",
    "image": "val2017/000000210273.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a bus moving toward the camera with blue on its front.",
    "solution": [
      362.04,
      118.05,
      424.51,
      194.73000000000002
    ],
    "normalized_solution": [
      566,
      276,
      663,
      455
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": true,
      "distractors": "13"
    },
    "image_index": 91,
    "file_name": "000000210273.jpg",
    "annotation_id": "000000210273_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a person standing at the doorway and eating something",
    "image": "val2017/000000507037.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a person standing at the doorway and eating something.",
    "solution": [
      0,
      246.23,
      25.34,
      383.58
    ],
    "normalized_solution": [
      0,
      513,
      40,
      799
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "13"
    },
    "image_index": 92,
    "file_name": "000000507037.jpg",
    "annotation_id": "000000507037_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the man wearing backpack to the left side of the red-shirt girl, not the boy",
    "image": "val2017/000000350122.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man wearing backpack to the left side of the red-shirt girl, not the boy.",
    "solution": [
      96.9,
      206.17,
      151.79000000000002,
      380.67999999999995
    ],
    "normalized_solution": [
      151,
      430,
      237,
      793
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 93,
    "file_name": "000000350122.jpg",
    "annotation_id": "000000350122_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the one standing above stairs, not near bike or motor",
    "image": "val2017/000000038829.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the one standing above stairs, not near bike or motor.",
    "solution": [
      392.03,
      60.98,
      418.64,
      133.46
    ],
    "normalized_solution": [
      613,
      143,
      654,
      313
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 94,
    "file_name": "000000038829.jpg",
    "annotation_id": "000000038829_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 433,
    "normal_caption": "the black motor on the front, close to the red motor, not close to the green bike",
    "image": "val2017/000000291634.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the black motor on the front, close to the red motor, not close to the green bike.",
    "solution": [
      17,
      224.07,
      168.41,
      384.39
    ],
    "normalized_solution": [
      39,
      350,
      389,
      601
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 97,
    "file_name": "000000291634.jpg",
    "annotation_id": "000000291634_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 481,
    "width": 640,
    "normal_caption": "the third one from the back of the boat",
    "image": "val2017/000000395180.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the third one from the back of the boat.",
    "solution": [
      477.48,
      189.92,
      493.46000000000004,
      203.54999999999998
    ],
    "normalized_solution": [
      746,
      395,
      771,
      423
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 101,
    "file_name": "000000395180.jpg",
    "annotation_id": "000000395180_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 333,
    "width": 500,
    "normal_caption": "the motor close to the woman's red motor",
    "image": "val2017/000000226417.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the motor close to the woman's red motor.",
    "solution": [
      194.7,
      197.58,
      231.32999999999998,
      262.70000000000005
    ],
    "normalized_solution": [
      389,
      593,
      463,
      789
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 103,
    "file_name": "000000226417.jpg",
    "annotation_id": "000000226417_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 333,
    "normal_caption": "The light near the '24 hour' sign with only three signals",
    "image": "val2017/000000301376.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: The light near the '24 hour' sign with only three signals.",
    "solution": [
      83.29,
      94.92,
      111.14000000000001,
      152.57
    ],
    "normalized_solution": [
      250,
      190,
      334,
      305
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 111,
    "file_name": "000000301376.jpg",
    "annotation_id": "000000301376_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the guy on the right side, red shirt, with no hat",
    "image": "val2017/000000455624.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the guy on the right side, red shirt, with no hat.",
    "solution": [
      614.54,
      143.23,
      640,
      206.35999999999999
    ],
    "normalized_solution": [
      960,
      335,
      1000,
      483
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 127,
    "file_name": "000000455624.jpg",
    "annotation_id": "000000455624_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 453,
    "width": 640,
    "normal_caption": "red cat on the blue motor",
    "image": "val2017/000000139099.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: red cat on the blue motor.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "23"
    },
    "image_index": 122,
    "file_name": "000000139099.jpg",
    "annotation_id": "000000139099_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the girl who is not a reflection in the glass",
    "image": "val2017/000000292456.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the girl who is not a reflection in the glass.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 123,
    "file_name": "000000292456.jpg",
    "annotation_id": "000000292456_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 400,
    "width": 600,
    "normal_caption": "the guy closest to the motor with a black box in the back",
    "image": "val2017/000000534605.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the guy closest to the motor with a black box in the back.",
    "solution": [
      283.68,
      97.14,
      323.75,
      216.22
    ],
    "normalized_solution": [
      473,
      243,
      540,
      541
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 124,
    "file_name": "000000534605.jpg",
    "annotation_id": "000000534605_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the light with green signal on",
    "image": "val2017/000000178982.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the light with green signal on.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 125,
    "file_name": "000000178982.jpg",
    "annotation_id": "000000178982_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 333,
    "normal_caption": "the motorcycle being leaned on by the person in the striped shirt",
    "image": "val2017/000000574702.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the motorcycle being leaned on by the person in the striped shirt.",
    "solution": [
      85.46,
      215.72,
      119.69,
      302.77
    ],
    "normalized_solution": [
      257,
      431,
      359,
      606
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 128,
    "file_name": "000000574702.jpg",
    "annotation_id": "000000574702_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 420,
    "width": 640,
    "normal_caption": "the guy on the wider motor, and his clothes is orange",
    "image": "val2017/000000246963.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the guy on the wider motor, and his clothes is orange.",
    "solution": [
      167.62,
      151.24,
      233.54000000000002,
      242.58
    ],
    "normalized_solution": [
      262,
      360,
      365,
      578
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 129,
    "file_name": "000000246963.jpg",
    "annotation_id": "000000246963_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 403,
    "width": 640,
    "normal_caption": "the kite that flies the third highest in the middle",
    "image": "val2017/000000345027.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the kite that flies the third highest in the middle.",
    "solution": [
      310.6,
      183.89,
      326.46000000000004,
      189.20999999999998
    ],
    "normalized_solution": [
      485,
      456,
      510,
      470
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 131,
    "file_name": "000000345027.jpg",
    "annotation_id": "000000345027_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the book with cover of same color as the page",
    "image": "val2017/000000200839.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the book with cover of same color as the page.",
    "solution": [
      143.97,
      240.83,
      176.81,
      268.65000000000003
    ],
    "normalized_solution": [
      225,
      502,
      276,
      560
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 134,
    "file_name": "000000200839.jpg",
    "annotation_id": "000000200839_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person on the right side of the row with no one wearing hat but one wearing hairband",
    "image": "val2017/000000057672.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the right side of the row with no one wearing hat but one wearing hairband.",
    "solution": [
      417.03,
      191.5,
      484.16999999999996,
      289.63
    ],
    "normalized_solution": [
      652,
      399,
      757,
      603
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    },
    "image_index": 136,
    "file_name": "000000057672.jpg",
    "annotation_id": "000000057672_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the guy with brown jeans, black hoodie and a suitcase walking in the street",
    "image": "val2017/000000138639.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the guy with brown jeans, black hoodie and a suitcase walking in the street.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "4",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "14"
    },
    "image_index": 108,
    "file_name": "000000138639.jpg",
    "annotation_id": "000000138639_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the man between the yellow-coat guy and the blue-shirt woman, hair not yellow",
    "image": "val2017/000000078748.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man between the yellow-coat guy and the blue-shirt woman, hair not yellow.",
    "solution": [
      244.74,
      13.38,
      289.17,
      111.38
    ],
    "normalized_solution": [
      382,
      28,
      452,
      232
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 121,
    "file_name": "000000078748.jpg",
    "annotation_id": "000000078748_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 336,
    "width": 500,
    "normal_caption": "the white car next to the red car, in front of the car that's tilted to the side",
    "image": "val2017/000000111086.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white car next to the red car, in front of the car that's tilted to the side.",
    "solution": [
      126.86,
      201,
      156.21,
      232.27
    ],
    "normalized_solution": [
      254,
      598,
      312,
      691
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "11"
    },
    "image_index": 113,
    "file_name": "000000111086.jpg",
    "annotation_id": "000000111086_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 569,
    "width": 640,
    "normal_caption": "the man with glasses, not in the car nor driving the motor",
    "image": "val2017/000000461751.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man with glasses, not in the car nor driving the motor.",
    "solution": [
      464.34,
      120.29,
      640,
      569
    ],
    "normalized_solution": [
      726,
      211,
      1000,
      1000
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 115,
    "file_name": "000000461751.jpg",
    "annotation_id": "000000461751_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "yellow taxi, not on the slope, close to the big bus",
    "image": "val2017/000000336232.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: yellow taxi, not on the slope, close to the big bus.",
    "solution": [
      412.46,
      107.39,
      471.75,
      156.45
    ],
    "normalized_solution": [
      644,
      251,
      737,
      366
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 130,
    "file_name": "000000336232.jpg",
    "annotation_id": "000000336232_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the man with shirt hair, sitting behind the long-hair guy",
    "image": "val2017/000000248334.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man with shirt hair, sitting behind the long-hair guy.",
    "solution": [
      469.42,
      186.72,
      487.43,
      221.01999999999998
    ],
    "normalized_solution": [
      939,
      498,
      975,
      589
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "8"
    },
    "image_index": 137,
    "file_name": "000000248334.jpg",
    "annotation_id": "000000248334_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the one not inside the bus, but close to the door",
    "image": "val2017/000000445834.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the one not inside the bus, but close to the door.",
    "solution": [
      424.1,
      180.42,
      517.0500000000001,
      415.7
    ],
    "normalized_solution": [
      663,
      423,
      808,
      974
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 139,
    "file_name": "000000445834.jpg",
    "annotation_id": "000000445834_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 425,
    "normal_caption": "the one with dark color cloth, not riding bike",
    "image": "val2017/000000472623.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the one with dark color cloth, not riding bike.",
    "solution": [
      125.81,
      239.86,
      152.76,
      305.90000000000003
    ],
    "normalized_solution": [
      296,
      375,
      359,
      478
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 140,
    "file_name": "000000472623.jpg",
    "annotation_id": "000000472623_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "the red-shirt person, with no hat on",
    "image": "val2017/000000244833.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the red-shirt person, with no hat on.",
    "solution": [
      547.17,
      12.75,
      613.73,
      119.36
    ],
    "normalized_solution": [
      855,
      30,
      959,
      279
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 141,
    "file_name": "000000244833.jpg",
    "annotation_id": "000000244833_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 361,
    "width": 640,
    "normal_caption": "the bag carried by the person with a purple umbrella and pulling a small suitcase",
    "image": "val2017/000000191845.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bag carried by the person with a purple umbrella and pulling a small suitcase.",
    "solution": [
      436.05,
      217.51,
      466.85,
      254.57999999999998
    ],
    "normalized_solution": [
      681,
      603,
      729,
      705
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    },
    "image_index": 143,
    "file_name": "000000191845.jpg",
    "annotation_id": "000000191845_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 470,
    "width": 640,
    "normal_caption": "the guy on the second row, not near the ones with umbrella",
    "image": "val2017/000000267537.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the guy on the second row, not near the ones with umbrella.",
    "solution": [
      498.75,
      0.28,
      635.88,
      234.72
    ],
    "normalized_solution": [
      779,
      1,
      994,
      499
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 144,
    "file_name": "000000267537.jpg",
    "annotation_id": "000000267537_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 421,
    "normal_caption": "the girl next to the man wearing backpack pointing somewhere, on the stairs",
    "image": "val2017/000000370486.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the girl next to the man wearing backpack pointing somewhere, on the stairs.",
    "solution": [
      41.32,
      53.59,
      76.08,
      113.12
    ],
    "normalized_solution": [
      98,
      84,
      181,
      177
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 145,
    "file_name": "000000370486.jpg",
    "annotation_id": "000000370486_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the chair only able to be seen through the middle window, on the left",
    "image": "val2017/000000333745.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair only able to be seen through the middle window, on the left.",
    "solution": [
      150.39,
      33.71,
      206.79,
      95.23
    ],
    "normalized_solution": [
      352,
      53,
      484,
      149
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "5"
    },
    "image_index": 146,
    "file_name": "000000333745.jpg",
    "annotation_id": "000000333745_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person on the right side from the single man's perspective, not holding beer",
    "image": "val2017/000000074058.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the right side from the single man's perspective, not holding beer.",
    "solution": [
      27.67,
      158.53,
      102.07000000000001,
      334.65
    ],
    "normalized_solution": [
      43,
      371,
      159,
      784
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 147,
    "file_name": "000000074058.jpg",
    "annotation_id": "000000074058_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the bed no one sitting on, and not the upper bed",
    "image": "val2017/000000393569.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bed no one sitting on, and not the upper bed.",
    "solution": [
      452.97,
      169.19,
      592.4300000000001,
      322.7
    ],
    "normalized_solution": [
      708,
      352,
      926,
      672
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 150,
    "file_name": "000000393569.jpg",
    "annotation_id": "000000393569_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 428,
    "normal_caption": "the cup facing right, not the rightmost one",
    "image": "val2017/000000292060.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cup facing right, not the rightmost one.",
    "solution": [
      271.28,
      271.82,
      296.09,
      298.78999999999996
    ],
    "normalized_solution": [
      634,
      425,
      692,
      467
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 157,
    "file_name": "000000292060.jpg",
    "annotation_id": "000000292060_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the white cup, beside the sink",
    "image": "val2017/000000437898.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white cup, beside the sink.",
    "solution": [
      65.61,
      228.82,
      82.41,
      249.57999999999998
    ],
    "normalized_solution": [
      103,
      536,
      129,
      584
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 158,
    "file_name": "000000437898.jpg",
    "annotation_id": "000000437898_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the green cup on top of an array of glasses, not upright",
    "image": "val2017/000000052996.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the green cup on top of an array of glasses, not upright.",
    "solution": [
      118.01,
      269.13,
      151.59,
      294.07
    ],
    "normalized_solution": [
      184,
      632,
      237,
      690
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 159,
    "file_name": "000000052996.jpg",
    "annotation_id": "000000052996_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "the knife beside the pineapple, third from the left",
    "image": "val2017/000000078266.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the knife beside the pineapple, third from the left.",
    "solution": [
      284.1,
      200.63,
      290.89000000000004,
      209.12
    ],
    "normalized_solution": [
      444,
      469,
      455,
      489
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 160,
    "file_name": "000000078266.jpg",
    "annotation_id": "000000078266_1744240036432"
  },
  {
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the bowl on the same cabinet shelf as the small yellow object",
    "image": "val2017/000000156278.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bowl on the same cabinet shelf as the small yellow object.",
    "solution": [
      278.52,
      305.12,
      336.25,
      333.28000000000003
    ],
    "normalized_solution": [
      435,
      718,
      525,
      784
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 162,
    "file_name": "000000156278.jpg",
    "annotation_id": "000000156278_1744240036432"
  },
  {
    "annotation_id": "38829_1742593294302",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person standing above stairs, not near any bikes or motorcycles",
    "image": "val2017/000000038829.jpg",
    "file_name": "000000038829.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person standing above stairs, not near any bikes or motorcycles.",
    "solution": [
      392.03,
      60.98,
      418.64,
      133.46
    ],
    "normalized_solution": [
      613,
      143,
      654,
      313
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 94
  },
  {
    "annotation_id": "309391_1742594615011",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 384,
    "width": 640,
    "normal_caption": "a black car that is not moving away from the camera",
    "image": "val2017/000000309391.jpg",
    "file_name": "000000309391.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a black car that is not moving away from the camera.",
    "solution": [
      311.42,
      189.69,
      364.25,
      213.92
    ],
    "normalized_solution": [
      487,
      494,
      569,
      557
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "7"
    },
    "image_index": 81
  },
  {
    "annotation_id": "122166_1742595465272",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car in front of a black Audi sedan",
    "image": "val2017/000000122166.jpg",
    "file_name": "000000122166.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car in front of a black Audi sedan.",
    "solution": [
      158.18,
      264.32,
      323.15999999999997,
      417.38
    ],
    "normalized_solution": [
      247,
      551,
      505,
      870
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 87
  },
  {
    "annotation_id": "122166_1742595533439",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car in front of a black Audi sedan",
    "image": "val2017/000000122166.jpg",
    "file_name": "000000122166.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car in front of a black Audi sedan.",
    "solution": [
      158.18,
      264.32,
      323.15999999999997,
      417.38
    ],
    "normalized_solution": [
      247,
      551,
      505,
      870
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 87
  },
  {
    "annotation_id": "241319_1742939549372",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 476,
    "width": 640,
    "normal_caption": "the reflection of the toothbrush that is not white",
    "image": "val2017/000000241319.jpg",
    "file_name": "000000241319.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the reflection of the toothbrush that is not white.",
    "solution": [
      196.75,
      151.84,
      239.71,
      239.18
    ],
    "normalized_solution": [
      307,
      319,
      375,
      502
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 163
  },
  {
    "annotation_id": "89556_1742939838888",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car parked next to a fire hydrant, which is not an sedan",
    "image": "val2017/000000089556.jpg",
    "file_name": "000000089556.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car parked next to a fire hydrant, which is not an sedan.",
    "solution": [
      321.15,
      127.77,
      627.64,
      328.29
    ],
    "normalized_solution": [
      502,
      266,
      981,
      684
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 168
  },
  {
    "annotation_id": "292997_1742940912411",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the lower traffic light mounted on the pole struck by a car",
    "image": "val2017/000000292997.jpg",
    "file_name": "000000292997.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the lower traffic light mounted on the pole struck by a car.",
    "solution": [
      479,
      227,
      498,
      261
    ],
    "normalized_solution": [
      748,
      473,
      778,
      544
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 169
  },
  {
    "annotation_id": "295809_1742963403240",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 512,
    "width": 640,
    "normal_caption": "the traffic light on the pole next to the black car on the left side, located at the upper left corner",
    "image": "val2017/000000295809.jpg",
    "file_name": "000000295809.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the traffic light on the pole next to the black car on the left side, located at the upper left corner.",
    "solution": [
      71.87,
      38.93,
      81.72,
      64.25999999999999
    ],
    "normalized_solution": [
      112,
      76,
      128,
      126
    ],
    "categories": {
      "empty_case": false,
      "hops": "5",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 170
  },
  {
    "annotation_id": "295809_1742963434580",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 512,
    "width": 640,
    "normal_caption": "the traffic light on the pole next to the black car on the left side, located at the upper right corner",
    "image": "val2017/000000295809.jpg",
    "file_name": "000000295809.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the traffic light on the pole next to the black car on the left side, located at the upper right corner.",
    "solution": [
      82.52,
      35.19,
      94.11,
      65.32
    ],
    "normalized_solution": [
      129,
      69,
      147,
      128
    ],
    "categories": {
      "empty_case": false,
      "hops": "5",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 170
  },
  {
    "annotation_id": "227511_1743028736038",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the parked car facing away from the camera, nearest to the silver car driving towards the camera",
    "image": "val2017/000000227511.jpg",
    "file_name": "000000227511.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the parked car facing away from the camera, nearest to the silver car driving towards the camera.",
    "solution": [
      182.65,
      258.59,
      195.41,
      267.9
    ],
    "normalized_solution": [
      365,
      690,
      391,
      714
    ],
    "categories": {
      "empty_case": false,
      "hops": "5",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 171
  },
  {
    "annotation_id": "418696_1743028923790",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the green traffic light hanging from a wire above the intersection, with the church tower behind it",
    "image": "val2017/000000418696.jpg",
    "file_name": "000000418696.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the green traffic light hanging from a wire above the intersection, with the church tower behind it.",
    "solution": [
      348.6,
      172.76,
      358.79,
      182.04999999999998
    ],
    "normalized_solution": [
      545,
      405,
      561,
      426
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "5"
    },
    "image_index": 172
  },
  {
    "annotation_id": "480944_1743029152077",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the sedan in front of the blue truck",
    "image": "val2017/000000480944.jpg",
    "file_name": "000000480944.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the sedan in front of the blue truck.",
    "solution": [
      132.62,
      356.49,
      225.3,
      392.09000000000003
    ],
    "normalized_solution": [
      276,
      557,
      469,
      613
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 173
  },
  {
    "annotation_id": "480944_1743029418875",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the wagon in front of the red truck",
    "image": "val2017/000000480944.jpg",
    "file_name": "000000480944.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the wagon in front of the red truck.",
    "solution": [
      21.07,
      354.61,
      123.52000000000001,
      398.21000000000004
    ],
    "normalized_solution": [
      44,
      554,
      257,
      622
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "6"
    },
    "image_index": 173
  },
  {
    "annotation_id": "412531_1743029524744",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the white car partially obscured by the bush",
    "image": "val2017/000000412531.jpg",
    "file_name": "000000412531.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white car partially obscured by the bush.",
    "solution": [
      333.89,
      280.56,
      389.08,
      327.04
    ],
    "normalized_solution": [
      522,
      585,
      608,
      681
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 175
  },
  {
    "annotation_id": "183709_1743029836053",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person wearing a dark jacket and carrying a shoulder bag",
    "image": "val2017/000000183709.jpg",
    "file_name": "000000183709.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a dark jacket and carrying a shoulder bag.",
    "solution": [
      215.07,
      223.54,
      232,
      277.55
    ],
    "normalized_solution": [
      448,
      349,
      483,
      434
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 176
  },
  {
    "annotation_id": "183709_1743029968398",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person standing on the traffic island waiting for the traffic light, wearing a white jacket",
    "image": "val2017/000000183709.jpg",
    "file_name": "000000183709.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person standing on the traffic island waiting for the traffic light, wearing a white jacket.",
    "solution": [
      215.07,
      223.54,
      232,
      277.55
    ],
    "normalized_solution": [
      448,
      349,
      483,
      434
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 176
  },
  {
    "annotation_id": "301135_1743032969026",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 428,
    "normal_caption": "the person who is neither standing nor lying on the bench, wearing sunglasses and holding a bag",
    "image": "val2017/000000301135.jpg",
    "file_name": "000000301135.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is neither standing nor lying on the bench, wearing sunglasses and holding a bag.",
    "solution": [
      206.97,
      396,
      278.90999999999997,
      541.22
    ],
    "normalized_solution": [
      484,
      619,
      652,
      846
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    },
    "image_index": 177
  },
  {
    "annotation_id": "301135_1743033605992",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 428,
    "normal_caption": "the handbag held by the person sitting on the same bench as the person wearing long blue jeans",
    "image": "val2017/000000301135.jpg",
    "file_name": "000000301135.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the handbag held by the person sitting on the same bench as the person wearing long blue jeans.",
    "solution": [
      126.87,
      422.93,
      164.79000000000002,
      442.27
    ],
    "normalized_solution": [
      296,
      661,
      385,
      691
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 177
  },
  {
    "annotation_id": "199771_1743034817144",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person wearing a black hat and plastic gloves, with a hand resting on the table",
    "image": "val2017/000000199771.jpg",
    "file_name": "000000199771.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a black hat and plastic gloves, with a hand resting on the table.",
    "solution": [
      244.85,
      104.07,
      343.43,
      270.86
    ],
    "normalized_solution": [
      383,
      245,
      537,
      637
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "9"
    },
    "image_index": 181
  },
  {
    "annotation_id": "504074_1743035255690",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the chair occupied by the person who does not have a laptop on the lap",
    "image": "val2017/000000504074.jpg",
    "file_name": "000000504074.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair occupied by the person who does not have a laptop on the lap.",
    "solution": [
      41,
      138,
      191,
      349
    ],
    "normalized_solution": [
      64,
      323,
      298,
      817
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 182
  },
  {
    "annotation_id": "298396_1743035742441",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the third knife from the top, hanging horizontally on the left-side wall",
    "image": "val2017/000000298396.jpg",
    "file_name": "000000298396.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the third knife from the top, hanging horizontally on the left-side wall.",
    "solution": [
      148.81,
      173.81,
      179.17000000000002,
      181.57
    ],
    "normalized_solution": [
      233,
      362,
      280,
      378
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 183
  },
  {
    "annotation_id": "298396_1743035848865",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the second knife from the top, hanging horizontally on the left-side wall",
    "image": "val2017/000000298396.jpg",
    "file_name": "000000298396.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the second knife from the top, hanging horizontally on the left-side wall.",
    "solution": [
      149.15,
      159.75,
      177.64000000000001,
      166.65
    ],
    "normalized_solution": [
      233,
      333,
      278,
      347
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 183
  },
  {
    "annotation_id": "298396_1743035931591",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the fifth knife from the top, hanging horizontally on the left-side wall",
    "image": "val2017/000000298396.jpg",
    "file_name": "000000298396.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the fifth knife from the top, hanging horizontally on the left-side wall.",
    "solution": [
      154.43,
      189.16,
      173.88,
      191.64
    ],
    "normalized_solution": [
      241,
      394,
      272,
      399
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 183
  },
  {
    "annotation_id": "479126_1743035982786",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the chair that is sitted by a person with a laptop on the lap",
    "image": "val2017/000000479126.jpg",
    "file_name": "000000479126.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the chair that is sitted by a person with a laptop on the lap.",
    "solution": [
      519.32,
      266.88,
      640,
      421.71000000000004
    ],
    "normalized_solution": [
      811,
      625,
      1000,
      988
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 184
  },
  {
    "annotation_id": "34873_1743037312583",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "one of the two chairs with identical backrest patterns and closer to the corner of the two walls",
    "image": "val2017/000000034873.jpg",
    "file_name": "000000034873.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: one of the two chairs with identical backrest patterns and closer to the corner of the two walls.",
    "solution": [
      482.45,
      169.57,
      528.5,
      219.01999999999998
    ],
    "normalized_solution": [
      754,
      353,
      826,
      456
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 185
  },
  {
    "annotation_id": "469192_1743038252862",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the kite located directly above the kite shaped like a green gecko",
    "image": "val2017/000000469192.jpg",
    "file_name": "000000469192.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the kite located directly above the kite shaped like a green gecko.",
    "solution": [
      508.69,
      50.06,
      549.5,
      70.32000000000001
    ],
    "normalized_solution": [
      795,
      104,
      859,
      147
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "12"
    },
    "image_index": 188
  },
  {
    "annotation_id": "567197_1743038636134",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 407,
    "width": 500,
    "normal_caption": "the car behind the one with its wheels turned right, facing towards the camera",
    "image": "val2017/000000567197.jpg",
    "file_name": "000000567197.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car behind the one with its wheels turned right, facing towards the camera.",
    "solution": [
      45.85,
      302.29,
      72.87,
      328.40000000000003
    ],
    "normalized_solution": [
      92,
      743,
      146,
      807
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 189
  },
  {
    "annotation_id": "492362_1743038892795",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the middle hotdog image on the food cart beneath the halal food sign",
    "image": "val2017/000000492362.jpg",
    "file_name": "000000492362.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the middle hotdog image on the food cart beneath the halal food sign.",
    "solution": [
      80.23,
      224.22,
      121.35,
      245.95
    ],
    "normalized_solution": [
      188,
      350,
      284,
      384
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 190
  },
  {
    "annotation_id": "78404_1743039916102",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 350,
    "width": 500,
    "normal_caption": "the women sitting on the right side of the chair",
    "image": "val2017/000000078404.jpg",
    "file_name": "000000078404.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the women sitting on the right side of the chair.",
    "solution": [
      218.06,
      9.28,
      405.3,
      306.34999999999997
    ],
    "normalized_solution": [
      436,
      27,
      811,
      875
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 191
  },
  {
    "annotation_id": "173799_1743040072713",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 524,
    "width": 640,
    "normal_caption": "the elephant standing on higher terrain behind the person who is not wearing a hat",
    "image": "val2017/000000173799.jpg",
    "file_name": "000000173799.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the elephant standing on higher terrain behind the person who is not wearing a hat.",
    "solution": [
      68.32,
      132.5,
      141,
      189.61
    ],
    "normalized_solution": [
      107,
      253,
      220,
      362
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "13"
    },
    "image_index": 192
  },
  {
    "annotation_id": "110042_1743041705366",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 425,
    "normal_caption": "the person who is not in a tent, facing away from the camera",
    "image": "val2017/000000110042.jpg",
    "file_name": "000000110042.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is not in a tent, facing away from the camera.",
    "solution": [
      81.58,
      105.96,
      112.33,
      206.42
    ],
    "normalized_solution": [
      192,
      166,
      264,
      323
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "4"
    },
    "image_index": 193
  },
  {
    "annotation_id": "580294_1743041892447",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 443,
    "width": 640,
    "normal_caption": "the empty plate that is not being used as a lid to cover the pot",
    "image": "val2017/000000580294.jpg",
    "file_name": "000000580294.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the empty plate that is not being used as a lid to cover the pot.",
    "solution": [
      389,
      123,
      420,
      193
    ],
    "normalized_solution": [
      608,
      278,
      656,
      436
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 194
  },
  {
    "annotation_id": "16249_1743042113421",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 365,
    "width": 500,
    "normal_caption": "the empty bench next to the bench occupied by a person reading a newspaper",
    "image": "val2017/000000016249.jpg",
    "file_name": "000000016249.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the empty bench next to the bench occupied by a person reading a newspaper.",
    "solution": [
      222.9,
      199.99,
      286.01,
      312.73
    ],
    "normalized_solution": [
      446,
      548,
      572,
      857
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 196
  },
  {
    "annotation_id": "16249_1743196211645",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 365,
    "width": 500,
    "normal_caption": "person sitting without glasses and with white hair",
    "image": "val2017/000000016249.jpg",
    "file_name": "000000016249.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person sitting without glasses and with white hair.",
    "solution": [
      314.46,
      98.67,
      454.03999999999996,
      281.57
    ],
    "normalized_solution": [
      629,
      270,
      908,
      771
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 196
  },
  {
    "annotation_id": "346703_1743196558721",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 550,
    "normal_caption": "an incomplete cake without star-shaped decoration",
    "image": "val2017/000000346703.jpg",
    "file_name": "000000346703.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: an incomplete cake without star-shaped decoration.",
    "solution": [
      207.57,
      552.07,
      376.22,
      640
    ],
    "normalized_solution": [
      377,
      863,
      684,
      1000
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 197
  },
  {
    "annotation_id": "346703_1743196756464",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 550,
    "normal_caption": "the person not holding a spoon, wearing white clothing and no hat",
    "image": "val2017/000000346703.jpg",
    "file_name": "000000346703.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person not holding a spoon, wearing white clothing and no hat.",
    "solution": [
      186.64,
      376.36,
      336.40999999999997,
      583.1600000000001
    ],
    "normalized_solution": [
      339,
      588,
      612,
      911
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "6"
    },
    "image_index": 197
  },
  {
    "annotation_id": "346703_1743196973149",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 550,
    "normal_caption": "the person on the left hand side of the person wearing a hat",
    "image": "val2017/000000346703.jpg",
    "file_name": "000000346703.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the left hand side of the person wearing a hat.",
    "solution": [
      316.19,
      129.38,
      549.66,
      366.81
    ],
    "normalized_solution": [
      575,
      202,
      999,
      573
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "6"
    },
    "image_index": 197
  },
  {
    "annotation_id": "294350_1743197098773",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person wearing a hat and not facing the camera",
    "image": "val2017/000000294350.jpg",
    "file_name": "000000294350.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a hat and not facing the camera.",
    "solution": [
      70.03,
      126.77,
      130.69,
      161.13
    ],
    "normalized_solution": [
      109,
      298,
      204,
      379
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "6"
    },
    "image_index": 198
  },
  {
    "annotation_id": "252219_1743197273559",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "the person walking not beneath an umbrella",
    "image": "val2017/000000252219.jpg",
    "file_name": "000000252219.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person walking not beneath an umbrella.",
    "solution": [
      9.79,
      167.06,
      131.73,
      393.51
    ],
    "normalized_solution": [
      15,
      390,
      206,
      919
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 199
  },
  {
    "annotation_id": "104572_1743260963696",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 419,
    "width": 640,
    "normal_caption": "the sink not in the mirror and closest to the paper towel dispenser",
    "image": "val2017/000000104572.jpg",
    "file_name": "000000104572.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the sink not in the mirror and closest to the paper towel dispenser.",
    "solution": [
      90.38,
      292.39,
      234.38,
      369.32
    ],
    "normalized_solution": [
      141,
      698,
      366,
      881
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 217
  },
  {
    "annotation_id": "283785_1743261209235",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 336,
    "width": 500,
    "normal_caption": "the teddy bear held by a person with a hat not facing the camera",
    "image": "val2017/000000283785.jpg",
    "file_name": "000000283785.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the teddy bear held by a person with a hat not facing the camera.",
    "solution": [
      47.64,
      204.77,
      89.64,
      239.76000000000002
    ],
    "normalized_solution": [
      95,
      609,
      179,
      714
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "5"
    },
    "image_index": 219
  },
  {
    "annotation_id": "534664_1743261317008",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 404,
    "width": 640,
    "normal_caption": "the all brown leather suitcase with a tag on it",
    "image": "val2017/000000534664.jpg",
    "file_name": "000000534664.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the all brown leather suitcase with a tag on it.",
    "solution": [
      415.83,
      114.19,
      608.73,
      259.78
    ],
    "normalized_solution": [
      650,
      283,
      951,
      643
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 220
  },
  {
    "annotation_id": "555597_1743261397143",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 517,
    "width": 640,
    "normal_caption": "the white car closest to a truck",
    "image": "val2017/000000555597.jpg",
    "file_name": "000000555597.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white car closest to a truck.",
    "solution": [
      306.02,
      386.98,
      396.42999999999995,
      425.69
    ],
    "normalized_solution": [
      478,
      749,
      619,
      823
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 221
  },
  {
    "annotation_id": "276018_1743262502730",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 416,
    "normal_caption": "the person in blue jacket holding a grey doll",
    "image": "val2017/000000276018.jpg",
    "file_name": "000000276018.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in blue jacket holding a grey doll.",
    "solution": [
      142.56,
      254.04,
      258.8,
      635.11
    ],
    "normalized_solution": [
      343,
      397,
      622,
      992
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "9"
    },
    "image_index": 223
  },
  {
    "annotation_id": "209613_1743262570421",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the dog facing the camera near a bush",
    "image": "val2017/000000209613.jpg",
    "file_name": "000000209613.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the dog facing the camera near a bush.",
    "solution": [
      168.52,
      182.74,
      201.58,
      212.66000000000003
    ],
    "normalized_solution": [
      263,
      428,
      315,
      498
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 227
  },
  {
    "annotation_id": "342367_1743262653518",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person sitting with a hat",
    "image": "val2017/000000342367.jpg",
    "file_name": "000000342367.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person sitting with a hat.",
    "solution": [
      411.24,
      277.76,
      547.94,
      425.63
    ],
    "normalized_solution": [
      643,
      579,
      856,
      887
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 237
  },
  {
    "annotation_id": "17627_1743519637856",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "a white car driving past a black car",
    "image": "val2017/000000017627.jpg",
    "file_name": "000000017627.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: a white car driving past a black car.",
    "solution": [
      264.65,
      235.3,
      375.21999999999997,
      302.59000000000003
    ],
    "normalized_solution": [
      414,
      490,
      586,
      630
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    },
    "image_index": 301
  },
  {
    "annotation_id": "211674_1743519813208",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 406,
    "width": 640,
    "normal_caption": "the person wearing a white hat looking towards the camera",
    "image": "val2017/000000211674.jpg",
    "file_name": "000000211674.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a white hat looking towards the camera.",
    "solution": [
      376.96,
      11.12,
      417.76,
      45.07
    ],
    "normalized_solution": [
      589,
      27,
      653,
      111
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 315
  },
  {
    "annotation_id": "156071_1743520253598",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person wearing a white cowboy hat on the right hand side of a person in a red top",
    "image": "val2017/000000156071.jpg",
    "file_name": "000000156071.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a white cowboy hat on the right hand side of a person in a red top.",
    "solution": [
      227.55,
      101.84,
      299.63,
      251
    ],
    "normalized_solution": [
      356,
      212,
      468,
      523
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "13"
    },
    "image_index": 322
  },
  {
    "annotation_id": "143556_1743520569040",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person wearing sunglasses riding a motorbike without a McDonald\u2019s sign on it",
    "image": "val2017/000000143556.jpg",
    "file_name": "000000143556.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing sunglasses riding a motorbike without a McDonald\u2019s sign on it.",
    "solution": [
      377.63,
      231.45,
      472.64,
      474.77
    ],
    "normalized_solution": [
      787,
      362,
      985,
      742
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 331
  },
  {
    "annotation_id": "7816_1743520727004",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person wearing a black top not facing the camera",
    "image": "val2017/000000007816.jpg",
    "file_name": "000000007816.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a black top not facing the camera.",
    "solution": [
      491.06,
      56.27,
      519.44,
      162.91
    ],
    "normalized_solution": [
      767,
      132,
      812,
      382
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 335
  },
  {
    "annotation_id": "194875_1743520851067",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 574,
    "width": 640,
    "normal_caption": "the person with long hair sitting right by the bar",
    "image": "val2017/000000194875.jpg",
    "file_name": "000000194875.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person with long hair sitting right by the bar.",
    "solution": [
      389.66,
      154.47,
      447.55,
      237.06
    ],
    "normalized_solution": [
      609,
      269,
      699,
      413
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "10"
    },
    "image_index": 338
  },
  {
    "annotation_id": "194875_1743520958164",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 574,
    "width": 640,
    "normal_caption": "the bottle with light orange liquor inside on the right hand side of a green bottle",
    "image": "val2017/000000194875.jpg",
    "file_name": "000000194875.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bottle with light orange liquor inside on the right hand side of a green bottle.",
    "solution": [
      344.67,
      95.8,
      354.88,
      136.62
    ],
    "normalized_solution": [
      539,
      167,
      555,
      238
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 338
  },
  {
    "annotation_id": "102411_1743521203776",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person wearing a white top facing away from the camera",
    "image": "val2017/000000102411.jpg",
    "file_name": "000000102411.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a white top facing away from the camera.",
    "solution": [
      202.34,
      174.08,
      216.86,
      213.57000000000002
    ],
    "normalized_solution": [
      316,
      408,
      339,
      500
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    },
    "image_index": 344
  },
  {
    "annotation_id": "109900_1743542454625",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 478,
    "width": 640,
    "normal_caption": "the person near a person holding a phone",
    "image": "val2017/000000109900.jpg",
    "file_name": "000000109900.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person near a person holding a phone.",
    "solution": [
      183.99,
      182.35,
      232.53,
      333
    ],
    "normalized_solution": [
      287,
      381,
      363,
      697
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 350
  },
  {
    "annotation_id": "284445_1743542826479",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 594,
    "width": 640,
    "normal_caption": "the person wearing a grey hat facing away from the camera",
    "image": "val2017/000000284445.jpg",
    "file_name": "000000284445.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a grey hat facing away from the camera.",
    "solution": [
      582.8,
      321.21,
      621.65,
      448.87
    ],
    "normalized_solution": [
      911,
      541,
      971,
      756
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "13"
    },
    "image_index": 387
  },
  {
    "annotation_id": "463199_1743543004006",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person in a blue top near the window",
    "image": "val2017/000000463199.jpg",
    "file_name": "000000463199.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a blue top near the window.",
    "solution": [
      216.43,
      134.65,
      274.4,
      242.49
    ],
    "normalized_solution": [
      338,
      281,
      429,
      505
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "11"
    },
    "image_index": 401
  },
  {
    "annotation_id": "1532_1743543184557",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the white car under the bridge",
    "image": "val2017/000000001532.jpg",
    "file_name": "000000001532.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white car under the bridge.",
    "solution": [
      106.19,
      375.71,
      185.28,
      435.29999999999995
    ],
    "normalized_solution": [
      166,
      783,
      290,
      907
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 419
  },
  {
    "annotation_id": "287291_1743543400698",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the person in a black top near a car",
    "image": "val2017/000000287291.jpg",
    "file_name": "000000287291.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a black top near a car.",
    "solution": [
      332.53,
      176.07,
      354.61999999999995,
      228.93
    ],
    "normalized_solution": [
      665,
      470,
      709,
      610
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 429
  },
  {
    "annotation_id": "303818_1744115681193",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person wearing white walking in front of a car",
    "image": "val2017/000000303818.jpg",
    "file_name": "000000303818.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing white walking in front of a car.",
    "solution": [
      11.78,
      184.89,
      25.91,
      217.25
    ],
    "normalized_solution": [
      25,
      289,
      54,
      339
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 449
  },
  {
    "annotation_id": "288584_1744115895091",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person wearing a hat near the bush",
    "image": "val2017/000000288584.jpg",
    "file_name": "000000288584.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a hat near the bush.",
    "solution": [
      399.17,
      143.93,
      489.37,
      399.17
    ],
    "normalized_solution": [
      624,
      337,
      765,
      935
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 450
  },
  {
    "annotation_id": "255917_1744116117577",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the grey car on the left side of a red car",
    "image": "val2017/000000255917.jpg",
    "file_name": "000000255917.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the grey car on the left side of a red car.",
    "solution": [
      50.5,
      329.7,
      130.23000000000002,
      384.96
    ],
    "normalized_solution": [
      79,
      772,
      203,
      902
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 456
  },
  {
    "annotation_id": "531134_1744116265191",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person wearing grey walking into an underpass",
    "image": "val2017/000000531134.jpg",
    "file_name": "000000531134.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing grey walking into an underpass.",
    "solution": [
      427.8,
      321.49,
      450.18,
      415.35
    ],
    "normalized_solution": [
      668,
      670,
      703,
      865
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 459
  },
  {
    "annotation_id": "162858_1744116338173",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 428,
    "normal_caption": "the black car behind a white car",
    "image": "val2017/000000162858.jpg",
    "file_name": "000000162858.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the black car behind a white car.",
    "solution": [
      359.14,
      339.46,
      426.90999999999997,
      542.75
    ],
    "normalized_solution": [
      839,
      530,
      997,
      848
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "12"
    },
    "image_index": 461
  },
  {
    "annotation_id": "412894_1744116578418",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the person wearing a white top and carrying a bag on the right shoulder",
    "image": "val2017/000000412894.jpg",
    "file_name": "000000412894.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a white top and carrying a bag on the right shoulder.",
    "solution": [
      0.82,
      537.34,
      63.81,
      640
    ],
    "normalized_solution": [
      2,
      840,
      149,
      1000
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 468
  },
  {
    "annotation_id": "88848_1744116699504",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 640,
    "normal_caption": "the person wearing sunglasses, positioned between two people",
    "image": "val2017/000000088848.jpg",
    "file_name": "000000088848.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing sunglasses, positioned between two people.",
    "solution": [
      468.19,
      470.56,
      519.9,
      614.79
    ],
    "normalized_solution": [
      732,
      735,
      812,
      961
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 472
  },
  {
    "annotation_id": "130826_1744116842828",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person wearing jeans and carrying a bag on the shoulder",
    "image": "val2017/000000130826.jpg",
    "file_name": "000000130826.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing jeans and carrying a bag on the shoulder.",
    "solution": [
      52.85,
      4.31,
      153.17,
      188.76
    ],
    "normalized_solution": [
      83,
      9,
      239,
      393
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "5"
    },
    "image_index": 476
  },
  {
    "annotation_id": "531707_1744116981433",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person sitting in the middle not wearing a hat",
    "image": "val2017/000000531707.jpg",
    "file_name": "000000531707.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person sitting in the middle not wearing a hat.",
    "solution": [
      331.89,
      221.08,
      392.43,
      376.76
    ],
    "normalized_solution": [
      519,
      461,
      613,
      785
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 485
  },
  {
    "annotation_id": "204186_1744117299968",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 513,
    "width": 640,
    "normal_caption": "the person in a white top not facing the camera",
    "image": "val2017/000000204186.jpg",
    "file_name": "000000204186.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top not facing the camera.",
    "solution": [
      521.14,
      66.78,
      562.13,
      190.28
    ],
    "normalized_solution": [
      814,
      130,
      878,
      371
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 517
  },
  {
    "annotation_id": "548780_1744117519828",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person in a white top not facing the camera",
    "image": "val2017/000000548780.jpg",
    "file_name": "000000548780.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top not facing the camera.",
    "solution": [
      175.6,
      0,
      261.96,
      210.14
    ],
    "normalized_solution": [
      274,
      0,
      409,
      492
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 532
  },
  {
    "annotation_id": "295231_1744117885971",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the sheep with dark face not facing the camera",
    "image": "val2017/000000295231.jpg",
    "file_name": "000000295231.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the sheep with dark face not facing the camera.",
    "solution": [
      311.07,
      160.92,
      458.86,
      321.4
    ],
    "normalized_solution": [
      648,
      251,
      956,
      502
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 597
  },
  {
    "annotation_id": "375763_1744118050795",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the sheep with a white face behind other sheep",
    "image": "val2017/000000375763.jpg",
    "file_name": "000000375763.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the sheep with a white face behind other sheep.",
    "solution": [
      161.15,
      182.81,
      204.73000000000002,
      210.83
    ],
    "normalized_solution": [
      252,
      381,
      320,
      439
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "11"
    },
    "image_index": 604
  },
  {
    "annotation_id": "430073_1744118285673",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person in a white top carrying a bag",
    "image": "val2017/000000430073.jpg",
    "file_name": "000000430073.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top carrying a bag.",
    "solution": [
      141,
      126,
      160,
      180
    ],
    "normalized_solution": [
      220,
      263,
      250,
      375
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "23"
    },
    "image_index": 615
  },
  {
    "annotation_id": "13659_1744118423931",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person on the right hand side of the person wearing a hat",
    "image": "val2017/000000013659.jpg",
    "file_name": "000000013659.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the right hand side of the person wearing a hat.",
    "solution": [
      331.36,
      94.09,
      461.70000000000005,
      265.38
    ],
    "normalized_solution": [
      518,
      196,
      721,
      553
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 633
  },
  {
    "annotation_id": "13659_1744118554804",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the red chair in front of a computer",
    "image": "val2017/000000013659.jpg",
    "file_name": "000000013659.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the red chair in front of a computer.",
    "solution": [
      188.62,
      124.46,
      277.81,
      194.67
    ],
    "normalized_solution": [
      295,
      259,
      434,
      406
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 633
  },
  {
    "annotation_id": "334555_1744118865354",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the person wearing a suit jacket standing by the wall",
    "image": "val2017/000000334555.jpg",
    "file_name": "000000334555.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a suit jacket standing by the wall.",
    "solution": [
      194.38,
      137.17,
      211.24,
      193.58999999999997
    ],
    "normalized_solution": [
      304,
      322,
      330,
      454
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "12"
    },
    "image_index": 660
  },
  {
    "annotation_id": "356612_1744119030948",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 416,
    "width": 640,
    "normal_caption": "the cow in front of a grey car",
    "image": "val2017/000000356612.jpg",
    "file_name": "000000356612.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cow in front of a grey car.",
    "solution": [
      224.82,
      199.42,
      283.78,
      299.53999999999996
    ],
    "normalized_solution": [
      351,
      479,
      443,
      720
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 665
  },
  {
    "annotation_id": "507797_1744119263307",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person wearing a white shirt facing away from the camera",
    "image": "val2017/000000507797.jpg",
    "file_name": "000000507797.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a white shirt facing away from the camera.",
    "solution": [
      147.26,
      168.7,
      206.04,
      360.69
    ],
    "normalized_solution": [
      230,
      397,
      322,
      849
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "7"
    },
    "image_index": 683
  },
  {
    "annotation_id": "70254_1744119539929",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 384,
    "width": 640,
    "normal_caption": "the person in a white top sitting on a bench",
    "image": "val2017/000000070254.jpg",
    "file_name": "000000070254.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top sitting on a bench.",
    "solution": [
      175.98,
      175.4,
      224,
      249.51
    ],
    "normalized_solution": [
      275,
      457,
      350,
      650
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 718
  },
  {
    "annotation_id": "181796_1744201784534",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 360,
    "width": 640,
    "normal_caption": "the transparent cup next to the bread",
    "image": "val2017/000000181796.jpg",
    "file_name": "000000181796.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the transparent cup next to the bread.",
    "solution": [
      213.9,
      60.5,
      298.65,
      154.13
    ],
    "normalized_solution": [
      334,
      168,
      467,
      428
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 2284
  },
  {
    "annotation_id": "146155_1744201991763",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 512,
    "width": 640,
    "normal_caption": "the person wearing a hat holding a glass in hand",
    "image": "val2017/000000146155.jpg",
    "file_name": "000000146155.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a hat holding a glass in hand.",
    "solution": [
      6.06,
      110.29,
      193.16,
      512
    ],
    "normalized_solution": [
      9,
      215,
      302,
      1000
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 2297
  },
  {
    "annotation_id": "210520_1744202253260",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 612,
    "width": 612,
    "normal_caption": "the spoon near the corn not in the bowl",
    "image": "val2017/000000210520.jpg",
    "file_name": "000000210520.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the spoon near the corn not in the bowl.",
    "solution": [
      420.68,
      375.49,
      449.69,
      514.55
    ],
    "normalized_solution": [
      687,
      614,
      735,
      841
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 2306
  },
  {
    "annotation_id": "192904_1744203259978",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 436,
    "width": 640,
    "normal_caption": "the spoon next to an empty cup",
    "image": "val2017/000000192904.jpg",
    "file_name": "000000192904.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the spoon next to an empty cup.",
    "solution": [
      257.16,
      185.54,
      270.13000000000005,
      266.48
    ],
    "normalized_solution": [
      402,
      426,
      422,
      611
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 2308
  },
  {
    "annotation_id": "117492_1744203929364",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "the person holding two teddy bears",
    "image": "val2017/000000117492.jpg",
    "file_name": "000000117492.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person holding two teddy bears.",
    "solution": [
      186.59,
      197.84,
      298.15999999999997,
      420.01
    ],
    "normalized_solution": [
      292,
      462,
      466,
      981
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 2322
  },
  {
    "annotation_id": "462576_1744204022545",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the upside-down cup on the edge of a bowl",
    "image": "val2017/000000462576.jpg",
    "file_name": "000000462576.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the upside-down cup on the edge of a bowl.",
    "solution": [
      82.4,
      21.56,
      114.35000000000001,
      58.78
    ],
    "normalized_solution": [
      129,
      45,
      179,
      122
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 2313
  },
  {
    "annotation_id": "173371_1744204132246",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 612,
    "width": 612,
    "normal_caption": "the fork on a plate with pizza",
    "image": "val2017/000000173371.jpg",
    "file_name": "000000173371.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the fork on a plate with pizza.",
    "solution": [
      30.2,
      352.26,
      79.7,
      573.65
    ],
    "normalized_solution": [
      49,
      576,
      130,
      937
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 2309
  },
  {
    "annotation_id": "192904_1744204193719",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 436,
    "width": 640,
    "normal_caption": "the spoon near a cup that is not empty",
    "image": "val2017/000000192904.jpg",
    "file_name": "000000192904.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the spoon near a cup that is not empty.",
    "solution": [
      296,
      308.82,
      423.53,
      332.36
    ],
    "normalized_solution": [
      463,
      708,
      662,
      762
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 2308
  },
  {
    "annotation_id": "541634_1744204279053",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 612,
    "width": 612,
    "normal_caption": "the transparent cup with a clear beverage inside",
    "image": "val2017/000000541634.jpg",
    "file_name": "000000541634.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the transparent cup with a clear beverage inside.",
    "solution": [
      0,
      82.66,
      117.63,
      270.23
    ],
    "normalized_solution": [
      0,
      135,
      192,
      442
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 2307
  },
  {
    "annotation_id": "541634_1744204349247",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 612,
    "width": 612,
    "normal_caption": "the transparent cup with a colored beverage inside",
    "image": "val2017/000000541634.jpg",
    "file_name": "000000541634.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the transparent cup with a colored beverage inside.",
    "solution": [
      78.94,
      33.76,
      224.81,
      324.71
    ],
    "normalized_solution": [
      129,
      55,
      367,
      531
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 2307
  },
  {
    "annotation_id": "210520_1744204456777",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 612,
    "width": 612,
    "normal_caption": "the spoon in the bowl close to a cup",
    "image": "val2017/000000210520.jpg",
    "file_name": "000000210520.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the spoon in the bowl close to a cup.",
    "solution": [
      424.21,
      161.06,
      571.51,
      237.47
    ],
    "normalized_solution": [
      693,
      263,
      934,
      388
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 2306
  },
  {
    "annotation_id": "171190_1744204522770",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person in a white shirt holding a glass",
    "image": "val2017/000000171190.jpg",
    "file_name": "000000171190.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white shirt holding a glass.",
    "solution": [
      491.87,
      141.3,
      593.26,
      331.15
    ],
    "normalized_solution": [
      769,
      294,
      927,
      690
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 2305
  },
  {
    "annotation_id": "171190_1744204587148",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person in a white shirt not holding a glass",
    "image": "val2017/000000171190.jpg",
    "file_name": "000000171190.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white shirt not holding a glass.",
    "solution": [
      202.79,
      146.52,
      277.21,
      244.67000000000002
    ],
    "normalized_solution": [
      317,
      305,
      433,
      510
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 2305
  },
  {
    "annotation_id": "171190_1744204705735",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person on the left side of the person in a white shirt and not holding a glass",
    "image": "val2017/000000171190.jpg",
    "file_name": "000000171190.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the left side of the person in a white shirt and not holding a glass.",
    "solution": [
      265.3,
      138.48,
      341.26,
      260.28
    ],
    "normalized_solution": [
      415,
      289,
      533,
      542
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 2305
  },
  {
    "annotation_id": "57150_1744204899565",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 320,
    "width": 240,
    "normal_caption": "the person near the teddy bear wearing a white top",
    "image": "val2017/000000057150.jpg",
    "file_name": "000000057150.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person near the teddy bear wearing a white top.",
    "solution": [
      36.91,
      85.86,
      126.06,
      268.81
    ],
    "normalized_solution": [
      154,
      268,
      525,
      840
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "12"
    },
    "image_index": 2299
  },
  {
    "annotation_id": "244750_1744205032925",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 393,
    "normal_caption": "the person covering their mouth and wearing a dark top",
    "image": "val2017/000000244750.jpg",
    "file_name": "000000244750.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person covering their mouth and wearing a dark top.",
    "solution": [
      230.49,
      148.53,
      296.45,
      243.55
    ],
    "normalized_solution": [
      586,
      297,
      754,
      487
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 2292
  },
  {
    "annotation_id": "470773_1744205146502",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the bowl with dark sauce next to the condiment bottles",
    "image": "val2017/000000470773.jpg",
    "file_name": "000000470773.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bowl with dark sauce next to the condiment bottles.",
    "solution": [
      126.1,
      318.87,
      182.62,
      364.55
    ],
    "normalized_solution": [
      197,
      664,
      285,
      759
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 2288
  },
  {
    "annotation_id": "181796_1744205284491",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 360,
    "width": 640,
    "normal_caption": "the opaque cup near the bread",
    "image": "val2017/000000181796.jpg",
    "file_name": "000000181796.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the opaque cup near the bread.",
    "solution": [
      495.01,
      47.84,
      552.71,
      98.78
    ],
    "normalized_solution": [
      773,
      133,
      864,
      274
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 2284
  },
  {
    "annotation_id": "483999_1744205488824",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "the person with dark hair on the left side of the person in a blue top",
    "image": "val2017/000000483999.jpg",
    "file_name": "000000483999.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person with dark hair on the left side of the person in a blue top.",
    "solution": [
      113.49,
      115.26,
      206.79,
      211.44
    ],
    "normalized_solution": [
      177,
      269,
      323,
      494
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    },
    "image_index": 2279
  },
  {
    "annotation_id": "268378_1744205637031",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 359,
    "width": 640,
    "normal_caption": "the person in a white top on the left side of the person in a red top",
    "image": "val2017/000000268378.jpg",
    "file_name": "000000268378.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top on the left side of the person in a red top.",
    "solution": [
      363.29,
      128.8,
      513.38,
      297.52
    ],
    "normalized_solution": [
      568,
      359,
      802,
      829
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 2274
  },
  {
    "annotation_id": "249129_1744205782166",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the teddy bear close to a window and not wearing a black top",
    "image": "val2017/000000249129.jpg",
    "file_name": "000000249129.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the teddy bear close to a window and not wearing a black top.",
    "solution": [
      402.11,
      63.19,
      511.25,
      185.74
    ],
    "normalized_solution": [
      628,
      148,
      799,
      435
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 2273
  },
  {
    "annotation_id": "336053_1744205846583",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the empty glass in the middle of the plates",
    "image": "val2017/000000336053.jpg",
    "file_name": "000000336053.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the empty glass in the middle of the plates.",
    "solution": [
      84.13,
      193.98,
      173.66,
      310.46999999999997
    ],
    "normalized_solution": [
      131,
      404,
      271,
      647
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 2272
  },
  {
    "annotation_id": "12670_1744226471356",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "the man who is on the phone",
    "image": "val2017/000000012670.jpg",
    "file_name": "000000012670.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the man who is on the phone.",
    "solution": [
      100,
      122,
      199,
      275
    ],
    "normalized_solution": [
      156,
      285,
      311,
      643
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": true,
      "distractors": "27"
    },
    "image_index": 2148
  },
  {
    "annotation_id": "94185_1744226495946",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "black board that does not have a number on it",
    "image": "val2017/000000094185.jpg",
    "file_name": "000000094185.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: black board that does not have a number on it.",
    "solution": [
      551,
      180,
      604,
      352
    ],
    "normalized_solution": [
      861,
      375,
      944,
      733
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 2145
  },
  {
    "annotation_id": "5001_1744226532170",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person behind the lady in orange",
    "image": "val2017/000000005001.jpg",
    "file_name": "000000005001.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person behind the lady in orange.",
    "solution": [
      425,
      25,
      506,
      164
    ],
    "normalized_solution": [
      664,
      52,
      791,
      342
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "14"
    },
    "image_index": 2142
  },
  {
    "annotation_id": "85157_1744226870546",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "person wearing striped shirt without long hair",
    "image": "val2017/000000085157.jpg",
    "file_name": "000000085157.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: person wearing striped shirt without long hair.",
    "solution": [
      411.75,
      88.22,
      639.25,
      439.28
    ],
    "normalized_solution": [
      643,
      184,
      999,
      915
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 2024
  },
  {
    "annotation_id": "14439_1744226922300",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 404,
    "width": 640,
    "normal_caption": "the person sitting on the left side of the red chair",
    "image": "val2017/000000014439.jpg",
    "file_name": "000000014439.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person sitting on the left side of the red chair.",
    "solution": [
      25.16,
      116.99,
      65.54,
      154.76
    ],
    "normalized_solution": [
      39,
      290,
      102,
      383
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 2014
  },
  {
    "annotation_id": "8629_1744235662523",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 640,
    "normal_caption": "the image containing fork and knife",
    "image": "val2017/000000008629.jpg",
    "file_name": "000000008629.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the image containing fork and knife.",
    "solution": [
      430,
      226,
      621,
      417
    ],
    "normalized_solution": [
      672,
      353,
      970,
      652
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 1873
  },
  {
    "annotation_id": "885_1744235855018",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "letter X on the wall",
    "image": "val2017/000000000885.jpg",
    "file_name": "000000000885.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: letter X on the wall.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 1821
  },
  {
    "annotation_id": "1000_1744238433793",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person standing to the right of the boy is not wearing a hat or holding a trophy",
    "image": "val2017/000000001000.jpg",
    "file_name": "000000001000.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person standing to the right of the boy is not wearing a hat or holding a trophy.",
    "solution": [
      386,
      156,
      461,
      478
    ],
    "normalized_solution": [
      603,
      325,
      720,
      996
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "12"
    },
    "image_index": 1864
  },
  {
    "annotation_id": "315450_1744327840720",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 428,
    "width": 640,
    "normal_caption": "the car that is in the shade of the bus",
    "image": "val2017/000000315450.jpg",
    "file_name": "000000315450.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car that is in the shade of the bus.",
    "solution": [
      46.87,
      230.53,
      150.57,
      299.18
    ],
    "normalized_solution": [
      73,
      539,
      235,
      699
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 299
  },
  {
    "annotation_id": "538364_1744328007768",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person that is on the street and neither riding a motorcycle nor wearing blue shirt",
    "image": "val2017/000000538364.jpg",
    "file_name": "000000538364.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person that is on the street and neither riding a motorcycle nor wearing blue shirt.",
    "solution": [
      45.32,
      122.27,
      84.17,
      268.05
    ],
    "normalized_solution": [
      71,
      255,
      132,
      558
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "9"
    },
    "image_index": 300
  },
  {
    "annotation_id": "260266_1744328197585",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 479,
    "normal_caption": "the lightest-colored car among the three parked one behind the other near the roadside closest to the camera",
    "image": "val2017/000000260266.jpg",
    "file_name": "000000260266.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the lightest-colored car among the three parked one behind the other near the roadside closest to the camera.",
    "solution": [
      123.08,
      523.04,
      182.35,
      557.02
    ],
    "normalized_solution": [
      257,
      817,
      381,
      870
    ],
    "categories": {
      "empty_case": false,
      "hops": "4",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 302
  },
  {
    "annotation_id": "26204_1744328255207",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the red car that is not waiting at the traffic light",
    "image": "val2017/000000026204.jpg",
    "file_name": "000000026204.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the red car that is not waiting at the traffic light.",
    "solution": [
      522.3,
      259.99,
      603.5999999999999,
      307.64
    ],
    "normalized_solution": [
      816,
      609,
      943,
      720
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "4"
    },
    "image_index": 303
  },
  {
    "annotation_id": "520009_1744328365906",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 412,
    "width": 500,
    "normal_caption": "the traffic light that is not farthest from the camera and does not have a no turning sign on it",
    "image": "val2017/000000520009.jpg",
    "file_name": "000000520009.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the traffic light that is not farthest from the camera and does not have a no turning sign on it.",
    "solution": [
      0.12,
      226.24,
      18.900000000000002,
      264.96000000000004
    ],
    "normalized_solution": [
      0,
      549,
      38,
      643
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 306
  },
  {
    "annotation_id": "284725_1744328533462",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the car that least should be parked where it is",
    "image": "val2017/000000284725.jpg",
    "file_name": "000000284725.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car that least should be parked where it is.",
    "solution": [
      147.53,
      290.17,
      378.32,
      376.28000000000003
    ],
    "normalized_solution": [
      231,
      680,
      591,
      881
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 307
  },
  {
    "annotation_id": "446651_1744328643299",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the person on the motorcycle but not holding the handlebar",
    "image": "val2017/000000446651.jpg",
    "file_name": "000000446651.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the motorcycle but not holding the handlebar.",
    "solution": [
      182.98,
      182.12,
      325.92999999999995,
      421.33000000000004
    ],
    "normalized_solution": [
      286,
      428,
      509,
      989
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 308
  },
  {
    "annotation_id": "278848_1744328762601",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person carrying a bag and holding an umbrella",
    "image": "val2017/000000278848.jpg",
    "file_name": "000000278848.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person carrying a bag and holding an umbrella.",
    "solution": [
      297.71,
      428.58,
      360.99,
      616.99
    ],
    "normalized_solution": [
      620,
      670,
      752,
      964
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 309
  },
  {
    "annotation_id": "463730_1744328879149",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person walking away from the camera and closest to the roundabout sign",
    "image": "val2017/000000463730.jpg",
    "file_name": "000000463730.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person walking away from the camera and closest to the roundabout sign.",
    "solution": [
      39.01,
      180.37,
      81.08,
      301.45
    ],
    "normalized_solution": [
      61,
      422,
      127,
      706
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 310
  },
  {
    "annotation_id": "480021_1744329561489",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 471,
    "width": 640,
    "normal_caption": "the person on the motorcycle that has only one rider on it",
    "image": "val2017/000000480021.jpg",
    "file_name": "000000480021.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person on the motorcycle that has only one rider on it.",
    "solution": [
      99.47,
      77.89,
      223.5,
      274.15
    ],
    "normalized_solution": [
      155,
      165,
      349,
      582
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 311
  },
  {
    "annotation_id": "142472_1744329647742",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the silver car that is furthest from the red bus",
    "image": "val2017/000000142472.jpg",
    "file_name": "000000142472.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the silver car that is furthest from the red bus.",
    "solution": [
      350.82,
      373.17,
      390.62,
      413.48
    ],
    "normalized_solution": [
      548,
      777,
      610,
      861
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": true,
      "distractors": "3"
    },
    "image_index": 312
  },
  {
    "annotation_id": "203389_1744329949902",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person wearing a beanie with sunglasses hanging on their head",
    "image": "val2017/000000203389.jpg",
    "file_name": "000000203389.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a beanie with sunglasses hanging on their head.",
    "solution": [
      182.03,
      198.98,
      366.05,
      480
    ],
    "normalized_solution": [
      284,
      415,
      572,
      1000
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 326
  },
  {
    "annotation_id": "226154_1744330060683",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 507,
    "width": 640,
    "normal_caption": "the person who is driving a vehicle but not a motorcycle",
    "image": "val2017/000000226154.jpg",
    "file_name": "000000226154.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person who is driving a vehicle but not a motorcycle.",
    "solution": [
      206.3,
      170.02,
      269.33000000000004,
      224.63
    ],
    "normalized_solution": [
      322,
      335,
      421,
      443
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 328
  },
  {
    "annotation_id": "308631_1744331093420",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the person wearing jeans and a black top",
    "image": "val2017/000000308631.jpg",
    "file_name": "000000308631.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing jeans and a black top.",
    "solution": [
      163.44,
      0,
      242.95,
      114.15
    ],
    "normalized_solution": [
      255,
      0,
      380,
      268
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": true,
      "distractors": "9"
    },
    "image_index": 334
  },
  {
    "annotation_id": "7816_1744331248490",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person sitting on the grass and not wearing white pants",
    "image": "val2017/000000007816.jpg",
    "file_name": "000000007816.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person sitting on the grass and not wearing white pants.",
    "solution": [
      415.88,
      122.97,
      479.89,
      176.01999999999998
    ],
    "normalized_solution": [
      650,
      288,
      750,
      412
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": true,
      "distractors": "9"
    },
    "image_index": 335
  },
  {
    "annotation_id": "245448_1744331843990",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person facing the camera, wearing a reflective vest and a hat",
    "image": "val2017/000000245448.jpg",
    "file_name": "000000245448.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person facing the camera, wearing a reflective vest and a hat.",
    "solution": [
      378.33,
      146.78,
      422.58,
      233.32
    ],
    "normalized_solution": [
      591,
      306,
      660,
      486
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "4"
    },
    "image_index": 339
  },
  {
    "annotation_id": "534827_1744334130503",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 612,
    "width": 612,
    "normal_caption": "the red motorcycle ridden by a person not wearing a yellow shirt",
    "image": "val2017/000000534827.jpg",
    "file_name": "000000534827.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the red motorcycle ridden by a person not wearing a yellow shirt.",
    "solution": [
      296.66,
      288.47,
      376.75,
      374.64000000000004
    ],
    "normalized_solution": [
      485,
      471,
      616,
      612
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": true,
      "distractors": "4"
    },
    "image_index": 342
  },
  {
    "annotation_id": "433204_1744334318318",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person wearing a reflective vest with their back to the camera",
    "image": "val2017/000000433204.jpg",
    "file_name": "000000433204.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a reflective vest with their back to the camera.",
    "solution": [
      463.09,
      236.85,
      478.26,
      288.87
    ],
    "normalized_solution": [
      724,
      493,
      747,
      602
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 346
  },
  {
    "annotation_id": "131386_1744334761373",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the fifth plane from the top in the stack",
    "image": "val2017/000000131386.jpg",
    "file_name": "000000131386.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the fifth plane from the top in the stack.",
    "solution": null,
    "normalized_solution": null,
    "categories": {
      "empty_case": true,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": true,
      "distractors": "4"
    },
    "image_index": 352
  },
  {
    "annotation_id": "381639_1744335265743",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 584,
    "normal_caption": "the person boarding the plane wearing a white shirt and carrying a backpack",
    "image": "val2017/000000381639.jpg",
    "file_name": "000000381639.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person boarding the plane wearing a white shirt and carrying a backpack.",
    "solution": [
      332.71,
      98.77,
      353.45,
      162.24
    ],
    "normalized_solution": [
      570,
      154,
      605,
      254
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "8"
    },
    "image_index": 357
  },
  {
    "annotation_id": "99054_1744335659875",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 427,
    "normal_caption": "the person wearing a reflective vest and standing under the airplane",
    "image": "val2017/000000099054.jpg",
    "file_name": "000000099054.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a reflective vest and standing under the airplane.",
    "solution": [
      298.66,
      492.89,
      330.19000000000005,
      569.29
    ],
    "normalized_solution": [
      699,
      770,
      773,
      890
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": true,
      "distractors": "2"
    },
    "image_index": 359
  },
  {
    "annotation_id": "502599_1744335768630",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the plane that is not orange and does not have \"U.S. AIR FORCE\" written on it",
    "image": "val2017/000000502599.jpg",
    "file_name": "000000502599.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the plane that is not orange and does not have \"U.S. AIR FORCE\" written on it.",
    "solution": [
      126.36,
      291.69,
      380.05,
      403.69
    ],
    "normalized_solution": [
      197,
      685,
      594,
      948
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 362
  },
  {
    "annotation_id": "163746_1744335861549",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 488,
    "width": 640,
    "normal_caption": "the person with long curly hair in the right image",
    "image": "val2017/000000163746.jpg",
    "file_name": "000000163746.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person with long curly hair in the right image.",
    "solution": [
      386.86,
      218.45,
      447.43,
      400.15
    ],
    "normalized_solution": [
      604,
      448,
      699,
      820
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "10"
    },
    "image_index": 368
  },
  {
    "annotation_id": "33114_1744335984747",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the orange-and-black signal light that is the second furthest from the camera",
    "image": "val2017/000000033114.jpg",
    "file_name": "000000033114.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the orange-and-black signal light that is the second furthest from the camera.",
    "solution": [
      349.84,
      332.27,
      394.22999999999996,
      377.39
    ],
    "normalized_solution": [
      547,
      692,
      616,
      786
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 369
  },
  {
    "annotation_id": "478862_1744336049408",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person standing near the nose of the plane wearing brown shorts",
    "image": "val2017/000000478862.jpg",
    "file_name": "000000478862.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person standing near the nose of the plane wearing brown shorts.",
    "solution": [
      80.84,
      285.3,
      116.75,
      389.93
    ],
    "normalized_solution": [
      126,
      594,
      182,
      812
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 371
  },
  {
    "annotation_id": "579158_1744336231546",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the third suitcase that is about to enter the airplane cargo hold",
    "image": "val2017/000000579158.jpg",
    "file_name": "000000579158.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the third suitcase that is about to enter the airplane cargo hold.",
    "solution": [
      187.98,
      322.2,
      219.95,
      345.53
    ],
    "normalized_solution": [
      294,
      671,
      344,
      720
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 372
  },
  {
    "annotation_id": "568439_1744373389385",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 449,
    "width": 640,
    "normal_caption": "the person in front of a building with a red bag",
    "image": "val2017/000000568439.jpg",
    "file_name": "000000568439.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in front of a building with a red bag.",
    "solution": [
      56.01,
      243.15,
      68.92999999999999,
      281.75
    ],
    "normalized_solution": [
      88,
      542,
      108,
      628
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 384
  },
  {
    "annotation_id": "568439_1744373529797",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 449,
    "width": 640,
    "normal_caption": "the board behind the route 26 bus",
    "image": "val2017/000000568439.jpg",
    "file_name": "000000568439.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the board behind the route 26 bus.",
    "solution": [
      0,
      235,
      54,
      338
    ],
    "normalized_solution": [
      0,
      523,
      84,
      753
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "23"
    },
    "image_index": 384
  },
  {
    "annotation_id": "550349_1744373623809",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person in a white top not driving",
    "image": "val2017/000000550349.jpg",
    "file_name": "000000550349.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top not driving.",
    "solution": [
      223.62,
      296.49,
      298.32,
      383.79
    ],
    "normalized_solution": [
      466,
      463,
      621,
      600
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 388
  },
  {
    "annotation_id": "441553_1744373757787",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person in a white top facing sideways toward the camera",
    "image": "val2017/000000441553.jpg",
    "file_name": "000000441553.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top facing sideways toward the camera.",
    "solution": [
      225.98,
      258.94,
      260.57,
      390.53
    ],
    "normalized_solution": [
      353,
      539,
      407,
      814
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 391
  },
  {
    "annotation_id": "545594_1744373989248",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 512,
    "width": 640,
    "normal_caption": "the person with a hat and glasses",
    "image": "val2017/000000545594.jpg",
    "file_name": "000000545594.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person with a hat and glasses.",
    "solution": [
      0.6,
      159.64,
      35.800000000000004,
      228.33999999999997
    ],
    "normalized_solution": [
      1,
      312,
      56,
      446
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "7"
    },
    "image_index": 397
  },
  {
    "annotation_id": "545594_1744374033520",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 512,
    "width": 640,
    "normal_caption": "the person in a green top holding the handrail",
    "image": "val2017/000000545594.jpg",
    "file_name": "000000545594.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a green top holding the handrail.",
    "solution": [
      255.49,
      218.13,
      307.9,
      330.95
    ],
    "normalized_solution": [
      399,
      426,
      481,
      646
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": true,
      "distractors": "7"
    },
    "image_index": 397
  },
  {
    "annotation_id": "307074_1744374185627",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 333,
    "width": 500,
    "normal_caption": "the grey car in front of a black car",
    "image": "val2017/000000307074.jpg",
    "file_name": "000000307074.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the grey car in front of a black car.",
    "solution": [
      121.31,
      281.81,
      146.62,
      296.24
    ],
    "normalized_solution": [
      243,
      846,
      293,
      890
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 406
  },
  {
    "annotation_id": "468925_1744374308189",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the bacon on the edge of a bowl",
    "image": "val2017/000000468925.jpg",
    "file_name": "000000468925.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bacon on the edge of a bowl.",
    "solution": [
      163,
      44,
      354,
      81
    ],
    "normalized_solution": [
      255,
      92,
      553,
      169
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 407
  },
  {
    "annotation_id": "97988_1744374459514",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 612,
    "width": 612,
    "normal_caption": "the person sitting on the bench wearing a white top",
    "image": "val2017/000000097988.jpg",
    "file_name": "000000097988.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person sitting on the bench wearing a white top.",
    "solution": [
      381,
      293,
      418,
      345
    ],
    "normalized_solution": [
      623,
      479,
      683,
      564
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "16"
    },
    "image_index": 415
  },
  {
    "annotation_id": "32941_1744374525138",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 458,
    "normal_caption": "the car in front of the blue car",
    "image": "val2017/000000032941.jpg",
    "file_name": "000000032941.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car in front of the blue car.",
    "solution": [
      266.2,
      196.93,
      301.03999999999996,
      224.84
    ],
    "normalized_solution": [
      581,
      308,
      657,
      351
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "4"
    },
    "image_index": 417
  },
  {
    "annotation_id": "94751_1744374630798",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 375,
    "normal_caption": "the traffic light behind a car",
    "image": "val2017/000000094751.jpg",
    "file_name": "000000094751.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the traffic light behind a car.",
    "solution": [
      1.02,
      224.07,
      12.91,
      247.20999999999998
    ],
    "normalized_solution": [
      3,
      448,
      34,
      494
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 418
  },
  {
    "annotation_id": "327890_1744374735368",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the bench facing sideways toward the camera and not next to the trash can",
    "image": "val2017/000000327890.jpg",
    "file_name": "000000327890.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bench facing sideways toward the camera and not next to the trash can.",
    "solution": [
      15.07,
      248.61,
      120.53999999999999,
      336.86
    ],
    "normalized_solution": [
      24,
      518,
      188,
      702
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 422
  },
  {
    "annotation_id": "144706_1744374959990",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the traffic light that is not next to the signpost and not on the lamppost",
    "image": "val2017/000000144706.jpg",
    "file_name": "000000144706.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the traffic light that is not next to the signpost and not on the lamppost.",
    "solution": [
      166.93,
      155.81,
      189.17000000000002,
      198.09
    ],
    "normalized_solution": [
      261,
      325,
      296,
      413
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 431
  },
  {
    "annotation_id": "105912_1744375166567",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the Canada maple leaf emblem not on the national flag",
    "image": "val2017/000000105912.jpg",
    "file_name": "000000105912.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the Canada maple leaf emblem not on the national flag.",
    "solution": [
      216,
      136,
      245,
      156
    ],
    "normalized_solution": [
      432,
      363,
      490,
      416
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 436
  },
  {
    "annotation_id": "436738_1744375337316",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 486,
    "width": 500,
    "normal_caption": "the solid-colored car next to the bus",
    "image": "val2017/000000436738.jpg",
    "file_name": "000000436738.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the solid-colored car next to the bus.",
    "solution": [
      370.52,
      348.79,
      467.65999999999997,
      391.55
    ],
    "normalized_solution": [
      741,
      718,
      935,
      806
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 440
  },
  {
    "annotation_id": "288584_1744375554978",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person with black hair behind the giraffe costume",
    "image": "val2017/000000288584.jpg",
    "file_name": "000000288584.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person with black hair behind the giraffe costume.",
    "solution": [
      127.74,
      257.92,
      211.48,
      426.17
    ],
    "normalized_solution": [
      200,
      604,
      330,
      998
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 450
  },
  {
    "annotation_id": "288584_1744375680145",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the handbag held by a person not with black hair behind the giraffe costume",
    "image": "val2017/000000288584.jpg",
    "file_name": "000000288584.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the handbag held by a person not with black hair behind the giraffe costume.",
    "solution": [
      75.42,
      337.16,
      119.78,
      427
    ],
    "normalized_solution": [
      118,
      790,
      187,
      1000
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 450
  },
  {
    "annotation_id": "98716_1744376004455",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 359,
    "width": 640,
    "normal_caption": "the person walking without wearing sunglasses",
    "image": "val2017/000000098716.jpg",
    "file_name": "000000098716.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person walking without wearing sunglasses.",
    "solution": [
      15.96,
      153.47,
      35.93,
      190.46
    ],
    "normalized_solution": [
      25,
      427,
      56,
      531
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 481
  },
  {
    "annotation_id": "373705_1744376072123",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person standing in white pants",
    "image": "val2017/000000373705.jpg",
    "file_name": "000000373705.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person standing in white pants.",
    "solution": [
      94.04,
      85.24,
      136.26,
      201.35
    ],
    "normalized_solution": [
      147,
      200,
      213,
      472
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 482
  },
  {
    "annotation_id": "11511_1744376344984",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 464,
    "width": 640,
    "normal_caption": "the person in a light yellow top and facing sideways toward the camera",
    "image": "val2017/000000011511.jpg",
    "file_name": "000000011511.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a light yellow top and facing sideways toward the camera.",
    "solution": [
      90.35,
      38.6,
      130.06,
      190.01999999999998
    ],
    "normalized_solution": [
      141,
      83,
      203,
      410
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 484
  },
  {
    "annotation_id": "571718_1744376540897",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the plastic bag without banana peel inside",
    "image": "val2017/000000571718.jpg",
    "file_name": "000000571718.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the plastic bag without banana peel inside.",
    "solution": [
      354,
      335,
      422,
      415
    ],
    "normalized_solution": [
      553,
      785,
      659,
      972
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "32"
    },
    "image_index": 486
  },
  {
    "annotation_id": "571718_1744376619144",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the paperboard facing the camera with numbers on it",
    "image": "val2017/000000571718.jpg",
    "file_name": "000000571718.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the paperboard facing the camera with numbers on it.",
    "solution": [
      92,
      109,
      145,
      207
    ],
    "normalized_solution": [
      144,
      255,
      227,
      485
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "32"
    },
    "image_index": 486
  },
  {
    "annotation_id": "44590_1744376749912",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 246,
    "width": 640,
    "normal_caption": "the person sitting on a motorbike wearing jeans",
    "image": "val2017/000000044590.jpg",
    "file_name": "000000044590.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person sitting on a motorbike wearing jeans.",
    "solution": [
      540.74,
      96.25,
      578.99,
      142.91
    ],
    "normalized_solution": [
      845,
      391,
      905,
      581
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 487
  },
  {
    "annotation_id": "62353_1744376878087",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person in a white top with their back to the camera",
    "image": "val2017/000000062353.jpg",
    "file_name": "000000062353.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top with their back to the camera.",
    "solution": [
      15.86,
      229.13,
      54.519999999999996,
      304.77
    ],
    "normalized_solution": [
      25,
      477,
      85,
      635
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 488
  },
  {
    "annotation_id": "227478_1744376966186",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the empty bench next to a tree",
    "image": "val2017/000000227478.jpg",
    "file_name": "000000227478.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the empty bench next to a tree.",
    "solution": [
      121.54,
      77.22,
      378.19,
      148.16
    ],
    "normalized_solution": [
      190,
      161,
      591,
      309
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 489
  },
  {
    "annotation_id": "286849_1744377221416",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 333,
    "normal_caption": "the giraffe in the middle with its mouth open",
    "image": "val2017/000000286849.jpg",
    "file_name": "000000286849.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the giraffe in the middle with its mouth open.",
    "solution": [
      103.61,
      96.73,
      285.55,
      251.53000000000003
    ],
    "normalized_solution": [
      311,
      193,
      858,
      503
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 504
  },
  {
    "annotation_id": "286849_1744377264000",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 500,
    "width": 333,
    "normal_caption": "the giraffe not in the middle with its mouth open",
    "image": "val2017/000000286849.jpg",
    "file_name": "000000286849.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the giraffe not in the middle with its mouth open.",
    "solution": [
      57.6,
      73.43,
      148.61,
      159.75
    ],
    "normalized_solution": [
      173,
      147,
      446,
      320
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 504
  },
  {
    "annotation_id": "322429_1744377404670",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 472,
    "normal_caption": "the pink vase without a tag on it",
    "image": "val2017/000000322429.jpg",
    "file_name": "000000322429.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the pink vase without a tag on it.",
    "solution": [
      244.17,
      511.48,
      337.51,
      624.82
    ],
    "normalized_solution": [
      517,
      799,
      715,
      976
    ],
    "categories": {
      "empty_case": false,
      "hops": "3",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 510
  },
  {
    "annotation_id": "322429_1744377526046",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 472,
    "normal_caption": "the bowl with a lid that is not green",
    "image": "val2017/000000322429.jpg",
    "file_name": "000000322429.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bowl with a lid that is not green.",
    "solution": [
      223.57,
      337.89,
      337.84,
      437.5
    ],
    "normalized_solution": [
      474,
      528,
      716,
      684
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 510
  },
  {
    "annotation_id": "322429_1744377662280",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 472,
    "normal_caption": "the white cup with no other colors on it",
    "image": "val2017/000000322429.jpg",
    "file_name": "000000322429.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white cup with no other colors on it.",
    "solution": [
      19.83,
      196.42,
      63.65,
      233.35
    ],
    "normalized_solution": [
      42,
      307,
      135,
      365
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "8"
    },
    "image_index": 510
  },
  {
    "annotation_id": "288685_1744377879992",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 436,
    "width": 640,
    "normal_caption": "the person wearing a hat and a white top",
    "image": "val2017/000000288685.jpg",
    "file_name": "000000288685.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing a hat and a white top.",
    "solution": [
      320.22,
      89.27,
      377.51000000000005,
      184.24
    ],
    "normalized_solution": [
      500,
      205,
      590,
      423
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 529
  },
  {
    "annotation_id": "288685_1744377940208",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 436,
    "width": 640,
    "normal_caption": "the person with sunglasses and a white top",
    "image": "val2017/000000288685.jpg",
    "file_name": "000000288685.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person with sunglasses and a white top.",
    "solution": [
      0,
      105.31,
      67.38,
      176.59
    ],
    "normalized_solution": [
      0,
      242,
      105,
      405
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 529
  },
  {
    "annotation_id": "169169_1744378006004",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the person with a white top and long hair",
    "image": "val2017/000000169169.jpg",
    "file_name": "000000169169.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person with a white top and long hair.",
    "solution": [
      580.02,
      364.06,
      594.39,
      424.17
    ],
    "normalized_solution": [
      906,
      758,
      929,
      884
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "13"
    },
    "image_index": 530
  },
  {
    "annotation_id": "140640_1744378104305",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 426,
    "width": 640,
    "normal_caption": "the person not cutting and not facing the camera",
    "image": "val2017/000000140640.jpg",
    "file_name": "000000140640.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person not cutting and not facing the camera.",
    "solution": [
      435.59,
      88.75,
      603.5,
      376.59
    ],
    "normalized_solution": [
      681,
      208,
      943,
      884
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "verb"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 531
  },
  {
    "annotation_id": "350054_1744378182571",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 375,
    "width": 500,
    "normal_caption": "the teddy bear not behind the cat",
    "image": "val2017/000000350054.jpg",
    "file_name": "000000350054.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the teddy bear not behind the cat.",
    "solution": [
      180.29,
      137.33,
      220.60999999999999,
      193.11
    ],
    "normalized_solution": [
      361,
      366,
      441,
      515
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 534
  },
  {
    "annotation_id": "277051_1744378356221",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the bird on the table without food",
    "image": "val2017/000000277051.jpg",
    "file_name": "000000277051.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the bird on the table without food.",
    "solution": [
      500.78,
      99.53,
      586.53,
      150.29
    ],
    "normalized_solution": [
      782,
      233,
      916,
      352
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 539
  },
  {
    "annotation_id": "494188_1744378588699",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person standing with a bag in hand",
    "image": "val2017/000000494188.jpg",
    "file_name": "000000494188.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person standing with a bag in hand.",
    "solution": [
      253.9,
      78.35,
      344.04,
      337.39
    ],
    "normalized_solution": [
      529,
      122,
      717,
      527
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "verb"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 555
  },
  {
    "annotation_id": "166277_1744378754060",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the opaque cup without a lid",
    "image": "val2017/000000166277.jpg",
    "file_name": "000000166277.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the opaque cup without a lid.",
    "solution": [
      325.46,
      239.82,
      454.27,
      416.87
    ],
    "normalized_solution": [
      678,
      375,
      946,
      651
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 569
  },
  {
    "annotation_id": "84650_1744378874845",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the suitcase with a cat on it",
    "image": "val2017/000000084650.jpg",
    "file_name": "000000084650.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the suitcase with a cat on it.",
    "solution": [
      188.76,
      237.3,
      555.51,
      472.45000000000005
    ],
    "normalized_solution": [
      295,
      494,
      868,
      984
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 578
  },
  {
    "annotation_id": "61171_1744379022625",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the cow with an ear tag that is not eating",
    "image": "val2017/000000061171.jpg",
    "file_name": "000000061171.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cow with an ear tag that is not eating.",
    "solution": [
      277.08,
      0.54,
      360.99,
      85.42
    ],
    "normalized_solution": [
      433,
      1,
      564,
      178
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 584
  },
  {
    "annotation_id": "416758_1744379269558",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the white cow standing",
    "image": "val2017/000000416758.jpg",
    "file_name": "000000416758.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white cow standing.",
    "solution": [
      397.77,
      63.45,
      602.31,
      315.27
    ],
    "normalized_solution": [
      622,
      132,
      941,
      657
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 608
  },
  {
    "annotation_id": "416758_1744379330668",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the cow with an ear tag not facing the camera",
    "image": "val2017/000000416758.jpg",
    "file_name": "000000416758.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the cow with an ear tag not facing the camera.",
    "solution": [
      64.14,
      75,
      421.03,
      443.28
    ],
    "normalized_solution": [
      100,
      156,
      658,
      924
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 608
  },
  {
    "annotation_id": "430073_1744379414619",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the empty red chair",
    "image": "val2017/000000430073.jpg",
    "file_name": "000000430073.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the empty red chair.",
    "solution": [
      360.62,
      211.42,
      396.36,
      263.21999999999997
    ],
    "normalized_solution": [
      563,
      440,
      619,
      548
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "attr"
      ],
      "occluded": false,
      "distractors": "6"
    },
    "image_index": 615
  },
  {
    "annotation_id": "11197_1744379649801",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 427,
    "width": 640,
    "normal_caption": "the person wearing jeans not wearing a hat",
    "image": "val2017/000000011197.jpg",
    "file_name": "000000011197.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person wearing jeans not wearing a hat.",
    "solution": [
      297,
      116,
      320,
      242
    ],
    "normalized_solution": [
      464,
      272,
      500,
      567
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "attr"
      ],
      "occluded": false,
      "distractors": "11"
    },
    "image_index": 640
  },
  {
    "annotation_id": "511999_1744379870219",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 446,
    "width": 640,
    "normal_caption": "the person in an orange top with their hand in the pocket",
    "image": "val2017/000000511999.jpg",
    "file_name": "000000511999.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in an orange top with their hand in the pocket.",
    "solution": [
      214.82,
      195.64,
      244.09,
      327.97
    ],
    "normalized_solution": [
      336,
      439,
      381,
      735
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 661
  },
  {
    "annotation_id": "423617_1744379980940",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the white car next to a bus",
    "image": "val2017/000000423617.jpg",
    "file_name": "000000423617.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the white car next to a bus.",
    "solution": [
      0,
      153.35,
      56.1,
      221.92
    ],
    "normalized_solution": [
      0,
      319,
      88,
      462
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "3"
    },
    "image_index": 671
  },
  {
    "annotation_id": "81394_1744380036726",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the motorcycle behind a board",
    "image": "val2017/000000081394.jpg",
    "file_name": "000000081394.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the motorcycle behind a board.",
    "solution": [
      532.29,
      172.58,
      633.68,
      224.69
    ],
    "normalized_solution": [
      832,
      360,
      990,
      468
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 674
  },
  {
    "annotation_id": "344029_1744380097267",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 480,
    "width": 640,
    "normal_caption": "the car behind the white car",
    "image": "val2017/000000344029.jpg",
    "file_name": "000000344029.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the car behind the white car.",
    "solution": [
      40.56,
      228.86,
      68.48,
      264.5
    ],
    "normalized_solution": [
      63,
      477,
      107,
      551
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "spatial",
        "attr"
      ],
      "occluded": false,
      "distractors": "2"
    },
    "image_index": 675
  },
  {
    "annotation_id": "507797_1744380196501",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 425,
    "width": 640,
    "normal_caption": "the person with dark hair getting off the bus",
    "image": "val2017/000000507797.jpg",
    "file_name": "000000507797.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person with dark hair getting off the bus.",
    "solution": [
      73.42,
      103.74,
      129.37,
      240.71999999999997
    ],
    "normalized_solution": [
      115,
      244,
      202,
      566
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "7"
    },
    "image_index": 683
  },
  {
    "annotation_id": "52007_1744380250260",
    "dataset": "refcocos_test",
    "text_type": "caption",
    "height": 640,
    "width": 480,
    "normal_caption": "the person in a white top who is not driving",
    "image": "val2017/000000052007.jpg",
    "file_name": "000000052007.jpg",
    "problem": "Please provide the bounding box coordinate of the region this sentence describes: the person in a white top who is not driving.",
    "solution": [
      219.08,
      255.51,
      258,
      313.75
    ],
    "normalized_solution": [
      456,
      399,
      538,
      490
    ],
    "categories": {
      "empty_case": false,
      "hops": "2",
      "type": [
        "exclude",
        "verb",
        "attr"
      ],
      "occluded": false,
      "distractors": "5"
    },
    "image_index": 686
  }
]